{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a049f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n",
      "  ConcatenatedTopologicalCSSCode: <class 'qectostim.codes.composite.concatenated.ConcatenatedTopologicalCSSCode'>\n",
      "  HomologicalProductCode: <class 'qectostim.codes.composite.homological_product.HomologicalProductCode'>\n",
      "  DualCode: <class 'qectostim.codes.composite.dual.DualCode'>\n",
      "  Decoders loaded: ['PyMatching', 'FusionBlossom', 'BeliefMatching', 'BPOSD', 'Tesseract', 'UnionFind', 'MLE', 'Hypergraph', 'Chromobius', 'Concatenated', 'FlatConcat', 'HardHierarchical', 'TurboConcatenatedTurbo', 'SoftHierarchical', 'SoftMVP', 'TurboV2', 'ExtrinsicTurbo', 'SoftMP', 'SingleShot']\n",
      "  ConcatenatedDecoder available: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 1: Setup and Imports\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure src is in path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Clear all qectostim module cache BEFORE importing (fresh start)\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "# Also clear the bytecode cache\n",
    "import importlib\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# Import testing utilities from qectostim.testing\n",
    "from qectostim.testing import (\n",
    "    clear_qectostim_modules,\n",
    "    test_composite_construction,\n",
    "    test_code_circuit,\n",
    "    test_decoder_on_code,\n",
    "    load_all_decoders,\n",
    "    STATUS_OK, STATUS_WARN, STATUS_SKIP, STATUS_FAIL,\n",
    ")\n",
    "\n",
    "# Import qectostim\n",
    "from qectostim.codes import discover_all_codes\n",
    "from qectostim.codes.composite import (\n",
    "    ConcatenatedTopologicalCSSCode,\n",
    "    HomologicalProductCode,\n",
    "    DualCode,\n",
    ")\n",
    "from qectostim.codes.abstract_css import CSSCodeWithComplex\n",
    "from qectostim.decoders import PyMatchingDecoder\n",
    "\n",
    "# Load all available decoders\n",
    "decoder_classes = load_all_decoders()\n",
    "\n",
    "# Try to import ConcatenatedDecoder\n",
    "try:\n",
    "    from qectostim.decoders.concatenated_decoder import ConcatenatedDecoder\n",
    "    HAS_CONCAT_DECODER = True\n",
    "except ImportError as e:\n",
    "    HAS_CONCAT_DECODER = False\n",
    "    print(f\"Note: ConcatenatedDecoder not available: {e}\")\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"  ConcatenatedTopologicalCSSCode: {ConcatenatedTopologicalCSSCode}\")\n",
    "print(f\"  HomologicalProductCode: {HomologicalProductCode}\")\n",
    "print(f\"  DualCode: {DualCode}\")\n",
    "print(f\"  Decoders loaded: {list(decoder_classes.keys())}\")\n",
    "print(f\"  ConcatenatedDecoder available: {HAS_CONCAT_DECODER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bac643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DISCOVERING BUILDING BLOCK CODES\n",
      "======================================================================\n",
      "\n",
      "Total discovered: 58\n",
      "CSS codes with k>0: 53\n",
      "\n",
      "By size:\n",
      "  Small (n≤10): 14\n",
      "  Medium (10<n≤30): 17\n",
      "  Surface-like: 11\n",
      "  Other: 11\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Code Name                                   n   k   d\n",
      "----------------------------------------------------------------------\n",
      "Repetition_3                                3   1   3\n",
      "FourQubit422_[[4,2,2]]                      4   2   2\n",
      "Repetition_5                                5   1   5\n",
      "C6                                          6   2   2\n",
      "Steane_713                                  7   1   3\n",
      "Hamming_CSS_7                               7   1   3\n",
      "Repetition_7                                7   1   7\n",
      "TriangularColour_d3                         7   1   3\n",
      "TetrahedralColorCode                        7   1   ?\n",
      "Code_832                                    8   3   2\n",
      "LoopToricCode4D                             8   2   ?\n",
      "HexagonalColour_d2                          8   2   2\n",
      "Shor_91                                     9   1   3\n",
      "RotatedSurface_[[9,1,3]]                    9   1   3\n",
      "XZZX_Surface_3                              9   1   3\n",
      "Colour488_[[9,1,3]]                         9   1   3\n",
      "BaconShor_3x3                               9   5   3\n",
      "Hyperbolic57Code                           13   1   5\n",
      "ProjectivePlaneSurface_[[13,1,None]]       13   1   ?\n",
      "QuantumPinCode_d3_m2                       13   1   3\n",
      "... and 33 more\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 2: Discover Building Block Codes\"\"\"\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DISCOVERING BUILDING BLOCK CODES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Discover codes - use smaller size for composite building\n",
    "all_codes = discover_all_codes(\n",
    "    max_qubits=50,  # Smaller for composition\n",
    "    include_qldpc=True,\n",
    "    include_subsystem=False,  # Skip subsystem for CSS operations\n",
    "    include_floquet=False,    # Skip floquet for CSS operations\n",
    "    include_bosonic=False,\n",
    "    include_qudit=False,\n",
    "    include_non_css=True,\n",
    "    timeout_per_code=3.0,\n",
    ")\n",
    "\n",
    "# Filter to CSS codes only (required for concatenation and homological product)\n",
    "css_codes = {}\n",
    "for name, code in all_codes.items():\n",
    "    if hasattr(code, 'hx') and hasattr(code, 'hz'):\n",
    "        # Additional check: must have k > 0\n",
    "        if code.k > 0:\n",
    "            # Verify CSS condition: hx @ hz.T == 0 (mod 2)\n",
    "            try:\n",
    "                import numpy as np\n",
    "                from scipy import sparse\n",
    "                hx = code.hx\n",
    "                hz = code.hz\n",
    "                # Handle sparse matrices\n",
    "                if sparse.issparse(hx):\n",
    "                    hx = hx.toarray()\n",
    "                if sparse.issparse(hz):\n",
    "                    hz = hz.toarray()\n",
    "                product = (hx @ hz.T) % 2\n",
    "                if np.any(product != 0):\n",
    "                    print(f\"  Skipping {name}: hx @ hz.T != 0 (not valid CSS)\")\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"  Skipping {name}: CSS check failed ({e})\")\n",
    "                continue  # Skip if CSS check fails\n",
    "            css_codes[name] = code\n",
    "\n",
    "print(f\"\\nTotal discovered: {len(all_codes)}\")\n",
    "print(f\"CSS codes with k>0: {len(css_codes)}\")\n",
    "\n",
    "# Categorize for smart pairing\n",
    "small_codes = {}   # n <= 10, good for inner codes\n",
    "medium_codes = {}  # 10 < n <= 30\n",
    "surface_codes = {} # Surface-like, good for outer codes\n",
    "other_codes = {}\n",
    "\n",
    "for name, code in css_codes.items():\n",
    "    n = code.n\n",
    "    if 'Surface' in name or 'Toric' in name:\n",
    "        surface_codes[name] = code\n",
    "    elif n <= 10:\n",
    "        small_codes[name] = code\n",
    "    elif n <= 30:\n",
    "        medium_codes[name] = code\n",
    "    else:\n",
    "        other_codes[name] = code\n",
    "\n",
    "print(f\"\\nBy size:\")\n",
    "print(f\"  Small (n≤10): {len(small_codes)}\")\n",
    "print(f\"  Medium (10<n≤30): {len(medium_codes)}\")\n",
    "print(f\"  Surface-like: {len(surface_codes)}\")\n",
    "print(f\"  Other: {len(other_codes)}\")\n",
    "\n",
    "\n",
    "# List codes\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"{'Code Name':<40} {'n':>4} {'k':>3} {'d':>3}\")\n",
    "print(\"-\"*70)\n",
    "for name, code in sorted(css_codes.items(), key=lambda x: x[1].n)[:20]:\n",
    "    d = code.metadata.get('distance', '?')\n",
    "    print(f\"{name:<40} {code.n:>4} {code.k:>3} {d:>3}\")\n",
    "if len(css_codes) > 20:\n",
    "    print(f\"... and {len(css_codes) - 20} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c05a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hom_results and dual_results if not defined\n",
    "if 'hom_results' not in dir():\n",
    "    hom_results = []\n",
    "if 'dual_results' not in dir():\n",
    "    dual_results = []\n",
    "\n",
    "# Also initialize codes_with_complex if needed\n",
    "if 'codes_with_complex' not in dir():\n",
    "    codes_with_complex = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eff5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting decoder smoke test results...\n",
      "    Found 11 outer codes: ['RotatedSurface_[[9,1,3]]', 'RotatedSurface_[[25,1,5]]', 'XZZX_Surface_3', 'XZZX_Surface_5']\n",
      "    Found 15 inner codes: ['FourQubit422_[[4,2,2]]', 'C6', 'Steane_713', 'Hamming_CSS_7']\n",
      "  [1/8] NO CONCATENATION...\n",
      "  [2/8] CONCATENATED CODES...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 6a: Collect Decoder Smoke Test Results (no output)\n",
    "\n",
    "This cell collects all results for composite code decoder tests.\n",
    "Results are stored in `smoke_test_results` for display in the next cell.\n",
    "\n",
    "Structure:\n",
    "1. [NO CONCATENATION] - Baseline LER for outer codes only\n",
    "2. [CONCATENATED CODES] - Should have LOWER LER than baseline\n",
    "3. [MULTI-LEVEL CONCATENATED] - Additional concatenation layer  \n",
    "4. [BASE-BEFORE-HOMOLOGICAL-PRODUCT] - Baseline for codes before tensor product\n",
    "5. [HOMOLOGICAL PRODUCT - NO METACHECKS] - Product codes without metachecks\n",
    "6. [HOMOLOGICAL PRODUCT - WITH METACHECKS] - Product codes with metachecks\n",
    "7. [5-CHAIN HOMOLOGICAL PRODUCTS] - SingleShot decoder test\n",
    "8. [DUAL CODES] - Dual code tests\n",
    "\"\"\"\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Clear qectostim modules to pick up any code fixes\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "# Re-import essential modules\n",
    "import numpy as np\n",
    "from qectostim.codes.discovery import discover_all_codes\n",
    "from qectostim.codes.composite.concatenated import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.codes.composite import HomologicalProductCode, DualCode\n",
    "from qectostim.testing import test_decoder_on_code, load_all_decoders, STATUS_OK, STATUS_WARN, STATUS_SKIP, STATUS_FAIL\n",
    "\n",
    "# Reload decoder classes and code lists\n",
    "decoder_classes = load_all_decoders()\n",
    "all_codes = discover_all_codes()\n",
    "css_codes = {n: c for n, c in all_codes.items() \n",
    "             if hasattr(c, 'hx') and hasattr(c, 'hz') and c.k > 0}\n",
    "\n",
    "# Parameters\n",
    "P_ERR = 0.005  # Error rate needs to be subthreshold\n",
    "SHOTS = 50  # Increased shots for reliable LER estimates at low error rates\n",
    "ROUNDS = 1\n",
    "\n",
    "# Storage for all results\n",
    "smoke_test_results = {\n",
    "    'params': {'p': P_ERR, 'shots': SHOTS, 'rounds': ROUNDS},\n",
    "    'decoder_names': [],\n",
    "    'sections': {},\n",
    "    'baselines': {},\n",
    "    'hom_base_lers': {},\n",
    "    'hom_no_meta_lers': {},\n",
    "}\n",
    "\n",
    "print(\"Collecting decoder smoke test results...\")\n",
    "\n",
    "if len(decoder_classes) == 0:\n",
    "    print(\"⚠️ No decoders available\")\n",
    "    smoke_test_results['decoder_names'] = []\n",
    "else:\n",
    "    # Use all available decoders (prioritize BPOSD, PyMatching)\n",
    "    primary_decoders = {}\n",
    "    for name in ['BPOSD', 'PyMatching']:\n",
    "        if name in decoder_classes:\n",
    "            primary_decoders[name] = decoder_classes[name]\n",
    "    for name, cls in decoder_classes.items():\n",
    "        if name not in primary_decoders:\n",
    "            primary_decoders[name] = cls\n",
    "    \n",
    "    decoder_names = list(primary_decoders.keys())\n",
    "    smoke_test_results['decoder_names'] = decoder_names\n",
    "    \n",
    "    def test_code_all_decoders(code, code_label, enable_metachecks=False):\n",
    "        \"\"\"Test a code with ALL decoders, return dict of results.\"\"\"\n",
    "        results = {'label': code_label, 'no_decode': None, 'decoders': {}}\n",
    "        for dec_name, dec_class in primary_decoders.items():\n",
    "            try:\n",
    "                res = test_decoder_on_code(\n",
    "                    code, dec_class, decoder_name=dec_name,\n",
    "                    code_type='CSS', p=P_ERR, shots=SHOTS, rounds=ROUNDS,\n",
    "                    enable_metachecks=enable_metachecks\n",
    "                )\n",
    "                if results['no_decode'] is None and res.ler_no_decode is not None:\n",
    "                    results['no_decode'] = res.ler_no_decode\n",
    "                results['decoders'][dec_name] = {'ler': res.ler, 'status': res.status}\n",
    "            except Exception as e:\n",
    "                results['decoders'][dec_name] = {'ler': None, 'status': 'FAIL', 'error': str(e)[:30]}\n",
    "        return results\n",
    "    \n",
    "    def get_best_ler(results):\n",
    "        \"\"\"Get best (minimum) LER from results dict.\"\"\"\n",
    "        lers = [r['ler'] for r in results['decoders'].values() if r.get('ler') is not None]\n",
    "        return min(lers) if lers else None\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Define outer/inner code pairs for concatenation tests\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Find suitable OUTER codes (surface-like, topological)\n",
    "    outer_codes = {}\n",
    "    for name, code in css_codes.items():\n",
    "        if ('Surface' in name or 'Rotated' in name) and code.n >= 9 and code.n <= 50:\n",
    "            outer_codes[name] = code\n",
    "    for name, code in css_codes.items():\n",
    "        if 'Toric' in name and code.n >= 8 and code.n <= 50 and name not in outer_codes:\n",
    "            outer_codes[name] = code\n",
    "    if len(outer_codes) < 2:\n",
    "        for name, code in sorted(css_codes.items(), key=lambda x: x[1].n):\n",
    "            if 9 <= code.n <= 30 and code.k >= 1 and name not in outer_codes:\n",
    "                outer_codes[name] = code\n",
    "                if len(outer_codes) >= 3:\n",
    "                    break\n",
    "    \n",
    "    # Find suitable INNER codes (small CSS codes)\n",
    "    inner_codes = {}\n",
    "    for name, code in css_codes.items():\n",
    "        if code.n <= 7 and code.k >= 1:\n",
    "            inner_codes[name] = code\n",
    "        if ('Surface' in name or 'Rotated' in name) and code.n >= 9 and code.n <= 50:\n",
    "            inner_codes[name] = code\n",
    "    \n",
    "    print(f\"    Found {len(outer_codes)} outer codes: {list(outer_codes.keys())[:4]}\")\n",
    "    print(f\"    Found {len(inner_codes)} inner codes: {list(inner_codes.keys())[:4]}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. [NO CONCATENATION] - Baseline outer codes\n",
    "    # =========================================================================\n",
    "    print(\"  [1/8] NO CONCATENATION...\")\n",
    "    smoke_test_results['sections']['NO_CONCAT'] = []\n",
    "    \n",
    "    for outer_name, outer_code in list(outer_codes.items())[:4]:\n",
    "        results = test_code_all_decoders(outer_code, outer_name, enable_metachecks=False)\n",
    "        best_ler = get_best_ler(results)\n",
    "        if best_ler is not None:\n",
    "            smoke_test_results['baselines'][outer_name] = best_ler\n",
    "        results['is_baseline'] = True\n",
    "        smoke_test_results['sections']['NO_CONCAT'].append(results)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. [CONCATENATED CODES] - Single-level concatenation\n",
    "    # =========================================================================\n",
    "    print(\"  [2/8] CONCATENATED CODES...\")\n",
    "    smoke_test_results['sections']['CONCAT'] = []\n",
    "    \n",
    "    max_concat = 6\n",
    "    concat_count = 0\n",
    "    for outer_name, outer_code in list(outer_codes.items())[:3]:\n",
    "        for inner_name, inner_code in list(inner_codes.items())[:3]:\n",
    "            if concat_count >= max_concat:\n",
    "                break\n",
    "            try:\n",
    "                concat = ConcatenatedTopologicalCSSCode(outer_code, inner_code)\n",
    "                code_label = f\"{outer_name}∘{inner_name}\"\n",
    "                \n",
    "                results = test_code_all_decoders(concat, code_label, enable_metachecks=False)\n",
    "                results['baseline_key'] = outer_name\n",
    "                smoke_test_results['sections']['CONCAT'].append(results)\n",
    "                concat_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                smoke_test_results['sections']['CONCAT'].append({\n",
    "                    'label': f\"{outer_name}∘{inner_name}\",\n",
    "                    'error': str(e)[:50]\n",
    "                })\n",
    "        if concat_count >= max_concat:\n",
    "            break\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. [MULTI-LEVEL CONCATENATED] - Double concatenation\n",
    "    # =========================================================================\n",
    "    print(\"  [3/8] MULTI-LEVEL CONCATENATED...\")\n",
    "    smoke_test_results['sections']['MULTI_CONCAT'] = []\n",
    "    \n",
    "    # Find a small inner code for multi-level\n",
    "    inner_422 = None\n",
    "    for name, code in css_codes.items():\n",
    "        if code.n == 4 and code.k == 2:\n",
    "            inner_422 = (name, code)\n",
    "            break\n",
    "    if inner_422 is None:\n",
    "        for name, code in sorted(css_codes.items(), key=lambda x: x[1].n):\n",
    "            if code.k >= 1 and code.n <= 7:\n",
    "                inner_422 = (name, code)\n",
    "                break\n",
    "    \n",
    "    # Find a surface-like outer code\n",
    "    outer_surface = None\n",
    "    for name, code in css_codes.items():\n",
    "        if 'Surface' in name or 'Toric' in name:\n",
    "            if code.n <= 25:\n",
    "                outer_surface = (name, code)\n",
    "                break\n",
    "    if outer_surface is None:\n",
    "        for name, code in sorted(css_codes.items(), key=lambda x: x[1].n):\n",
    "            if code.n >= 9 and code.n <= 30:\n",
    "                outer_surface = (name, code)\n",
    "                break\n",
    "    \n",
    "    if inner_422 and outer_surface:\n",
    "        inner_name, inner_code = inner_422\n",
    "        outer_name, outer_code = outer_surface\n",
    "        \n",
    "        try:\n",
    "            level1 = ConcatenatedTopologicalCSSCode(inner_code, inner_code)\n",
    "            level1_label = f\"({inner_name}∘{inner_name})\"\n",
    "            level2 = ConcatenatedTopologicalCSSCode(outer_code, level1)\n",
    "            level2_label = f\"{outer_name}∘{level1_label}\"\n",
    "            \n",
    "            results = test_code_all_decoders(level2, level2_label, enable_metachecks=False)\n",
    "            results['baseline_key'] = outer_name\n",
    "            smoke_test_results['sections']['MULTI_CONCAT'].append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['MULTI_CONCAT'].append({\n",
    "                'label': 'Multi-level concat',\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. [BASE-BEFORE-HOMOLOGICAL-PRODUCT]\n",
    "    # =========================================================================\n",
    "    print(\"  [4/8] BASE-BEFORE-HOMOLOGICAL-PRODUCT...\")\n",
    "    smoke_test_results['sections']['HOM_BASE'] = []\n",
    "    \n",
    "    codes_with_complex_local = {}\n",
    "    for name, code in css_codes.items():\n",
    "        if hasattr(code, 'chain_complex') and code.chain_complex is not None:\n",
    "            codes_with_complex_local[name] = code\n",
    "    \n",
    "    try:\n",
    "        from qectostim.codes.surface.toric_code_general import ToricCode\n",
    "        tc = ToricCode(Lx=2, Ly=2)\n",
    "        if hasattr(tc, 'chain_complex') and tc.chain_complex is not None:\n",
    "            codes_with_complex_local['ToricCode_2x2'] = tc\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for name, code in list(codes_with_complex_local.items())[:3]:\n",
    "        results = test_code_all_decoders(code, name, enable_metachecks=False)\n",
    "        best_ler = get_best_ler(results)\n",
    "        if best_ler is not None:\n",
    "            smoke_test_results['hom_base_lers'][name] = best_ler\n",
    "        results['is_baseline'] = True\n",
    "        smoke_test_results['sections']['HOM_BASE'].append(results)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. [HOMOLOGICAL PRODUCT - NO METACHECKS]\n",
    "    # =========================================================================\n",
    "    print(\"  [5/8] HOMOLOGICAL PRODUCT - NO METACHECKS...\")\n",
    "    smoke_test_results['sections']['HOM_NO_META'] = []\n",
    "    \n",
    "    complex_list = list(codes_with_complex_local.items())[:2]\n",
    "    for name_a, code_a in complex_list:\n",
    "        try:\n",
    "            product = HomologicalProductCode(code_a, code_a)\n",
    "            code_label = f\"{name_a}⊗{name_a}\"\n",
    "            \n",
    "            results = test_code_all_decoders(product, code_label, enable_metachecks=False)\n",
    "            results['baseline_key'] = name_a\n",
    "            best_ler = get_best_ler(results)\n",
    "            if best_ler is not None:\n",
    "                smoke_test_results['hom_no_meta_lers'][code_label] = best_ler\n",
    "            smoke_test_results['sections']['HOM_NO_META'].append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['HOM_NO_META'].append({\n",
    "                'label': f\"{name_a}⊗{name_a}\",\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 6. [HOMOLOGICAL PRODUCT - WITH METACHECKS]\n",
    "    # =========================================================================\n",
    "    print(\"  [6/8] HOMOLOGICAL PRODUCT - WITH METACHECKS...\")\n",
    "    smoke_test_results['sections']['HOM_META'] = []\n",
    "    \n",
    "    for name_a, code_a in complex_list:\n",
    "        try:\n",
    "            product = HomologicalProductCode(code_a, code_a)\n",
    "            code_label = f\"{name_a}⊗{name_a} (meta)\"\n",
    "            \n",
    "            results = test_code_all_decoders(product, code_label, enable_metachecks=True)\n",
    "            results['baseline_key'] = f\"{name_a}⊗{name_a}\"\n",
    "            smoke_test_results['sections']['HOM_META'].append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['HOM_META'].append({\n",
    "                'label': f\"{name_a}⊗{name_a} (meta)\",\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 7. [5-CHAIN HOMOLOGICAL PRODUCTS] - SingleShot decoder test\n",
    "    # =========================================================================\n",
    "    print(\"  [7/8] 5-CHAIN HOMOLOGICAL PRODUCTS (SingleShot test)...\")\n",
    "    smoke_test_results['sections']['HOM_5CHAIN'] = []\n",
    "    \n",
    "    five_chain_products = []\n",
    "    \n",
    "    try:\n",
    "        from qectostim.codes.surface.toric_code_general import ToricCode\n",
    "        tc_small = ToricCode(Lx=2, Ly=2)\n",
    "        if hasattr(tc_small, 'chain_complex') and tc_small.chain_complex is not None:\n",
    "            product_toric = HomologicalProductCode(tc_small, tc_small)\n",
    "            five_chain_products.append(('ToricCode_2x2⊗ToricCode_2x2', product_toric, tc_small))\n",
    "    except Exception as e:\n",
    "        print(f\"    ToricCode⊗ToricCode failed: {e}\")\n",
    "    \n",
    "    for code_label, product, base_code in five_chain_products:\n",
    "        has_meta_x = hasattr(product, 'meta_x') and product.meta_x is not None and product.meta_x.size > 0\n",
    "        has_meta_z = hasattr(product, 'meta_z') and product.meta_z is not None and product.meta_z.size > 0\n",
    "        print(f\"    {code_label}: meta_x={has_meta_x}, meta_z={has_meta_z}\")\n",
    "        \n",
    "        try:\n",
    "            results = test_code_all_decoders(product, code_label, enable_metachecks=True)\n",
    "            results['has_metachecks'] = has_meta_x or has_meta_z\n",
    "            smoke_test_results['sections']['HOM_5CHAIN'].append(results)\n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['HOM_5CHAIN'].append({\n",
    "                'label': code_label,\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 8. [DUAL CODES]\n",
    "    # =========================================================================\n",
    "    print(\"  [8/8] DUAL CODES...\")\n",
    "    smoke_test_results['sections']['DUAL'] = []\n",
    "    \n",
    "    dual_candidates = []\n",
    "    for name, code in css_codes.items():\n",
    "        if code.n <= 15 and code.k >= 1:\n",
    "            dual_candidates.append((name, code))\n",
    "    \n",
    "    for orig_name, orig_code in dual_candidates[:3]:\n",
    "        try:\n",
    "            dual = DualCode(orig_code)\n",
    "            code_label = f\"Dual({orig_name})\"\n",
    "            \n",
    "            results = test_code_all_decoders(dual, code_label, enable_metachecks=False)\n",
    "            smoke_test_results['sections']['DUAL'].append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['DUAL'].append({\n",
    "                'label': f\"Dual({orig_name})\",\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "\n",
    "print(\"\\n✓ Results collected. Run the next cell to display formatted output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd1b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "DECODER SMOKE TEST ON COMPOSITE CODES - COMPREHENSIVE COMPARISON\n",
      "========================================================================================================================\n",
      "\n",
      "Parameters: p=0.005, shots=10000, rounds=1\n",
      "Expectation: More concatenation → LOWER LER; Metachecks → LOWER LER for homological products\n",
      "\n",
      "Testing with decoders: ['BPOSD', 'PyMatching', 'FusionBlossom', 'BeliefMatching', 'Tesseract', 'UnionFind', 'MLE', 'Hypergraph', 'Chromobius', 'Concatenated', 'FlatConcat', 'HardHierarchical', 'TurboConcatenatedTurbo', 'SoftHierarchical', 'SoftMVP', 'TurboV2', 'ExtrinsicTurbo', 'SoftMP', 'SingleShot']\n",
      "\n",
      "  Code                                                     no-dec BPOSD        PyMatching   FusionBlosso BeliefMatchi Tesseract    UnionFind    MLE          Hypergraph   Chromobius   Concatenated FlatConcat   HardHierarch TurboConcate SoftHierarch SoftMVP      TurboV2      ExtrinsicTur SoftMP       SingleShot    Status\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NO CONCATENATION] - Baseline LER for outer codes\n",
      "  RotatedSurface_[[9,1,3]]                                 0.0309 0.0022       0.0026       0.0017       0.0029       0.0025       0.0024       0.0030       0.0345       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         baseline\n",
      "  RotatedSurface_[[25,1,5]]                                0.0557 0.0007       0.0005       0.0006       0.0007       0.0003       0.0002       0.0034       0.0552       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         baseline\n",
      "  XZZX_Surface_3                                           0.0337 0.0015       0.0019       0.0025       0.0024       0.0027       0.0024       0.0023       0.0352       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         baseline\n",
      "  XZZX_Surface_5                                           0.0603 0.0006       0.0006       0.0001       0.0006       0.0003       0.0005       0.0042       0.0639       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         baseline\n",
      "\n",
      "[CONCATENATED CODES] - Should have LOWER LER than outer code baseline\n",
      "  RotatedSurface_[[9,1,3]]∘FourQubit422_[[4,2,2]]          0.0853 0.0029 ▲▲!   -skip        -skip        0.0030 ▲▲!   0.0034 ▲▲!   -skip        -skip        0.0727 ▲▲!   -skip        0.0035 ▲▲!   0.0022 ▲     0.0905 ▲▲!   -skip        0.0944 ▲▲!   0.0843 ▲▲!   -skip        -skip        ✗fail        -skip         ⚠️ worse\n",
      "  RotatedSurface_[[9,1,3]]∘C6                              0.0909 0.0013 ▼     -skip        -skip        0.0028 ▲▲!   0.0015 ▼     -skip        -skip        0.0088 ▲▲!   -skip        0.0010 ▼     0.0010 ▼     0.0959 ▲▲!   -skip        0.3625 ▲▲!   0.0911 ▲▲!   -skip        -skip        ✗fail        -skip         ✓ improved\n",
      "  RotatedSurface_[[9,1,3]]∘Steane_713                      0.1476 0.0009 ▼     -skip        -skip        -skip        0.0012 ▼     -skip        -skip        0.0910 ▲▲!   -skip        0.0009 ▼     0.0012 ▼     0.1557 ▲▲!   -skip        0.3945 ▲▲!   0.1515 ▲▲!   -skip        -skip        ✗fail        -skip         ✓ improved\n",
      "  RotatedSurface_[[25,1,5]]∘FourQubit422_[[4,2,2]]         0.1374 0.0004 ▲▲!   -skip        -skip        0.0008 ▲▲!   0.0005 ▲▲!   -skip        -skip        0.1158 ▲▲!   -skip        0.0002       0.0004 ▲▲!   0.1328 ▲▲!   -skip        0.1739 ▲▲!   0.1362 ▲▲!   -skip        -skip        ✗fail        -skip         ~ similar\n",
      "  RotatedSurface_[[25,1,5]]∘C6                             0.1533 0.0001 ▼     -skip        -skip        0.0004 ▲▲!   0.0005 ▲▲!   -skip        -skip        0.0043 ▲▲!   -skip        0.0002       0.0000 ▼▼    0.1535 ▲▲!   -skip        0.4440 ▲▲!   0.1545 ▲▲!   -skip        -skip        ✗fail        -skip         ✓ MUCH better\n",
      "  RotatedSurface_[[25,1,5]]∘Steane_713                     0.2260 0.0001 ▼     -skip        -skip        -skip        0.0004 ▲▲!   -skip        -skip        0.1719 ▲▲!   -skip        0.0002       0.0003 ▲     0.2130 ▲▲!   -skip        0.4963 ▲▲!   0.2232 ▲▲!   -skip        -skip        ✗fail        -skip         ✓ improved\n",
      "\n",
      "[MULTI-LEVEL CONCATENATED] - Double concatenation (even lower LER expected)\n",
      "  RotatedSurface_[[9,1,3]]∘(FourQubit422_[[4,2,...         0.1975 0.0055 ▲▲!   -skip        -skip        -skip        0.0055 ▲▲!   -skip        -skip        0.1836 ▲▲!   -skip        0.0046 ▲▲!   0.0048 ▲▲!   0.1704 ▲▲!   -skip        0.4152 ▲▲!   0.2006 ▲▲!   -skip        -skip        ✗fail        -skip         ✗ WORSE!\n",
      "\n",
      "[BASE-BEFORE-HOMOLOGICAL-PRODUCT] - Baseline codes for tensor product\n",
      "  FourQubit422_[[4,2,2]]                                   0.0217 0.0241       0.0210       0.0223       0.0252       0.0242       0.0225       0.0225       0.0256       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         baseline\n",
      "  Steane_713                                               0.0389 0.0152       0.0252       0.0310       0.0208       0.0116       0.0277       0.0106       0.0280       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         baseline\n",
      "  Shor_91                                                  0.0982 0.0164       0.0227       0.0186       0.0182       0.0188       0.0262       0.0172       0.0627       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         baseline\n",
      "\n",
      "[HOMOLOGICAL PRODUCT - NO METACHECKS] - 4D codes without metachecks\n",
      "  FourQubit422_[[4,2,2]]⊗FourQubit422_[[4,2,2]]            0.0600 0.0045 ▼▼    -skip        -skip        -skip        0.0033 ▼▼    -skip        0.0053 ▼▼    0.0050 ▼▼    -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         ✓ MUCH better\n",
      "  Steane_713⊗Steane_713                                    0.1687 0.0011 ▼▼    -skip        -skip        -skip        0.0013 ▼▼    -skip        -skip        ✗fail        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         ✓ MUCH better\n",
      "\n",
      "[HOMOLOGICAL PRODUCT - WITH METACHECKS] - Should be BETTER than no metachecks\n",
      "  FourQubit422_[[4,2,2]]⊗FourQubit422_[[4,2,2]]...         0.0619 0.0038 ▲     -skip        -skip        -skip        0.0040 ▲     -skip        0.0060 ▲▲!   0.0045 ▲     -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        0.0038 ▲      ⚠️ worse\n",
      "  Steane_713⊗Steane_713 (meta)                             0.1647 0.0011       -skip        -skip        -skip        0.0006 ▼     -skip        -skip        ✗fail        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        0.0014 ▲      ✓ improved\n",
      "\n",
      "[5-CHAIN HOMOLOGICAL PRODUCTS] - ToricCode⊗ToricCode etc. for SingleShot decoder\n",
      "  ToricCode_2x2⊗ToricCode_2x2                              0.0950 0.0052       -skip        -skip        -skip        0.0028       -skip        -skip        ✗fail        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        0.0087        ---\n",
      "\n",
      "[DUAL CODES]\n",
      "  Dual(FourQubit422_[[4,2,2]])                             0.0215 0.0191       0.0215       0.0228       0.0206       0.0210       0.0238       0.0229       0.0224       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         ---\n",
      "  Dual(C6)                                                 0.0220 0.0209       0.0188       0.0218       0.0199       0.0208       0.0206       0.0198       0.0186       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         ---\n",
      "  Dual(Steane_713)                                         0.0386 0.0195       0.0277       0.0262       0.0200       0.0112       0.0277       0.0093       0.0284       -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip        -skip         ---\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Section                                       Avg LER      Min LER      Max LER    Count\n",
      "NO_CONCAT                                      0.0009       0.0001       0.0017        4\n",
      "CONCAT                                         0.0007       0.0000       0.0022        6\n",
      "MULTI_CONCAT                                   0.0046       0.0046       0.0046        1\n",
      "HOM_BASE                                       0.0160       0.0106       0.0210        3\n",
      "HOM_NO_META                                    0.0022       0.0011       0.0033        2\n",
      "HOM_META                                       0.0022       0.0006       0.0038        2\n",
      "HOM_5CHAIN                                     0.0028       0.0028       0.0028        1\n",
      "DUAL                                           0.0157       0.0093       0.0191        3\n",
      "\n",
      "Key Comparisons:\n",
      "  ⚠️ Concatenation: 0.0009 → 0.0007 (+16.2%)\n",
      "  ✗ Multi-concat: 0.0009 → 0.0046 (-425.7%)\n",
      "  ✗ Metachecks (hom. product): 0.0022 → 0.0022 (+0.0%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 6b: Display Decoder Smoke Test Results\n",
    "\n",
    "Formats and displays results collected in the previous cell.\n",
    "\"\"\"\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Check if results exist\n",
    "if 'smoke_test_results' not in dir() and 'smoke_test_results' not in globals():\n",
    "    print(\"⚠️ Run Cell 6a first to collect results\")\n",
    "else:\n",
    "    params = smoke_test_results['params']\n",
    "    decoder_names = smoke_test_results['decoder_names']\n",
    "    sections = smoke_test_results['sections']\n",
    "    baselines = smoke_test_results['baselines']\n",
    "    hom_base_lers = smoke_test_results['hom_base_lers']\n",
    "    hom_no_meta_lers = smoke_test_results['hom_no_meta_lers']\n",
    "    \n",
    "    def format_ler_with_arrow(ler, baseline=None):\n",
    "        \"\"\"Format LER with trend arrow if baseline provided.\"\"\"\n",
    "        if ler is None:\n",
    "            return \"✗fail\"\n",
    "        ler_str = f\"{ler:.4f}\"\n",
    "        if baseline is not None and baseline > 0:\n",
    "            if ler < baseline * 0.5:\n",
    "                return f\"{ler_str} ▼▼\"\n",
    "            elif ler < baseline * 0.9:\n",
    "                return f\"{ler_str} ▼\"\n",
    "            elif ler > baseline * 1.5:\n",
    "                return f\"{ler_str} ▲▲!\"\n",
    "            elif ler > baseline * 1.1:\n",
    "                return f\"{ler_str} ▲\"\n",
    "        return ler_str\n",
    "    \n",
    "    def get_best_ler(results):\n",
    "        \"\"\"Get best LER from results.\"\"\"\n",
    "        if 'decoders' not in results:\n",
    "            return None\n",
    "        lers = [r['ler'] for r in results['decoders'].values() if r.get('ler') is not None]\n",
    "        return min(lers) if lers else None\n",
    "    \n",
    "    # Print header\n",
    "    print(\"=\" * 120)\n",
    "    print(\"DECODER SMOKE TEST ON COMPOSITE CODES - COMPREHENSIVE COMPARISON\")\n",
    "    print(\"=\" * 120)\n",
    "    print(f\"\\nParameters: p={params['p']}, shots={params['shots']}, rounds={params['rounds']}\")\n",
    "    print(\"Expectation: More concatenation → LOWER LER; Metachecks → LOWER LER for homological products\\n\")\n",
    "    print(f\"Testing with decoders: {decoder_names}\\n\")\n",
    "    \n",
    "    # Build header row\n",
    "    col_width = 12\n",
    "    code_col_width = 50\n",
    "    header = f\"  {'Code':<{code_col_width}} {'no-dec':>{col_width}}\"\n",
    "    for dec_name in decoder_names:\n",
    "        header += f\" {dec_name[:col_width]:<{col_width}}\"\n",
    "    header += \"  Status\"\n",
    "    sep_line = \"-\" * (code_col_width + 4 + col_width + (col_width + 1) * len(decoder_names) + 15)\n",
    "    \n",
    "    print(header)\n",
    "    print(sep_line)\n",
    "    \n",
    "    # Section display info\n",
    "    section_info = [\n",
    "        ('NO_CONCAT', '[NO CONCATENATION] - Baseline LER for outer codes', None),\n",
    "        ('CONCAT', '[CONCATENATED CODES] - Should have LOWER LER than outer code baseline', 'baselines'),\n",
    "        ('MULTI_CONCAT', '[MULTI-LEVEL CONCATENATED] - Double concatenation (even lower LER expected)', 'baselines'),\n",
    "        ('HOM_BASE', '[BASE-BEFORE-HOMOLOGICAL-PRODUCT] - Baseline codes for tensor product', None),\n",
    "        ('HOM_NO_META', '[HOMOLOGICAL PRODUCT - NO METACHECKS] - 4D codes without metachecks', 'hom_base_lers'),\n",
    "        ('HOM_META', '[HOMOLOGICAL PRODUCT - WITH METACHECKS] - Should be BETTER than no metachecks', 'hom_no_meta_lers'),\n",
    "        ('HOM_5CHAIN', '[5-CHAIN HOMOLOGICAL PRODUCTS] - ToricCode⊗ToricCode etc. for SingleShot decoder', None),\n",
    "        ('DUAL', '[DUAL CODES]', None),\n",
    "    ]\n",
    "    \n",
    "    all_section_lers = {}\n",
    "    \n",
    "    for sec_key, sec_title, baseline_source in section_info:\n",
    "        if sec_key not in sections or not sections[sec_key]:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{sec_title}\")\n",
    "        all_section_lers[sec_key] = []\n",
    "        \n",
    "        for results in sections[sec_key]:\n",
    "            label = results.get('label', '???')\n",
    "            if len(label) > code_col_width - 2:\n",
    "                label = label[:code_col_width - 5] + \"...\"\n",
    "            \n",
    "            # Handle error case\n",
    "            if 'error' in results:\n",
    "                print(f\"  {label:<{code_col_width}} ERROR: {results['error']}\")\n",
    "                continue\n",
    "            \n",
    "            # Get baseline for comparison\n",
    "            baseline = None\n",
    "            if baseline_source == 'baselines':\n",
    "                baseline = baselines.get(results.get('baseline_key'))\n",
    "            elif baseline_source == 'hom_base_lers':\n",
    "                baseline = hom_base_lers.get(results.get('baseline_key'))\n",
    "            elif baseline_source == 'hom_no_meta_lers':\n",
    "                baseline = hom_no_meta_lers.get(results.get('baseline_key'))\n",
    "            \n",
    "            # No-decode column\n",
    "            no_dec = results.get('no_decode')\n",
    "            no_dec_str = f\"{no_dec:.4f}\" if no_dec is not None else \"---\"\n",
    "            \n",
    "            row = f\"  {label:<{code_col_width}} {no_dec_str:>{col_width}}\"\n",
    "            \n",
    "            # Each decoder column\n",
    "            for dec_name in decoder_names:\n",
    "                dec_res = results.get('decoders', {}).get(dec_name, {})\n",
    "                ler = dec_res.get('ler')\n",
    "                if dec_res.get('status') == 'SKIP':\n",
    "                    row += f\" {'-skip':<{col_width}}\"\n",
    "                else:\n",
    "                    ler_str = format_ler_with_arrow(ler, baseline)\n",
    "                    row += f\" {ler_str:<{col_width}}\"\n",
    "            \n",
    "            # Status column\n",
    "            best_ler = get_best_ler(results)\n",
    "            if best_ler is not None:\n",
    "                all_section_lers[sec_key].append(best_ler)\n",
    "            \n",
    "            is_baseline = results.get('is_baseline', False)\n",
    "            if is_baseline:\n",
    "                row += \"  baseline\"\n",
    "            elif baseline is not None and best_ler is not None:\n",
    "                if best_ler < baseline * 0.3:\n",
    "                    row += f\"  {STATUS_OK} MUCH better\"\n",
    "                elif best_ler < baseline * 0.7:\n",
    "                    row += f\"  {STATUS_OK} improved\"\n",
    "                elif best_ler < baseline * 0.95:\n",
    "                    row += f\"  {STATUS_OK} slightly better\"\n",
    "                elif best_ler > baseline * 1.5:\n",
    "                    row += f\"  {STATUS_FAIL} WORSE!\"\n",
    "                elif best_ler > baseline * 1.1:\n",
    "                    row += f\"  {STATUS_WARN} worse\"\n",
    "                else:\n",
    "                    row += f\"  ~ similar\"\n",
    "            else:\n",
    "                row += \"  ---\"\n",
    "            \n",
    "            print(row)\n",
    "    \n",
    "    print(sep_line)\n",
    "    \n",
    "    # SUMMARY\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\n{'Section':<40} {'Avg LER':>12} {'Min LER':>12} {'Max LER':>12} {'Count':>8}\")\n",
    "    for sec_key in ['NO_CONCAT', 'CONCAT', 'MULTI_CONCAT', 'HOM_BASE', 'HOM_NO_META', 'HOM_META', 'HOM_5CHAIN', 'DUAL']:\n",
    "        if sec_key in all_section_lers and all_section_lers[sec_key]:\n",
    "            lers = all_section_lers[sec_key]\n",
    "            avg_ler = np.mean(lers)\n",
    "            min_ler = np.min(lers)\n",
    "            max_ler = np.max(lers)\n",
    "            print(f\"{sec_key:<40} {avg_ler:>12.4f} {min_ler:>12.4f} {max_ler:>12.4f} {len(lers):>8}\")\n",
    "    \n",
    "    # Key comparisons\n",
    "    print(\"\\nKey Comparisons:\")\n",
    "    \n",
    "    if 'NO_CONCAT' in all_section_lers and 'CONCAT' in all_section_lers:\n",
    "        base_avg = np.mean(all_section_lers['NO_CONCAT'])\n",
    "        concat_avg = np.mean(all_section_lers['CONCAT'])\n",
    "        if base_avg > 0:\n",
    "            improvement = (base_avg - concat_avg) / base_avg * 100\n",
    "            status = STATUS_OK if improvement > 20 else (STATUS_WARN if improvement > 0 else STATUS_FAIL)\n",
    "            print(f\"  {status} Concatenation: {base_avg:.4f} → {concat_avg:.4f} ({improvement:+.1f}%)\")\n",
    "    \n",
    "    if 'NO_CONCAT' in all_section_lers and 'MULTI_CONCAT' in all_section_lers:\n",
    "        base_avg = np.mean(all_section_lers['NO_CONCAT'])\n",
    "        multi_avg = np.mean(all_section_lers['MULTI_CONCAT'])\n",
    "        if base_avg > 0:\n",
    "            improvement = (base_avg - multi_avg) / base_avg * 100\n",
    "            status = STATUS_OK if improvement > 40 else (STATUS_WARN if improvement > 0 else STATUS_FAIL)\n",
    "            print(f\"  {status} Multi-concat: {base_avg:.4f} → {multi_avg:.4f} ({improvement:+.1f}%)\")\n",
    "    \n",
    "    if 'HOM_NO_META' in all_section_lers and 'HOM_META' in all_section_lers:\n",
    "        no_meta_avg = np.mean(all_section_lers['HOM_NO_META'])\n",
    "        meta_avg = np.mean(all_section_lers['HOM_META'])\n",
    "        if no_meta_avg > 0:\n",
    "            improvement = (no_meta_avg - meta_avg) / no_meta_avg * 100\n",
    "            status = STATUS_OK if improvement > 10 else (STATUS_WARN if improvement > 0 else STATUS_FAIL)\n",
    "            print(f\"  {status} Metachecks (hom. product): {no_meta_avg:.4f} → {meta_avg:.4f} ({improvement:+.1f}%)\")\n",
    "        elif meta_avg == 0 and no_meta_avg == 0:\n",
    "            print(f\"  {STATUS_OK} Metachecks (hom. product): both 0.0000 (perfect)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde1d9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DIAGNOSTIC: Testing hierarchical decoders on concatenated code\n",
      "======================================================================\n",
      "\n",
      "Code: Concatenated(RotatedSurfaceCode, SteaneCode713)\n",
      "  Inner: n=7, k=1, hx=(3, 7), hz=(3, 7)\n",
      "  Outer: n=9, k=1\n",
      "  Total: n=63, k=1\n",
      "\n",
      "Loaded 19 decoders: ['PyMatching', 'FusionBlossom', 'BeliefMatching', 'BPOSD', 'Tesseract', 'UnionFind', 'MLE', 'Hypergraph', 'Chromobius', 'Concatenated', 'FlatConcat', 'HardHierarchical', 'TurboConcatenatedTurbo', 'SoftHierarchical', 'SoftMVP', 'TurboV2', 'ExtrinsicTurbo', 'SoftMP', 'SingleShot']\n",
      "\n",
      "Testing on: Concatenated(RotatedSurfaceCode, SteaneCode713)\n",
      "Parameters: p=0.005, shots=1000, rounds=1\n",
      "----------------------------------------------------------------------\n",
      "  BPOSD: ✓ OK\n",
      "    LER: 0.0030\n",
      "    Warning: DEM has hyperedges (4D+ code)\n",
      "  BeliefMatching: ✗ SKIP\n",
      "    Warning: DEM has hyperedges (4D+ code)\n",
      "    Warning: BeliefMatching: BP incompatible with code structure\n",
      "    Error: Hyperedge incompatible\n",
      "  TurboV2: ✓ OK\n",
      "    LER: 0.1590\n",
      "    Warning: DEM has hyperedges (4D+ code)\n",
      "  ExtrinsicTurbo: ✓ OK\n",
      "    LER: 0.1470\n",
      "    Warning: DEM has hyperedges (4D+ code)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottjones_admin/Library/Mobile Documents/com~apple~CloudDocs/Mac files/Repos/QECToStim/src/qectostim/decoders/soft_hierarchical_decoder.py:190: UserWarning: SoftHierarchicalDecoder: DEM has 1 observables, expected 10 (1 main + 9 inner blocks). Using code-based soft information estimation (may be less accurate).\n",
      "  warnings.warn(\n",
      "/Users/scottjones_admin/Library/Mobile Documents/com~apple~CloudDocs/Mac files/Repos/QECToStim/my_venv/lib/python3.11/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SoftHierarchical: ✓ OK\n",
      "    LER: 0.2920\n",
      "    Warning: DEM has hyperedges (4D+ code)\n",
      "  SoftMP: ✓ OK\n",
      "    LER: 0.1540\n",
      "    Warning: DEM has hyperedges (4D+ code)\n",
      "  HardHierarchical: ✓ OK\n",
      "    LER: 0.1050\n",
      "    Warning: DEM has hyperedges (4D+ code)\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "BPOSD baseline: 0.0030\n",
      "\n",
      "Relative to BPOSD:\n",
      "  ✗ TurboV2: 0.1590 (53.0x BPOSD)\n",
      "  ✗ ExtrinsicTurbo: 0.1470 (49.0x BPOSD)\n",
      "  ✗ SoftHierarchical: 0.2920 (97.3x BPOSD)\n",
      "  ✗ SoftMP: 0.1540 (51.3x BPOSD)\n",
      "  ✗ HardHierarchical: 0.1050 (35.0x BPOSD)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottjones_admin/Library/Mobile Documents/com~apple~CloudDocs/Mac files/Repos/QECToStim/src/qectostim/decoders/hard_hierarchical_decoder.py:229: UserWarning: HierarchicalConcatenatedDecoder: DEM has 1 observables, expected 10 (1 main + 9 inner blocks). Inner code type: SteaneCode713, Multi-level: False\n",
      "  warnings.warn(\n",
      "/Users/scottjones_admin/Library/Mobile Documents/com~apple~CloudDocs/Mac files/Repos/QECToStim/src/qectostim/decoders/hard_hierarchical_decoder.py:492: UserWarning: HierarchicalConcatenatedDecoder: Using pre-calculated P_logical = 0.0220 for outer decoder edge weights. This is a hard hierarchical approach.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 7: Test hierarchical decoders via testing_utils framework\"\"\"\n",
    "import sys\n",
    "# Clear cached modules to pick up fixes\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "import numpy as np\n",
    "from qectostim.codes.surface.rotated_surface import RotatedSurfaceCode\n",
    "from qectostim.codes.small.four_two_two import FourQubit422Code\n",
    "from qectostim.codes.small.steane_713 import SteaneCode713\n",
    "from qectostim.codes.composite.concatenated import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.testing import test_decoder_on_code, load_all_decoders\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DIAGNOSTIC: Testing hierarchical decoders on concatenated code\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Build the code\n",
    "inner = SteaneCode713()\n",
    "outer = RotatedSurfaceCode(distance=3)  # Smaller for faster testing\n",
    "concat = ConcatenatedTopologicalCSSCode(outer=outer, inner=inner)\n",
    "\n",
    "print(f\"\\nCode: {concat.name}\")\n",
    "print(f\"  Inner: n={inner.n}, k={inner.k}, hx={inner.hx.shape}, hz={inner.hz.shape}\")\n",
    "print(f\"  Outer: n={outer.n}, k={outer.k}\")\n",
    "print(f\"  Total: n={concat.n}, k={concat.k}\")\n",
    "\n",
    "# Test parameters\n",
    "P_ERR = 0.005\n",
    "SHOTS = 1000\n",
    "ROUNDS = 1\n",
    "\n",
    "# Load all decoders\n",
    "decoder_classes = load_all_decoders()\n",
    "print(f\"\\nLoaded {len(decoder_classes)} decoders: {list(decoder_classes.keys())}\")\n",
    "\n",
    "# Test the hierarchical decoders + baselines\n",
    "decoders_to_test = ['BPOSD', 'BeliefMatching', 'TurboV2', 'ExtrinsicTurbo', 'SoftHierarchical', 'SoftMP', 'HardHierarchical']\n",
    "\n",
    "print(f\"\\nTesting on: {concat.name}\")\n",
    "print(f\"Parameters: p={P_ERR}, shots={SHOTS}, rounds={ROUNDS}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "results_summary = {}\n",
    "for dec_name in decoders_to_test:\n",
    "    if dec_name not in decoder_classes:\n",
    "        print(f\"  {dec_name}: NOT LOADED\")\n",
    "        continue\n",
    "    \n",
    "    dec_class = decoder_classes[dec_name]\n",
    "    result = test_decoder_on_code(\n",
    "        code=concat, \n",
    "        decoder_class=dec_class,\n",
    "        decoder_name=dec_name,\n",
    "        p=P_ERR, \n",
    "        shots=SHOTS, \n",
    "        rounds=ROUNDS\n",
    "    )\n",
    "    \n",
    "    status_icon = \"✓\" if result.status == \"OK\" else (\"⚠\" if result.status == \"WARN\" else \"✗\")\n",
    "    print(f\"  {dec_name}: {status_icon} {result.status}\")\n",
    "    if result.ler is not None:\n",
    "        print(f\"    LER: {result.ler:.4f}\")\n",
    "        results_summary[dec_name] = result.ler\n",
    "    if result.warnings:\n",
    "        for w in result.warnings[:2]:  # Limit warnings\n",
    "            print(f\"    Warning: {w[:80]}\")\n",
    "    if result.error:\n",
    "        print(f\"    Error: {result.error[:80]}\")\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "if 'BPOSD' in results_summary:\n",
    "    bposd_ler = results_summary['BPOSD']\n",
    "    print(f\"BPOSD baseline: {bposd_ler:.4f}\")\n",
    "    print(\"\\nRelative to BPOSD:\")\n",
    "    for name, ler in results_summary.items():\n",
    "        if name != 'BPOSD':\n",
    "            ratio = ler / bposd_ler if bposd_ler > 0 else float('inf')\n",
    "            status = \"✓\" if ratio < 2 else (\"⚠\" if ratio < 10 else \"✗\")\n",
    "            print(f\"  {status} {name}: {ler:.4f} ({ratio:.1f}x BPOSD)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee335fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Testing TurboV2 and ExtrinsicTurbo directly\n",
      "======================================================================\n",
      "\n",
      "Code: Concatenated(RotatedSurfaceCode, FourQubit422Code)\n",
      "  n=36, k=10\n",
      "\n",
      "--- Testing TurboV2 ---\n",
      "  Status: OK\n",
      "  LER: 0.0840\n",
      "\n",
      "--- Testing ExtrinsicTurbo ---\n",
      "  Status: OK\n",
      "  LER: 0.0940\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 8: Debug and test TurboV2/ExtrinsicTurbo directly\"\"\"\n",
    "import sys\n",
    "# Clear cached modules\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "import numpy as np\n",
    "from qectostim.codes.surface.rotated_surface import RotatedSurfaceCode\n",
    "from qectostim.codes.small.four_two_two import FourQubit422Code\n",
    "from qectostim.codes.composite.concatenated import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.testing import test_decoder_on_code\n",
    "from qectostim.decoders.turbo_decoder_v2 import TurboDecoderV2\n",
    "from qectostim.decoders.extrinsic_turbo_decoder import ExtrinsicTurboDecoder\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Testing TurboV2 and ExtrinsicTurbo directly\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Build the code\n",
    "inner = FourQubit422Code()\n",
    "outer = RotatedSurfaceCode(distance=3)\n",
    "concat = ConcatenatedTopologicalCSSCode(outer=outer, inner=inner)\n",
    "\n",
    "print(f\"\\nCode: {concat.name}\")\n",
    "print(f\"  n={concat.n}, k={concat.k}\")\n",
    "\n",
    "# Test parameters\n",
    "P_ERR = 0.005\n",
    "SHOTS = 1000\n",
    "ROUNDS = 1\n",
    "\n",
    "# Direct test of TurboV2 \n",
    "print(\"\\n--- Testing TurboV2 ---\")\n",
    "result = test_decoder_on_code(\n",
    "    code=concat, \n",
    "    decoder_class=TurboDecoderV2,\n",
    "    decoder_name='TurboV2',\n",
    "    p=P_ERR, \n",
    "    shots=SHOTS, \n",
    "    rounds=ROUNDS\n",
    ")\n",
    "print(f\"  Status: {result.status}\")\n",
    "if result.ler is not None:\n",
    "    print(f\"  LER: {result.ler:.4f}\")\n",
    "if result.error:\n",
    "    print(f\"  Error: {result.error}\")\n",
    "if result.warnings:\n",
    "    for w in result.warnings[:3]:\n",
    "        print(f\"  Warning: {w[:100]}\")\n",
    "\n",
    "# Direct test of ExtrinsicTurbo\n",
    "print(\"\\n--- Testing ExtrinsicTurbo ---\")\n",
    "result = test_decoder_on_code(\n",
    "    code=concat, \n",
    "    decoder_class=ExtrinsicTurboDecoder,\n",
    "    decoder_name='ExtrinsicTurbo',\n",
    "    p=P_ERR, \n",
    "    shots=SHOTS, \n",
    "    rounds=ROUNDS\n",
    ")\n",
    "print(f\"  Status: {result.status}\")\n",
    "if result.ler is not None:\n",
    "    print(f\"  LER: {result.ler:.4f}\")\n",
    "if result.error:\n",
    "    print(f\"  Error: {result.error}\")\n",
    "if result.warnings:\n",
    "    for w in result.warnings[:3]:\n",
    "        print(f\"  Warning: {w[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bcbe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPARISON: SoftMP vs BPOSD at different error rates\n",
      "======================================================================\n",
      "\n",
      "Code: Concatenated(RotatedSurfaceCode, FourQubit422Code)\n",
      "  [[36, 10]]\n",
      "\n",
      "Testing with shots=2000, rounds=1\n",
      "----------------------------------------------------------------------\n",
      "       p |      BPOSD |     SoftMP |    Ratio\n",
      "----------------------------------------------------------------------\n",
      "   0.001 |     0.0000 |     0.0180 |        ∞\n",
      "   0.003 |     0.0010 |     0.0605 |    60.5x\n",
      "   0.005 |     0.0025 |     0.1135 |    45.4x\n",
      "   0.010 |     0.0110 |     0.1695 |    15.4x\n",
      "   0.020 |     0.0535 |     0.3220 |     6.0x\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 9: Compare test_decoder_on_code results at different error rates\"\"\"\n",
    "import sys\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "import numpy as np\n",
    "from qectostim.codes.surface.rotated_surface import RotatedSurfaceCode\n",
    "from qectostim.codes.small.four_two_two import FourQubit422Code\n",
    "from qectostim.codes.composite.concatenated import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.testing import test_decoder_on_code\n",
    "from qectostim.decoders.soft_message_passing_decoder import SoftMessagePassingDecoder\n",
    "from qectostim.decoders.bp_osd import BPOSDDecoder\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPARISON: SoftMP vs BPOSD at different error rates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Build the code\n",
    "inner = FourQubit422Code()\n",
    "outer = RotatedSurfaceCode(distance=3)\n",
    "concat = ConcatenatedTopologicalCSSCode(outer=outer, inner=inner)\n",
    "\n",
    "print(f\"\\nCode: {concat.name}\")\n",
    "print(f\"  [[{concat.n}, {concat.k}]]\")\n",
    "\n",
    "# Test at multiple error rates\n",
    "SHOTS = 2000\n",
    "ROUNDS = 1\n",
    "\n",
    "print(f\"\\nTesting with shots={SHOTS}, rounds={ROUNDS}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'p':>8} | {'BPOSD':>10} | {'SoftMP':>10} | {'Ratio':>8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for p in [0.001, 0.003, 0.005, 0.01, 0.02]:\n",
    "    # Test BPOSD\n",
    "    bposd_result = test_decoder_on_code(\n",
    "        code=concat, decoder_class=BPOSDDecoder, decoder_name='BPOSD',\n",
    "        p=p, shots=SHOTS, rounds=ROUNDS\n",
    "    )\n",
    "    \n",
    "    # Test SoftMP\n",
    "    softmp_result = test_decoder_on_code(\n",
    "        code=concat, decoder_class=SoftMessagePassingDecoder, decoder_name='SoftMP',\n",
    "        p=p, shots=SHOTS, rounds=ROUNDS\n",
    "    )\n",
    "    \n",
    "    bposd_ler = bposd_result.ler if bposd_result.ler is not None else float('nan')\n",
    "    softmp_ler = softmp_result.ler if softmp_result.ler is not None else float('nan')\n",
    "    \n",
    "    if bposd_ler > 0 and softmp_ler > 0:\n",
    "        ratio = softmp_ler / bposd_ler\n",
    "        ratio_str = f\"{ratio:.1f}x\"\n",
    "    elif bposd_ler == 0 and softmp_ler == 0:\n",
    "        ratio_str = \"both 0\"\n",
    "    elif bposd_ler == 0:\n",
    "        ratio_str = \"∞\"\n",
    "    else:\n",
    "        ratio_str = \"n/a\"\n",
    "    \n",
    "    print(f\"{p:>8.3f} | {bposd_ler:>10.4f} | {softmp_ler:>10.4f} | {ratio_str:>8}\")\n",
    "\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66567600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DIAGNOSIS: Why does SoftMP fail?\n",
      "======================================================================\n",
      "\n",
      "Code: [[36, 10]]\n",
      "DEM: 26 detectors, 1 observables\n",
      "Blocks: 9, dets_per_block: 2\n",
      "\n",
      "Inner logical operators in decoder:\n",
      "  inner_lz: [1 0 1 0]\n",
      "  inner_lx: [1 1 0 0]\n",
      "\n",
      "Sampled 500 shots, 0 with nonzero syndrome\n",
      "SoftMP errors: 0/500 = 0.0%\n",
      "\n",
      "======================================================================\n",
      "ANALYZING SOFT INFO COMPUTATION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHT: The [[4,2,2]] inner code problem\n",
      "======================================================================\n",
      "\n",
      "The [[4,2,2]] code has:\n",
      "  - 4 physical qubits\n",
      "  - 2 logical qubits (k=2)\n",
      "  - Distance 2\n",
      "\n",
      "The problem: We're encoding a SINGLE outer qubit into k=2 inner logical qubits.\n",
      "The decoder doesn't know which of the 2 inner logicals corresponds to the outer qubit!\n",
      "\n",
      "For Z-basis decoding:\n",
      "  - Inner code has 1 Z-stabilizer\n",
      "  - Inner code has 2 logical Z operators (lz1, lz2)\n",
      "  - The decoder needs to track errors on the correct logical qubit\n",
      "\n",
      "If decoder.inner_lz = [1 0 1 0]\n",
      "This means it's tracking errors on physical qubits [0 2]\n",
      "\n",
      "For a [[4,2,2]] code, the logical Z operators should be on disjoint qubit pairs.\n",
      "If we're tracking the WRONG logical operator, we'll decode incorrectly 50% of the time!\n",
      "\n",
      "\n",
      "Actual inner logical Z support:\n",
      "  decoder.inner_lz: [1 0 1 0]\n",
      "\n",
      "Inner code hx: [[1 1 1 1]]\n",
      "Inner code hz: [[1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 10: Diagnose WHY SoftMP fails - look at soft info computation\"\"\"\n",
    "import sys\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "import numpy as np\n",
    "from qectostim.codes.surface.rotated_surface import RotatedSurfaceCode\n",
    "from qectostim.codes.small.four_two_two import FourQubit422Code\n",
    "from qectostim.codes.composite.concatenated import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.experiments.memory import CSSMemoryExperiment\n",
    "from qectostim.noise.models import CircuitDepolarizingNoise\n",
    "from qectostim.decoders.soft_message_passing_decoder import SoftMessagePassingDecoder\n",
    "from qectostim.decoders.block_extraction import BlockExtractor, collapse_block_syndrome\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DIAGNOSIS: Why does SoftMP fail?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Build the code\n",
    "inner = FourQubit422Code()\n",
    "outer = RotatedSurfaceCode(distance=3)\n",
    "concat = ConcatenatedTopologicalCSSCode(outer=outer, inner=inner)\n",
    "\n",
    "# Generate circuit and DEM\n",
    "noise = CircuitDepolarizingNoise(p1=0.01, p2=0.01)\n",
    "exp = CSSMemoryExperiment(code=concat, rounds=1, noise_model=noise)\n",
    "circuit = exp.to_stim()\n",
    "dem = circuit.detector_error_model()\n",
    "\n",
    "# Create decoder\n",
    "decoder = SoftMessagePassingDecoder(concat, dem, rounds=1, basis=\"Z\")\n",
    "\n",
    "print(f\"\\nCode: [[{concat.n}, {concat.k}]]\")\n",
    "print(f\"DEM: {dem.num_detectors} detectors, {dem.num_observables} observables\")\n",
    "print(f\"Blocks: {decoder.n_blocks}, dets_per_block: {decoder.dets_per_block}\")\n",
    "\n",
    "# Check inner logical operators\n",
    "print(f\"\\nInner logical operators in decoder:\")\n",
    "print(f\"  inner_lz: {decoder.inner_lz}\")\n",
    "print(f\"  inner_lx: {decoder.inner_lx}\")\n",
    "\n",
    "# Sample\n",
    "sampler = circuit.compile_detector_sampler()\n",
    "samples, obs = sampler.sample(shots=500, separate_observables=True)\n",
    "nonzero_mask = np.sum(samples, axis=1) > 0\n",
    "print(f\"\\nSampled 500 shots, {np.sum(nonzero_mask)} with nonzero syndrome\")\n",
    "\n",
    "# Decode and find errors\n",
    "preds = decoder.decode_batch(samples)\n",
    "wrong = (preds[:, 0] != obs[:, 0])\n",
    "print(f\"SoftMP errors: {np.sum(wrong)}/{len(samples)} = {np.sum(wrong)/len(samples)*100:.1f}%\")\n",
    "\n",
    "# Analyze the SOFT INFO computation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYZING SOFT INFO COMPUTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# The key question: How does SoftMP compute P(logical_error | syndrome)?\n",
    "# It does:\n",
    "# 1. For each block: collapse detector syndrome to stabilizer syndrome\n",
    "# 2. Compute soft info for block's logical error\n",
    "# 3. Combine soft info across blocks using outer code structure\n",
    "\n",
    "# Let's trace a specific error case\n",
    "fail_indices = np.where(wrong)[0]\n",
    "if len(fail_indices) > 0:\n",
    "    idx = fail_indices[0]\n",
    "    syn = samples[idx]\n",
    "    true_obs = obs[idx, 0]\n",
    "    pred_obs = preds[idx, 0]\n",
    "    \n",
    "    print(f\"\\nAnalyzing failing shot {idx}:\")\n",
    "    print(f\"  True observable: {true_obs}\")\n",
    "    print(f\"  SoftMP prediction: {pred_obs}\")\n",
    "    print(f\"  Total syndrome weight: {np.sum(syn)}\")\n",
    "    \n",
    "    # Show active blocks\n",
    "    print(f\"\\n  Active blocks:\")\n",
    "    for blk in range(decoder.n_blocks):\n",
    "        det_start, det_stop = decoder.inner_slices[blk]\n",
    "        block_syn = syn[det_start:det_stop]\n",
    "        if np.sum(block_syn) > 0:\n",
    "            stab_syn = collapse_block_syndrome(\n",
    "                block_syn, decoder.n_inner_x_checks, decoder.n_inner_z_checks, 1, \"Z\"\n",
    "            )\n",
    "            print(f\"    Block {blk}: det={block_syn}, stab={stab_syn}\")\n",
    "    \n",
    "    # Show outer syndrome\n",
    "    outer_start, outer_end = decoder.outer_slice\n",
    "    outer_syn = syn[outer_start:outer_end]\n",
    "    print(f\"  Outer syndrome: weight={np.sum(outer_syn)}\")\n",
    "\n",
    "# KEY INSIGHT: What's the [[4,2,2]] inner code doing?\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHT: The [[4,2,2]] inner code problem\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "The [[4,2,2]] code has:\n",
    "  - 4 physical qubits\n",
    "  - 2 logical qubits (k=2)\n",
    "  - Distance 2\n",
    "\n",
    "The problem: We're encoding a SINGLE outer qubit into k=2 inner logical qubits.\n",
    "The decoder doesn't know which of the 2 inner logicals corresponds to the outer qubit!\n",
    "\n",
    "For Z-basis decoding:\n",
    "  - Inner code has 1 Z-stabilizer\n",
    "  - Inner code has 2 logical Z operators (lz1, lz2)\n",
    "  - The decoder needs to track errors on the correct logical qubit\n",
    "  \n",
    "If decoder.inner_lz = {decoder.inner_lz}\n",
    "This means it's tracking errors on physical qubits {np.where(decoder.inner_lz)[0] if decoder.inner_lz is not None else 'None'}\n",
    "\n",
    "For a [[4,2,2]] code, the logical Z operators should be on disjoint qubit pairs.\n",
    "If we're tracking the WRONG logical operator, we'll decode incorrectly 50% of the time!\n",
    "\"\"\")\n",
    "\n",
    "# Check what inner_lz actually is\n",
    "print(f\"\\nActual inner logical Z support:\")\n",
    "print(f\"  decoder.inner_lz: {decoder.inner_lz}\")\n",
    "\n",
    "# This should be the logical Z of the inner code restricted to one of its k logical qubits\n",
    "# For [[4,2,2]], typical lz = [[1,1,0,0], [0,0,1,1]]\n",
    "print(f\"\\nInner code hx: {inner.hx}\")\n",
    "print(f\"Inner code hz: {inner.hz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2122d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HYPOTHESIS: k=1 inner codes should match BPOSD, k=2 should be worse\n",
      "(v2: with string-format logical operator fix)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Testing: FourQubit422 [[4,2,2]] k=2\n",
      "Inner code: n=4, k=2, d=2\n",
      "======================================================================\n",
      "Concatenated code: [[36, 10]]\n",
      "  BPOSD:  LER = 0.0115\n",
      "  SoftMP: LER = 0.1840\n",
      "  Ratio (SoftMP/BPOSD): 16.0x\n",
      "\n",
      "======================================================================\n",
      "Testing: RepetitionCode [[3,1,3]] k=1\n",
      "Inner code: n=3, k=1, d=3\n",
      "======================================================================\n",
      "Concatenated code: [[27, 1]]\n",
      "  BPOSD:  LER = 0.0010\n",
      "  SoftMP: LER = 0.1215\n",
      "  Ratio (SoftMP/BPOSD): 121.5x\n",
      "\n",
      "======================================================================\n",
      "Testing: SteaneCode [[7,1,3]] k=1\n",
      "Inner code: n=7, k=1, d=3\n",
      "======================================================================\n",
      "Concatenated code: [[63, 1]]\n",
      "  BPOSD:  LER = 0.0055\n",
      "  SoftMP: LER = 0.2525\n",
      "  Ratio (SoftMP/BPOSD): 45.9x\n",
      "\n",
      "======================================================================\n",
      "SUMMARY: Does k=1 perform better than k=2?\n",
      "======================================================================\n",
      "Inner Code                            k    BPOSD   SoftMP    Ratio\n",
      "----------------------------------------------------------------------\n",
      "FourQubit422 [[4,2,2]] k=2            2   0.0115   0.1840    16.0x\n",
      "RepetitionCode [[3,1,3]] k=1          1   0.0010   0.1215   121.5x\n",
      "SteaneCode [[7,1,3]] k=1               1   0.0055   0.2525    45.9x\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS:\n",
      "======================================================================\n",
      "Average ratio for k=1 codes: 83.7x\n",
      "Average ratio for k=2 codes: 16.0x\n",
      "✗ HYPOTHESIS REJECTED: k=1 does not significantly outperform k=2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HYPOTHESIS TEST (v2): k=1 vs k=2 inner codes\n",
    "=============================================\n",
    "After fixing string-format logical operator parsing.\n",
    "\n",
    "Theory: Hierarchical decoders should work well for k=1 inner codes but\n",
    "poorly for k>1 inner codes due to ambiguity in which logical qubit was corrupted.\n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Reload modules to get fresh state (picks up fix to _get_logical_support)\n",
    "modules_to_clear = [m for m in sys.modules if 'qectostim' in m]\n",
    "for m in modules_to_clear:\n",
    "    del sys.modules[m]\n",
    "\n",
    "from qectostim.codes.composite import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.codes.surface import RotatedSurfaceCode\n",
    "from qectostim.codes.small import FourQubit422Code, RepetitionCode, SteaneCode713\n",
    "from qectostim.decoders import BPOSDDecoder\n",
    "from qectostim.decoders.soft_message_passing_decoder import SoftMessagePassingDecoder\n",
    "from qectostim.testing import test_decoder_on_code\n",
    "\n",
    "# Test parameters\n",
    "P_ERR = 0.01\n",
    "SHOTS = 2000\n",
    "ROUNDS = 1\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HYPOTHESIS: k=1 inner codes should match BPOSD, k=2 should be worse\")\n",
    "print(\"(v2: with string-format logical operator fix)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "outer = RotatedSurfaceCode(distance=3)\n",
    "inner_codes = {\n",
    "    \"FourQubit422 [[4,2,2]] k=2\": FourQubit422Code(),\n",
    "    \"RepetitionCode [[3,1,3]] k=1\": RepetitionCode(N=3),\n",
    "    \"SteaneCode [[7,1,3]] k=1\": SteaneCode713(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, inner in inner_codes.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing: {name}\")\n",
    "    print(f\"Inner code: n={inner.n}, k={inner.k}, d={inner.distance if hasattr(inner, 'distance') else '?'}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Build concatenated code\n",
    "    try:\n",
    "        concat = ConcatenatedTopologicalCSSCode(outer, inner)\n",
    "        print(f\"Concatenated code: [[{concat.n}, {concat.k}]]\")\n",
    "    except Exception as e:\n",
    "        print(f\"  FAILED to build concatenated code: {e}\")\n",
    "        results[name] = {\"bposd\": None, \"softmp\": None, \"ratio\": None, \"k\": inner.k}\n",
    "        continue\n",
    "    \n",
    "    # Test BPOSD (baseline)\n",
    "    try:\n",
    "        bposd_result = test_decoder_on_code(\n",
    "            code=concat, decoder_class=BPOSDDecoder, decoder_name='BPOSD',\n",
    "            p=P_ERR, shots=SHOTS, rounds=ROUNDS\n",
    "        )\n",
    "        bposd_ler = bposd_result.ler if bposd_result.ler is not None else float('nan')\n",
    "        print(f\"  BPOSD:  LER = {bposd_ler:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  BPOSD:  FAILED - {e}\")\n",
    "        bposd_ler = None\n",
    "    \n",
    "    # Test SoftMP hierarchical decoder\n",
    "    try:\n",
    "        softmp_result = test_decoder_on_code(\n",
    "            code=concat, decoder_class=SoftMessagePassingDecoder, decoder_name='SoftMP',\n",
    "            p=P_ERR, shots=SHOTS, rounds=ROUNDS\n",
    "        )\n",
    "        softmp_ler = softmp_result.ler if softmp_result.ler is not None else float('nan')\n",
    "        print(f\"  SoftMP: LER = {softmp_ler:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  SoftMP: FAILED - {e}\")\n",
    "        softmp_ler = None\n",
    "    \n",
    "    # Calculate ratio\n",
    "    if bposd_ler is not None and softmp_ler is not None and bposd_ler > 0:\n",
    "        ratio = softmp_ler / bposd_ler\n",
    "        print(f\"  Ratio (SoftMP/BPOSD): {ratio:.1f}x\")\n",
    "    elif bposd_ler == 0:\n",
    "        ratio = float('inf') if softmp_ler > 0 else 1.0\n",
    "        print(f\"  Ratio: BPOSD=0, SoftMP={softmp_ler:.4f if softmp_ler else 'N/A'}\")\n",
    "    else:\n",
    "        ratio = None\n",
    "    \n",
    "    results[name] = {\n",
    "        \"bposd\": bposd_ler,\n",
    "        \"softmp\": softmp_ler,\n",
    "        \"ratio\": ratio,\n",
    "        \"k\": inner.k\n",
    "    }\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY: Does k=1 perform better than k=2?\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Inner Code':<35} {'k':>3} {'BPOSD':>8} {'SoftMP':>8} {'Ratio':>8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, data in results.items():\n",
    "    bposd_str = f\"{data['bposd']:.4f}\" if data['bposd'] is not None and not np.isnan(data['bposd']) else \"FAIL\"\n",
    "    softmp_str = f\"{data['softmp']:.4f}\" if data['softmp'] is not None and not np.isnan(data['softmp']) else \"FAIL\"\n",
    "    ratio_str = f\"{data['ratio']:.1f}x\" if data['ratio'] is not None and data['ratio'] != float('inf') else \"N/A\"\n",
    "    print(f\"{name:<35} {data['k']:>3} {bposd_str:>8} {softmp_str:>8} {ratio_str:>8}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYSIS:\")\n",
    "print(\"=\" * 70)\n",
    "k1_ratios = [d['ratio'] for n, d in results.items() if d['k'] == 1 and d['ratio'] is not None and d['ratio'] != float('inf')]\n",
    "k2_ratios = [d['ratio'] for n, d in results.items() if d['k'] == 2 and d['ratio'] is not None and d['ratio'] != float('inf')]\n",
    "\n",
    "if k1_ratios:\n",
    "    avg_k1 = np.mean(k1_ratios)\n",
    "    print(f\"Average ratio for k=1 codes: {avg_k1:.1f}x\")\n",
    "if k2_ratios:\n",
    "    avg_k2 = np.mean(k2_ratios)\n",
    "    print(f\"Average ratio for k=2 codes: {avg_k2:.1f}x\")\n",
    "\n",
    "if k1_ratios and k2_ratios:\n",
    "    if avg_k1 < avg_k2 / 2:\n",
    "        print(\"✓ HYPOTHESIS CONFIRMED: k=1 inner codes perform significantly better!\")\n",
    "    else:\n",
    "        print(\"✗ HYPOTHESIS REJECTED: k=1 does not significantly outperform k=2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956d303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOGICAL OPERATOR STRUCTURE FOR INNER CODES\n",
      "======================================================================\n",
      "\n",
      "FourQubit422 [[4,2,2]] k=2\n",
      "--------------------------------------------------\n",
      "  n=4, k=2\n",
      "  logical_z_ops: [{0: 'Z', 2: 'Z'}, {1: 'Z', 3: 'Z'}]\n",
      "  logical_x_ops: [{0: 'X', 1: 'X'}, {1: 'X', 2: 'X'}]\n",
      "  logical_z (matrix): NOT FOUND\n",
      "  logical_x (matrix): NOT FOUND\n",
      "  metadata['logical_z_support']: [0, 2]\n",
      "  metadata['logical_x_support']: [0, 1]\n",
      "\n",
      "RepetitionCode [[3,1,3]] k=1\n",
      "--------------------------------------------------\n",
      "  n=3, k=1\n",
      "  logical_z_ops: ['ZII']\n",
      "  logical_x_ops: ['XXX']\n",
      "  logical_z (matrix): NOT FOUND\n",
      "  logical_x (matrix): NOT FOUND\n",
      "\n",
      "SteaneCode [[7,1,3]] k=1\n",
      "--------------------------------------------------\n",
      "  n=7, k=1\n",
      "  logical_z_ops: ['ZZZIIII']\n",
      "  logical_x_ops: ['XXXIIII']\n",
      "  logical_z (matrix): NOT FOUND\n",
      "  logical_x (matrix): NOT FOUND\n",
      "  metadata['logical_z_support']: [0, 1, 2]\n",
      "  metadata['logical_x_support']: [0, 1, 2]\n",
      "\n",
      "======================================================================\n",
      "CONCLUSION: Which logical format does each code use?\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Investigate the logical operators for all test codes\"\"\"\n",
    "print(\"=\" * 70)\n",
    "print(\"LOGICAL OPERATOR STRUCTURE FOR INNER CODES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, inner in inner_codes.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"  n={inner.n}, k={inner.k}\")\n",
    "    \n",
    "    # Check logical_z_ops attribute (dict format)\n",
    "    if hasattr(inner, 'logical_z_ops'):\n",
    "        print(f\"  logical_z_ops: {inner.logical_z_ops}\")\n",
    "    else:\n",
    "        print(f\"  logical_z_ops: NOT FOUND\")\n",
    "    \n",
    "    # Check logical_x_ops attribute (dict format)\n",
    "    if hasattr(inner, 'logical_x_ops'):\n",
    "        print(f\"  logical_x_ops: {inner.logical_x_ops}\")\n",
    "    else:\n",
    "        print(f\"  logical_x_ops: NOT FOUND\")\n",
    "    \n",
    "    # Check logical_z (matrix form)\n",
    "    if hasattr(inner, 'logical_z') and inner.logical_z is not None:\n",
    "        lz = np.array(inner.logical_z)\n",
    "        print(f\"  logical_z (matrix): shape={lz.shape}\")\n",
    "        print(f\"    {lz}\")\n",
    "    else:\n",
    "        print(f\"  logical_z (matrix): NOT FOUND\")\n",
    "    \n",
    "    # Check logical_x (matrix form)\n",
    "    if hasattr(inner, 'logical_x') and inner.logical_x is not None:\n",
    "        lx = np.array(inner.logical_x)\n",
    "        print(f\"  logical_x (matrix): shape={lx.shape}\")\n",
    "        print(f\"    {lx}\")\n",
    "    else:\n",
    "        print(f\"  logical_x (matrix): NOT FOUND\")\n",
    "    \n",
    "    # Check metadata hints\n",
    "    if hasattr(inner, 'metadata'):\n",
    "        if 'logical_z_support' in inner.metadata:\n",
    "            print(f\"  metadata['logical_z_support']: {inner.metadata['logical_z_support']}\")\n",
    "        if 'logical_x_support' in inner.metadata:\n",
    "            print(f\"  metadata['logical_x_support']: {inner.metadata['logical_x_support']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONCLUSION: Which logical format does each code use?\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DETECTOR STRUCTURE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FourQubit422 [[4,2,2]] k=2\n",
      "======================================================================\n",
      "Code: [[36, 10]]\n",
      "Circuit: 62 qubits, 26 detectors, 1 observables\n",
      "DEM: 26 detectors, 31 errors\n",
      "\n",
      "BlockExtractor:\n",
      "  n_blocks: 9\n",
      "  n_inner_qubits: 4\n",
      "  n_inner_x_checks: 1\n",
      "  n_inner_z_checks: 1\n",
      "  dets_per_block_per_round: 2\n",
      "\n",
      "  Expected inner detectors: 18\n",
      "  Total DEM detectors: 26\n",
      "  Outer detectors: ~8\n",
      "\n",
      "  Sample block slices:\n",
      "    Block 0: detectors [0, 2) = 2 detectors\n",
      "    Block 1: detectors [2, 4) = 2 detectors\n",
      "    Block 2: detectors [4, 6) = 2 detectors\n",
      "\n",
      "======================================================================\n",
      "RepetitionCode [[3,1,3]] k=1\n",
      "======================================================================\n",
      "Code: [[27, 1]]\n",
      "Circuit: 53 qubits, 44 detectors, 1 observables\n",
      "DEM: 44 detectors, 49 errors\n",
      "\n",
      "BlockExtractor:\n",
      "  n_blocks: 9\n",
      "  n_inner_qubits: 3\n",
      "  n_inner_x_checks: 0\n",
      "  n_inner_z_checks: 2\n",
      "  dets_per_block_per_round: 2\n",
      "\n",
      "  Expected inner detectors: 18\n",
      "  Total DEM detectors: 44\n",
      "  Outer detectors: ~26\n",
      "\n",
      "  Sample block slices:\n",
      "    Block 0: detectors [0, 4) = 4 detectors\n",
      "    Block 1: detectors [4, 8) = 4 detectors\n",
      "    Block 2: detectors [8, 12) = 4 detectors\n",
      "\n",
      "======================================================================\n",
      "SteaneCode [[7,1,3]] k=1\n",
      "======================================================================\n",
      "Code: [[63, 1]]\n",
      "Circuit: 125 qubits, 62 detectors, 1 observables\n",
      "DEM: 62 detectors, 94 errors\n",
      "\n",
      "BlockExtractor:\n",
      "  n_blocks: 9\n",
      "  n_inner_qubits: 7\n",
      "  n_inner_x_checks: 3\n",
      "  n_inner_z_checks: 3\n",
      "  dets_per_block_per_round: 6\n",
      "\n",
      "  Expected inner detectors: 54\n",
      "  Total DEM detectors: 62\n",
      "  Outer detectors: ~8\n",
      "\n",
      "  Sample block slices:\n",
      "    Block 0: detectors [0, 6) = 6 detectors\n",
      "    Block 1: detectors [6, 12) = 6 detectors\n",
      "    Block 2: detectors [12, 18) = 6 detectors\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DEEP DIVE: Compare detector structure for k=1 vs k=2 codes\n",
    "=========================================================\n",
    "Let's see if the detector slicing is correct for each code type.\n",
    "\"\"\"\n",
    "from qectostim.experiments.memory import CSSMemoryExperiment\n",
    "from qectostim.decoders.block_extraction import BlockExtractor\n",
    "from qectostim.noise import CircuitDepolarizingNoise\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DETECTOR STRUCTURE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "P_ERR = 0.01\n",
    "ROUNDS = 1\n",
    "\n",
    "for name, inner in inner_codes.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    concat = ConcatenatedTopologicalCSSCode(outer, inner)\n",
    "    \n",
    "    # Build circuit and DEM\n",
    "    try:\n",
    "        exp = CSSMemoryExperiment(concat, rounds=ROUNDS)\n",
    "        base_circuit = exp.to_stim()\n",
    "        noise = CircuitDepolarizingNoise(P_ERR)\n",
    "        circuit = noise.apply(base_circuit)\n",
    "        # Allow decomposition failures for non-graph-like codes\n",
    "        dem = circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
    "    except Exception as e:\n",
    "        print(f\"  Circuit/DEM build FAILED: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Code: [[{concat.n}, {concat.k}]]\")\n",
    "    print(f\"Circuit: {circuit.num_qubits} qubits, {circuit.num_detectors} detectors, {circuit.num_observables} observables\")\n",
    "    print(f\"DEM: {dem.num_detectors} detectors, {dem.num_errors} errors\")\n",
    "    \n",
    "    # Try to build BlockExtractor\n",
    "    try:\n",
    "        extractor = BlockExtractor(concat, dem, rounds=ROUNDS)\n",
    "        print(f\"\\nBlockExtractor:\")\n",
    "        print(f\"  n_blocks: {extractor.n_blocks}\")\n",
    "        print(f\"  n_inner_qubits: {extractor.n_inner_qubits}\")\n",
    "        print(f\"  n_inner_x_checks: {extractor.n_inner_x_checks}\")\n",
    "        print(f\"  n_inner_z_checks: {extractor.n_inner_z_checks}\")\n",
    "        print(f\"  dets_per_block_per_round: {extractor.n_inner_x_checks + extractor.n_inner_z_checks}\")\n",
    "        \n",
    "        # Check total detector accounting\n",
    "        expected_inner_total = extractor.n_blocks * (extractor.n_inner_x_checks + extractor.n_inner_z_checks) * ROUNDS\n",
    "        print(f\"\\n  Expected inner detectors: {expected_inner_total}\")\n",
    "        print(f\"  Total DEM detectors: {dem.num_detectors}\")\n",
    "        print(f\"  Outer detectors: ~{dem.num_detectors - expected_inner_total}\")\n",
    "        \n",
    "        # Check first few block slices\n",
    "        print(f\"\\n  Sample block slices:\")\n",
    "        for i in range(min(3, extractor.n_blocks)):\n",
    "            start, stop = extractor.inner_slices[i]\n",
    "            print(f\"    Block {i}: detectors [{start}, {stop}) = {stop-start} detectors\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  BlockExtractor FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a5fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRACE: SoftMP decoding step by step\n",
      "======================================================================\n",
      "Code: [[36, 10]]\n",
      "Detector matrix shape: (100, 26)\n",
      "Observable shape: (100, 1)\n",
      "\n",
      "SoftMP config:\n",
      "  n_blocks: 9\n",
      "  inner_slices: [(0, (0, 6)), (1, (6, 12)), (2, (12, 18))]...\n",
      "  outer_slice: (54, 26)\n",
      "  inner_lz: [1 0 1 0]\n",
      "  outer_L: [1 1 1 0 0 0 0 0 0]\n",
      "\n",
      "--- Sample 0 (has syndrome) ---\n",
      "Syndrome triggered: 3 detectors\n",
      "Actual observable: True\n",
      "Inner hard decisions: [0 0 0 0 0 0 0 0 0]\n",
      "Inner logical probs: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "--- Sample 1 (has syndrome) ---\n",
      "Syndrome triggered: 3 detectors\n",
      "Actual observable: False\n",
      "Inner hard decisions: [0 0 0 0 0 0 0 0 0]\n",
      "Inner logical probs: [0.    0.    0.    0.375 0.    0.    0.    0.    0.   ]\n",
      "\n",
      "--- Sample 4 (has syndrome) ---\n",
      "Syndrome triggered: 4 detectors\n",
      "Actual observable: True\n",
      "Inner hard decisions: [0 0 0 0 0 0 0 0 0]\n",
      "Inner logical probs: [0.    0.    0.375 0.    0.    0.    0.    0.    0.   ]\n",
      "\n",
      "--- Sample 6 (has syndrome) ---\n",
      "Syndrome triggered: 2 detectors\n",
      "Actual observable: False\n",
      "Inner hard decisions: [0 0 0 0 0 0 0 0 0]\n",
      "Inner logical probs: [0.    0.    0.    0.375 0.375 0.    0.    0.    0.   ]\n",
      "\n",
      "--- Sample 10 (has syndrome) ---\n",
      "Syndrome triggered: 3 detectors\n",
      "Actual observable: False\n",
      "Inner hard decisions: [0 0 0 0 0 0 0 0 0]\n",
      "Inner logical probs: [0.    0.375 0.    0.    0.    0.    0.    0.    0.   ]\n",
      "\n",
      "======================================================================\n",
      "SoftMP Errors: 7/100 = 7.0%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BPOSDDecoder' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m syndrome = dets[i]\n\u001b[32m     83\u001b[39m actual_obs = obs[i][\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m pred = \u001b[43mbposd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m(syndrome)\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred[\u001b[32m0\u001b[39m] != actual_obs:\n\u001b[32m     86\u001b[39m     bposd_errors += \u001b[32m1\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'BPOSDDecoder' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DIAGNOSE: Trace through SoftMP decoding to see where it fails\n",
    "============================================================\n",
    "Focus on FourQubit422 since that has correct block slices\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Use FourQubit422 which has correct-looking slices\n",
    "inner = FourQubit422Code()\n",
    "concat = ConcatenatedTopologicalCSSCode(outer, inner)\n",
    "\n",
    "exp = CSSMemoryExperiment(concat, rounds=1)\n",
    "base_circuit = exp.to_stim()\n",
    "noise = CircuitDepolarizingNoise(0.01)\n",
    "circuit = noise.apply(base_circuit)\n",
    "dem = circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRACE: SoftMP decoding step by step\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sample some noisy syndromes\n",
    "sampler = circuit.compile_detector_sampler()\n",
    "n_samples = 100\n",
    "dets, obs = sampler.sample(shots=n_samples, separate_observables=True)\n",
    "\n",
    "# Initialize decoder\n",
    "softmp = SoftMessagePassingDecoder(concat, dem)\n",
    "\n",
    "print(f\"Code: [[{concat.n}, {concat.k}]]\")\n",
    "print(f\"Detector matrix shape: {dets.shape}\")\n",
    "print(f\"Observable shape: {obs.shape}\")\n",
    "print(f\"\\nSoftMP config:\")\n",
    "print(f\"  n_blocks: {softmp.n_blocks}\")\n",
    "print(f\"  inner_slices: {list(softmp.inner_slices.items())[:3]}...\")\n",
    "print(f\"  outer_slice: {softmp.outer_slice}\")\n",
    "print(f\"  inner_lz: {softmp.inner_lz}\")\n",
    "print(f\"  outer_L: {softmp.outer_L}\")\n",
    "\n",
    "# Trace through a few samples with syndrome triggered\n",
    "n_trace = 0\n",
    "errors = 0\n",
    "softmp_predictions = []\n",
    "for i in range(n_samples):\n",
    "    syndrome = dets[i]\n",
    "    actual_obs = obs[i][0]\n",
    "    \n",
    "    if np.sum(syndrome) > 0 and n_trace < 5:\n",
    "        n_trace += 1\n",
    "        print(f\"\\n--- Sample {i} (has syndrome) ---\")\n",
    "        print(f\"Syndrome triggered: {np.sum(syndrome)} detectors\")\n",
    "        print(f\"Actual observable: {actual_obs}\")\n",
    "        \n",
    "        # Decode step by step manually\n",
    "        inner_hard = np.zeros(softmp.n_blocks, dtype=np.uint8)\n",
    "        inner_probs = np.zeros(softmp.n_blocks, dtype=np.float64)\n",
    "        \n",
    "        for block_id in range(softmp.n_blocks):\n",
    "            det_start, det_stop = softmp.inner_slices[block_id]\n",
    "            block_syn = syndrome[det_start:det_stop]\n",
    "            hard, p_log = softmp._compute_inner_logical_prob(block_id, block_syn)\n",
    "            inner_hard[block_id] = hard\n",
    "            inner_probs[block_id] = p_log\n",
    "        \n",
    "        print(f\"Inner hard decisions: {inner_hard}\")\n",
    "        print(f\"Inner logical probs: {np.round(inner_probs, 3)}\")\n",
    "        \n",
    "    # Always collect predictions for statistics\n",
    "    pred = softmp.decode(syndrome)\n",
    "    softmp_predictions.append(pred[0])\n",
    "    if pred[0] != actual_obs:\n",
    "        errors += 1\n",
    "\n",
    "softmp_ler = errors / n_samples\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"SoftMP Errors: {errors}/{n_samples} = {softmp_ler:.1%}\")\n",
    "\n",
    "# Compare to BPOSD\n",
    "bposd = BPOSDDecoder(dem)\n",
    "bposd_errors = 0\n",
    "for i in range(n_samples):\n",
    "    syndrome = dets[i]\n",
    "    actual_obs = obs[i][0]\n",
    "    pred = bposd.decode(syndrome)\n",
    "    if pred[0] != actual_obs:\n",
    "        bposd_errors += 1\n",
    "\n",
    "bposd_ler = bposd_errors / n_samples\n",
    "print(f\"BPOSD Errors: {bposd_errors}/{n_samples} = {bposd_ler:.1%}\")\n",
    "print(f\"Ratio: {softmp_ler/bposd_ler if bposd_ler > 0 else 'inf'}x\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Detector slice computation\n",
      "======================================================================\n",
      "Circuit rounds: 1 (explicit)\n",
      "Circuit detectors: 26\n",
      "DEM detectors: 26\n",
      "\n",
      "Creating SoftMP with rounds=1:\n",
      "  softmp.rounds: 1\n",
      "  softmp.n_inner_x_checks: 1\n",
      "  softmp.n_inner_z_checks: 1\n",
      "  dets_per_block_per_round: 2\n",
      "  Expected dets_per_block: 2\n",
      "  softmp.dets_per_block: 2\n",
      "  softmp.inner_slices (first 3): [(0, (0, 2)), (1, (2, 4)), (2, (4, 6))]\n",
      "  softmp.outer_slice: (18, 26)\n",
      "  softmp.num_detectors: 26\n",
      "\n",
      "Expected distribution:\n",
      "  9 blocks × 2 dets/block = 18 inner detectors\n",
      "  Remaining for outer: 8\n",
      "\n",
      "Outer slice: (18, 26)\n",
      "  This is 8 detectors\n",
      "  But DEM has 26 total detectors\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRACE: Where is the 6-detector slice coming from?\n",
    "=================================================\n",
    "\"\"\"\n",
    "print(\"=\" * 70)\n",
    "print(\"DEBUGGING: Detector slice computation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# This is from the previous diagnostic\n",
    "inner = FourQubit422Code()\n",
    "concat = ConcatenatedTopologicalCSSCode(outer, inner)\n",
    "\n",
    "exp = CSSMemoryExperiment(concat, rounds=1)  # Explicit rounds=1\n",
    "base_circuit = exp.to_stim()\n",
    "noise = CircuitDepolarizingNoise(0.01)\n",
    "circuit = noise.apply(base_circuit)\n",
    "dem = circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
    "\n",
    "print(f\"Circuit rounds: 1 (explicit)\")\n",
    "print(f\"Circuit detectors: {circuit.num_detectors}\")\n",
    "print(f\"DEM detectors: {dem.num_detectors}\")\n",
    "\n",
    "# Create SoftMP with explicit rounds=1\n",
    "print(\"\\nCreating SoftMP with rounds=1:\")\n",
    "softmp = SoftMessagePassingDecoder(concat, dem, rounds=1)\n",
    "\n",
    "print(f\"  softmp.rounds: {softmp.rounds}\")\n",
    "print(f\"  softmp.n_inner_x_checks: {softmp.n_inner_x_checks}\")\n",
    "print(f\"  softmp.n_inner_z_checks: {softmp.n_inner_z_checks}\")\n",
    "print(f\"  dets_per_block_per_round: {softmp.n_inner_x_checks + softmp.n_inner_z_checks}\")\n",
    "print(f\"  Expected dets_per_block: {(softmp.n_inner_x_checks + softmp.n_inner_z_checks) * softmp.rounds}\")\n",
    "print(f\"  softmp.dets_per_block: {softmp.dets_per_block}\")\n",
    "print(f\"  softmp.inner_slices (first 3): {list(softmp.inner_slices.items())[:3]}\")\n",
    "print(f\"  softmp.outer_slice: {softmp.outer_slice}\")\n",
    "print(f\"  softmp.num_detectors: {softmp.num_detectors}\")\n",
    "\n",
    "# Now check what SHOULD be happening\n",
    "print(\"\\nExpected distribution:\")\n",
    "expected_inner = 9 * softmp.dets_per_block\n",
    "print(f\"  9 blocks × {softmp.dets_per_block} dets/block = {expected_inner} inner detectors\")\n",
    "print(f\"  Remaining for outer: {dem.num_detectors - expected_inner}\")\n",
    "\n",
    "# Check if outer_slice makes sense\n",
    "outer_start, outer_stop = softmp.outer_slice\n",
    "print(f\"\\nOuter slice: ({outer_start}, {outer_stop})\")\n",
    "print(f\"  This is {outer_stop - outer_start} detectors\")\n",
    "print(f\"  But DEM has {dem.num_detectors} total detectors\")\n",
    "\n",
    "if outer_start > dem.num_detectors:\n",
    "    print(f\"  ⚠️ ERROR: outer_start ({outer_start}) > num_detectors ({dem.num_detectors})!\")\n",
    "    print(f\"  This means inner slices EXCEED the actual detector count!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a930fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROPERLY CONFIGURED DECODER COMPARISON\n",
      "======================================================================\n",
      "Code: [[36, 10]]\n",
      "Circuit: 26 detectors, rounds=1\n",
      "\n",
      "SoftMP detector config:\n",
      "  n_blocks: 9\n",
      "  dets_per_block: 2\n",
      "  inner total: 18\n",
      "  outer slice: (18, 26)\n",
      "  inner_lz: [1 0 1 0]\n",
      "  outer_L: [1 1 1 0 0 0 0 0 0]\n",
      "\n",
      "======================================================================\n",
      "Results at p=0.01, rounds=1, shots=500\n",
      "======================================================================\n",
      "BPOSD:  LER = 0.0000 (0/500 errors)\n",
      "SoftMP: LER = 0.0560 (28/500 errors)\n",
      "N/A\n",
      "\n",
      "======================================================================\n",
      "SoftMP failure analysis (first 5):\n",
      "{'='*70}\n",
      "\n",
      "Sample 3:\n",
      "  Syndrome weight: 2\n",
      "  Actual: True, Predicted: 0\n",
      "  Inner hard: [0 0 0 0 0 0 0 0 0]\n",
      "  Inner probs: [0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002]\n",
      "\n",
      "Sample 13:\n",
      "  Syndrome weight: 1\n",
      "  Actual: False, Predicted: 1\n",
      "  Inner hard: [0 0 0 0 0 0 0 0 0]\n",
      "  Inner probs: [0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002]\n",
      "\n",
      "Sample 23:\n",
      "  Syndrome weight: 3\n",
      "  Actual: True, Predicted: 0\n",
      "  Inner hard: [0 0 0 0 0 0 0 0 0]\n",
      "  Inner probs: [0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.375 0.375]\n",
      "\n",
      "Sample 54:\n",
      "  Syndrome weight: 1\n",
      "  Actual: False, Predicted: 1\n",
      "  Inner hard: [0 0 0 0 0 0 0 0 0]\n",
      "  Inner probs: [0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002]\n",
      "\n",
      "Sample 63:\n",
      "  Syndrome weight: 1\n",
      "  Actual: False, Predicted: 1\n",
      "  Inner hard: [0 0 0 0 0 0 0 0 0]\n",
      "  Inner probs: [0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PROPERLY CONFIGURED COMPARISON\n",
    "==============================\n",
    "Now with correct rounds=1 configuration throughout.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROPERLY CONFIGURED DECODER COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use FourQubit422 for this analysis\n",
    "inner = FourQubit422Code()\n",
    "concat = ConcatenatedTopologicalCSSCode(outer, inner)\n",
    "\n",
    "# Build circuit with rounds=1\n",
    "ROUNDS = 1\n",
    "exp = CSSMemoryExperiment(concat, rounds=ROUNDS)\n",
    "base_circuit = exp.to_stim()\n",
    "noise = CircuitDepolarizingNoise(0.01)\n",
    "circuit = noise.apply(base_circuit)\n",
    "dem = circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
    "\n",
    "print(f\"Code: [[{concat.n}, {concat.k}]]\")\n",
    "print(f\"Circuit: {circuit.num_detectors} detectors, rounds={ROUNDS}\")\n",
    "\n",
    "# Create decoders with CORRECT rounds\n",
    "softmp = SoftMessagePassingDecoder(concat, dem, rounds=ROUNDS)\n",
    "bposd = BPOSDDecoder(dem)\n",
    "\n",
    "print(f\"\\nSoftMP detector config:\")\n",
    "print(f\"  n_blocks: {softmp.n_blocks}\")\n",
    "print(f\"  dets_per_block: {softmp.dets_per_block}\")\n",
    "print(f\"  inner total: {softmp.n_blocks * softmp.dets_per_block}\")\n",
    "print(f\"  outer slice: {softmp.outer_slice}\")\n",
    "print(f\"  inner_lz: {softmp.inner_lz}\")\n",
    "print(f\"  outer_L: {softmp.outer_L}\")\n",
    "\n",
    "# Sample and decode\n",
    "sampler = circuit.compile_detector_sampler()\n",
    "SHOTS = 500\n",
    "dets, obs = sampler.sample(shots=SHOTS, separate_observables=True)\n",
    "\n",
    "softmp_errors = 0\n",
    "bposd_errors = 0\n",
    "\n",
    "# Detailed analysis of failures\n",
    "softmp_failures = []\n",
    "bposd_failures = []\n",
    "\n",
    "for i in range(SHOTS):\n",
    "    syndrome = dets[i]\n",
    "    actual = obs[i][0]\n",
    "    \n",
    "    softmp_pred = softmp.decode(syndrome)[0]\n",
    "    bposd_pred = bposd.decode_batch(syndrome.reshape(1, -1))[0, 0]\n",
    "    \n",
    "    if softmp_pred != actual:\n",
    "        softmp_errors += 1\n",
    "        if len(softmp_failures) < 5:\n",
    "            softmp_failures.append({\n",
    "                'idx': i,\n",
    "                'syn_weight': np.sum(syndrome),\n",
    "                'actual': actual,\n",
    "                'pred': softmp_pred,\n",
    "                'syndrome': syndrome.copy()\n",
    "            })\n",
    "    \n",
    "    if bposd_pred != actual:\n",
    "        bposd_errors += 1\n",
    "        if len(bposd_failures) < 5:\n",
    "            bposd_failures.append({\n",
    "                'idx': i,\n",
    "                'syn_weight': np.sum(syndrome),\n",
    "                'actual': actual,\n",
    "                'pred': bposd_pred,\n",
    "            })\n",
    "\n",
    "softmp_ler = softmp_errors / SHOTS\n",
    "bposd_ler = bposd_errors / SHOTS\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Results at p=0.01, rounds=1, shots={SHOTS}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"BPOSD:  LER = {bposd_ler:.4f} ({bposd_errors}/{SHOTS} errors)\")\n",
    "print(f\"SoftMP: LER = {softmp_ler:.4f} ({softmp_errors}/{SHOTS} errors)\")\n",
    "print(f\"Ratio: {softmp_ler/bposd_ler:.1f}x\" if bposd_ler > 0 else \"N/A\")\n",
    "\n",
    "# Analyze SoftMP failures\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SoftMP failure analysis (first 5):\")\n",
    "print(\"{'='*70}\")\n",
    "for f in softmp_failures:\n",
    "    print(f\"\\nSample {f['idx']}:\")\n",
    "    print(f\"  Syndrome weight: {f['syn_weight']}\")\n",
    "    print(f\"  Actual: {f['actual']}, Predicted: {f['pred']}\")\n",
    "    \n",
    "    # Trace through the decoding\n",
    "    syn = f['syndrome']\n",
    "    inner_hard = np.zeros(softmp.n_blocks, dtype=np.uint8)\n",
    "    inner_probs = np.zeros(softmp.n_blocks, dtype=np.float64)\n",
    "    \n",
    "    for block_id in range(softmp.n_blocks):\n",
    "        det_start, det_stop = softmp.inner_slices[block_id]\n",
    "        block_syn = syn[det_start:det_stop]\n",
    "        hard, p_log = softmp._compute_inner_logical_prob(block_id, block_syn)\n",
    "        inner_hard[block_id] = hard\n",
    "        inner_probs[block_id] = p_log\n",
    "    \n",
    "    print(f\"  Inner hard: {inner_hard}\")\n",
    "    print(f\"  Inner probs: {np.round(inner_probs, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c08663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SYNDROME STRUCTURE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Inner code (FourQubit422):\n",
      "  hx (detects Z errors): [[1 1 1 1]]\n",
      "  hz (detects X errors): [[1 1 1 1]]\n",
      "  n_inner_x_checks: 1\n",
      "  n_inner_z_checks: 1\n",
      "\n",
      "Circuit detectors: 26\n",
      "\n",
      "Sample syndrome patterns:\n",
      "\n",
      "Sample 1: total triggered = 2\n",
      "  Full syndrome: [False False False False False False False  True False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False]\n",
      "  Block 3: [False  True] (dets 6:8)\n",
      "  Outer: [False False  True False False False False False] (dets 18:26)\n",
      "\n",
      "Sample 3: total triggered = 2\n",
      "  Full syndrome: [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False  True\n",
      " False False]\n",
      "  Block 6: [False  True] (dets 12:14)\n",
      "  Outer: [False False False False False  True False False] (dets 18:26)\n",
      "\n",
      "Sample 4: total triggered = 3\n",
      "  Full syndrome: [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      "  True  True]\n",
      "  Outer: [ True False False False False False  True  True] (dets 18:26)\n",
      "\n",
      "Sample 6: total triggered = 1\n",
      "  Full syndrome: [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False]\n",
      "  Outer: [ True False False False False False False False] (dets 18:26)\n",
      "\n",
      "Sample 9: total triggered = 1\n",
      "  Full syndrome: [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False]\n",
      "  Block 7: [ True False] (dets 14:16)\n",
      "\n",
      "======================================================================\n",
      "Block detector statistics:\n",
      "======================================================================\n",
      "Blocks with any syndrome activity (out of 500 samples):\n",
      "  Block 0: 12 samples (2.4%)\n",
      "  Block 1: 14 samples (2.8%)\n",
      "  Block 2: 7 samples (1.4%)\n",
      "  Block 3: 6 samples (1.2%)\n",
      "  Block 4: 4 samples (0.8%)\n",
      "  Block 5: 9 samples (1.8%)\n",
      "  Block 6: 29 samples (5.8%)\n",
      "  Block 7: 44 samples (8.8%)\n",
      "  Block 8: 37 samples (7.4%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DEBUG: What do the block syndromes actually represent?\n",
    "=====================================================\n",
    "\"\"\"\n",
    "print(\"=\" * 70)\n",
    "print(\"SYNDROME STRUCTURE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Look at what detectors correspond to for FourQubit422\n",
    "print(\"\\nInner code (FourQubit422):\")\n",
    "print(f\"  hx (detects Z errors): {inner.hx}\")\n",
    "print(f\"  hz (detects X errors): {inner.hz}\")\n",
    "print(f\"  n_inner_x_checks: {softmp.n_inner_x_checks}\")\n",
    "print(f\"  n_inner_z_checks: {softmp.n_inner_z_checks}\")\n",
    "\n",
    "print(f\"\\nCircuit detectors: {circuit.num_detectors}\")\n",
    "\n",
    "# Sample a few syndromes and see the patterns\n",
    "print(\"\\nSample syndrome patterns:\")\n",
    "for i in range(min(10, SHOTS)):\n",
    "    syn = dets[i]\n",
    "    if np.sum(syn) > 0:\n",
    "        print(f\"\\nSample {i}: total triggered = {np.sum(syn)}\")\n",
    "        print(f\"  Full syndrome: {syn}\")\n",
    "        \n",
    "        # Look at each block\n",
    "        for b in range(softmp.n_blocks):\n",
    "            start, stop = softmp.inner_slices[b]\n",
    "            block_syn = syn[start:stop]\n",
    "            if np.sum(block_syn) > 0:\n",
    "                print(f\"  Block {b}: {block_syn} (dets {start}:{stop})\")\n",
    "        \n",
    "        # Outer detectors\n",
    "        outer_start, outer_stop = softmp.outer_slice\n",
    "        outer_syn = syn[outer_start:outer_stop]\n",
    "        if np.sum(outer_syn) > 0:\n",
    "            print(f\"  Outer: {outer_syn} (dets {outer_start}:{outer_stop})\")\n",
    "\n",
    "# Check if detectors are actually firing in blocks\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Block detector statistics:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "block_activity = np.zeros(softmp.n_blocks)\n",
    "for i in range(SHOTS):\n",
    "    for b in range(softmp.n_blocks):\n",
    "        start, stop = softmp.inner_slices[b]\n",
    "        block_activity[b] += np.any(dets[i, start:stop])\n",
    "\n",
    "print(\"Blocks with any syndrome activity (out of {} samples):\".format(SHOTS))\n",
    "for b, count in enumerate(block_activity):\n",
    "    print(f\"  Block {b}: {int(count)} samples ({count/SHOTS*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CIRCUIT STRUCTURE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Circuit summary:\n",
      "  Qubits: 62\n",
      "  Detectors: 26\n",
      "  Observables: 1\n",
      "\n",
      "Detector coordinates (if available):\n",
      "\n",
      "SoftMP expects:\n",
      "  9 blocks × 2 dets = 18 inner\n",
      "  8 outer detectors\n",
      "  Total: 26\n",
      "\n",
      "But the circuit may have a different layout!\n",
      "CSSMemoryExperiment uses the concatenated code's flat stabilizer structure,\n",
      "not a block-by-block inner code structure.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KEY INSIGHT: The detector layout doesn't match SoftMP's assumptions!\n",
    "====================================================================\n",
    "CSSMemoryExperiment lays out detectors differently than a concatenated structure.\n",
    "Let's verify this by looking at the circuit.\n",
    "\"\"\"\n",
    "print(\"=\" * 70)\n",
    "print(\"CIRCUIT STRUCTURE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Print a summary of the circuit\n",
    "print(f\"\\nCircuit summary:\")\n",
    "print(f\"  Qubits: {circuit.num_qubits}\")\n",
    "print(f\"  Detectors: {circuit.num_detectors}\")\n",
    "print(f\"  Observables: {circuit.num_observables}\")\n",
    "\n",
    "# Look at detector coords to understand layout\n",
    "print(\"\\nDetector coordinates (if available):\")\n",
    "det_coords = {}\n",
    "for line in str(circuit).split('\\n'):\n",
    "    if line.startswith('DETECTOR'):\n",
    "        # Parse detector index and coords\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 2:\n",
    "            try:\n",
    "                coords = [float(x) for x in parts[1].strip('()').split(',')]\n",
    "                det_idx = len(det_coords)\n",
    "                det_coords[det_idx] = coords\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Print first 20 detector coords\n",
    "for det_idx in range(min(26, len(det_coords))):\n",
    "    if det_idx in det_coords:\n",
    "        coords = det_coords[det_idx]\n",
    "        print(f\"  D{det_idx}: {coords}\")\n",
    "\n",
    "# Check if detectors are grouped by block\n",
    "print(f\"\\nSoftMP expects:\")\n",
    "print(f\"  {softmp.n_blocks} blocks × {softmp.dets_per_block} dets = {softmp.n_blocks * softmp.dets_per_block} inner\")\n",
    "print(f\"  {softmp.outer_slice[1] - softmp.outer_slice[0]} outer detectors\")\n",
    "print(f\"  Total: {circuit.num_detectors}\")\n",
    "\n",
    "print(f\"\\nBut the circuit may have a different layout!\")\n",
    "print(f\"CSSMemoryExperiment uses the concatenated code's flat stabilizer structure,\")\n",
    "print(f\"not a block-by-block inner code structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca81155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "USING ConcatenatedMemoryExperiment\n",
      "======================================================================\n",
      "ConcatenatedMemoryExperiment failed: The circuit contains non-deterministic observables.\n",
      "\n",
      "To make an SVG picture of the problem, you can use the python API like this:\n",
      "    your_circuit.diagram('detslice-with-ops-svg', tick=range(0, 5), filter_coords=['L8', 'L9', ])\n",
      "or the command line API like this:\n",
      "    stim diagram --in your_circuit_file.stim --type detslice-with-ops-svg --tick 0:5 --filter_coords L8:L9 > output_image.svg\n",
      "\n",
      "This was discovered while analyzing a Z-basis reset (R) on:\n",
      "    qubit 48\n",
      "\n",
      "The collapse anti-commuted with these detectors/observables:\n",
      "    L8\n",
      "    L9\n",
      "\n",
      "The backward-propagating error sensitivity for L8 was:\n",
      "    Z28 [coords (-0.5, 3.74264)]\n",
      "    Z30 [coords (0.5, 4.74264)]\n",
      "    X46\n",
      "    X48\n",
      "\n",
      "The backward-propagating error sensitivity for L9 was:\n",
      "    Z32 [coords (3.74264, 3.74264)]\n",
      "    Z34 [coords (4.74264, 4.74264)]\n",
      "    X48\n",
      "\n",
      "Circuit stack trace:\n",
      "    during TICK layer #1 of 19\n",
      "    at instruction #37 [which is R 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_39840/455100180.py\", line 15, in <module>\n",
      "    concat_dem = concat_circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: The circuit contains non-deterministic observables.\n",
      "\n",
      "To make an SVG picture of the problem, you can use the python API like this:\n",
      "    your_circuit.diagram('detslice-with-ops-svg', tick=range(0, 5), filter_coords=['L8', 'L9', ])\n",
      "or the command line API like this:\n",
      "    stim diagram --in your_circuit_file.stim --type detslice-with-ops-svg --tick 0:5 --filter_coords L8:L9 > output_image.svg\n",
      "\n",
      "This was discovered while analyzing a Z-basis reset (R) on:\n",
      "    qubit 48\n",
      "\n",
      "The collapse anti-commuted with these detectors/observables:\n",
      "    L8\n",
      "    L9\n",
      "\n",
      "The backward-propagating error sensitivity for L8 was:\n",
      "    Z28 [coords (-0.5, 3.74264)]\n",
      "    Z30 [coords (0.5, 4.74264)]\n",
      "    X46\n",
      "    X48\n",
      "\n",
      "The backward-propagating error sensitivity for L9 was:\n",
      "    Z32 [coords (3.74264, 3.74264)]\n",
      "    Z34 [coords (4.74264, 4.74264)]\n",
      "    X48\n",
      "\n",
      "Circuit stack trace:\n",
      "    during TICK layer #1 of 19\n",
      "    at instruction #37 [which is R 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRY: ConcatenatedMemoryExperiment for block-grouped detectors\n",
    "=============================================================\n",
    "\"\"\"\n",
    "from qectostim.experiments.concatenated_memory import ConcatenatedMemoryExperiment\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"USING ConcatenatedMemoryExperiment\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Build circuit with ConcatenatedMemoryExperiment\n",
    "    concat_exp = ConcatenatedMemoryExperiment(concat, rounds=1, basis=\"Z\")\n",
    "    concat_circuit = noise.apply(concat_exp.to_stim())\n",
    "    concat_dem = concat_circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
    "    \n",
    "    print(f\"ConcatenatedMemoryExperiment circuit:\")\n",
    "    print(f\"  Qubits: {concat_circuit.num_qubits}\")\n",
    "    print(f\"  Detectors: {concat_circuit.num_detectors}\")\n",
    "    print(f\"  Observables: {concat_circuit.num_observables}\")\n",
    "    \n",
    "    # Compare to CSSMemoryExperiment\n",
    "    print(f\"\\nCSSMemoryExperiment circuit:\")\n",
    "    print(f\"  Qubits: {circuit.num_qubits}\")\n",
    "    print(f\"  Detectors: {circuit.num_detectors}\")\n",
    "    print(f\"  Observables: {circuit.num_observables}\")\n",
    "    \n",
    "    if concat_circuit.num_detectors != circuit.num_detectors:\n",
    "        print(f\"\\n⚠️ Different detector counts! ConcatExp has {concat_circuit.num_detectors}, CSSExp has {circuit.num_detectors}\")\n",
    "    \n",
    "    # Test SoftMP with ConcatenatedMemoryExperiment circuit\n",
    "    softmp_concat = SoftMessagePassingDecoder(concat, concat_dem, rounds=1)\n",
    "    \n",
    "    print(f\"\\nSoftMP with ConcatenatedMemoryExperiment:\")\n",
    "    print(f\"  n_blocks: {softmp_concat.n_blocks}\")\n",
    "    print(f\"  dets_per_block: {softmp_concat.dets_per_block}\")\n",
    "    print(f\"  inner_slices: {list(softmp_concat.inner_slices.items())[:3]}...\")\n",
    "    print(f\"  outer_slice: {softmp_concat.outer_slice}\")\n",
    "    \n",
    "    # Sample and compare decoders\n",
    "    concat_sampler = concat_circuit.compile_detector_sampler()\n",
    "    concat_dets, concat_obs = concat_sampler.sample(shots=200, separate_observables=True)\n",
    "    \n",
    "    softmp_errors = 0\n",
    "    bposd_concat = BPOSDDecoder(concat_dem)\n",
    "    bposd_errors = 0\n",
    "    \n",
    "    for i in range(200):\n",
    "        syn = concat_dets[i]\n",
    "        actual = concat_obs[i][0]\n",
    "        \n",
    "        softmp_pred = softmp_concat.decode(syn)[0]\n",
    "        bposd_pred = bposd_concat.decode_batch(syn.reshape(1, -1))[0, 0]\n",
    "        \n",
    "        if softmp_pred != actual:\n",
    "            softmp_errors += 1\n",
    "        if bposd_pred != actual:\n",
    "            bposd_errors += 1\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Results with ConcatenatedMemoryExperiment (200 samples):\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"BPOSD:  {bposd_errors}/200 = {bposd_errors/200:.1%}\")\n",
    "    print(f\"SoftMP: {softmp_errors}/200 = {softmp_errors/200:.1%}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ConcatenatedMemoryExperiment failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b058ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Template DEM vs Actual Inner Block Detector Structure\n",
      "======================================================================\n",
      "\n",
      "Inner code: SteaneCode713\n",
      "  n=7, k=1\n",
      "  hx shape: (3, 7), hz shape: (3, 7)\n",
      "  X stabilizers: 3, Z stabilizers: 3\n",
      "\n",
      "Outer code: RotatedSurfaceCode\n",
      "  n=9, k=1\n",
      "\n",
      "--- Concatenated Circuit ---\n",
      "Total detectors: 62\n",
      "Total observables: 1\n",
      "\n",
      "Detector slices from experiment:\n",
      "  inner_slices: {0: (0, 6), 1: (6, 12), 2: (12, 18), 3: (18, 24), 4: (24, 30), 5: (30, 36), 6: (36, 42), 7: (42, 48), 8: (48, 54)}\n",
      "  outer_slices: {0: (54, 62)}\n",
      "  inner_dets_per_block: 6\n",
      "  outer_dets: 8\n",
      "  n_inner_blocks: 9\n",
      "  total_detectors: 62\n",
      "  rounds: 1\n",
      "  basis: Z\n",
      "\n",
      "--- Template DEM for Inner Code ---\n",
      "Template circuit detectors: 6\n",
      "Template circuit observables: 1\n",
      "Template DEM detectors: 6\n",
      "Template DEM observables: 1\n",
      "\n",
      "Actual inner block 0 detector count: 6\n",
      "Template DEM detector count: 6\n",
      "MATCH: True\n"
     ]
    }
   ],
   "source": [
    "# Debug: Compare Template DEM vs actual inner block detector counts\n",
    "import numpy as np\n",
    "from qectostim.codes.small.steane_713 import SteaneCode713\n",
    "from qectostim.codes.surface.rotated_surface import RotatedSurfaceCode\n",
    "from qectostim.codes.composite.concatenated import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.experiments.concatenated_memory import ConcatenatedMemoryExperiment\n",
    "from qectostim.experiments.memory import CSSMemoryExperiment\n",
    "from qectostim.noise.models import CircuitDepolarizingNoise\n",
    "\n",
    "# Build concatenated code\n",
    "inner = SteaneCode713()\n",
    "outer = RotatedSurfaceCode(distance=3)\n",
    "concat = ConcatenatedTopologicalCSSCode(outer=outer, inner=inner)\n",
    "\n",
    "P_ERR = 0.005\n",
    "ROUNDS = 1\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Template DEM vs Actual Inner Block Detector Structure\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nInner code: {inner.name}\")\n",
    "print(f\"  n={inner.n}, k={inner.k}\")\n",
    "print(f\"  hx shape: {inner.hx.shape}, hz shape: {inner.hz.shape}\")\n",
    "print(f\"  X stabilizers: {inner.hx.shape[0]}, Z stabilizers: {inner.hz.shape[0]}\")\n",
    "\n",
    "print(f\"\\nOuter code: {outer.name}\")\n",
    "print(f\"  n={outer.n}, k={outer.k}\")\n",
    "\n",
    "# Build concatenated circuit\n",
    "noise = CircuitDepolarizingNoise(p1=P_ERR, p2=P_ERR, before_measure_flip=P_ERR)\n",
    "concat_exp = ConcatenatedMemoryExperiment(concat, noise_model=P_ERR, rounds=ROUNDS)\n",
    "concat_circuit = concat_exp.to_stim()\n",
    "concat_dem = concat_circuit.detector_error_model(decompose_errors=True)\n",
    "\n",
    "print(f\"\\n--- Concatenated Circuit ---\")\n",
    "print(f\"Total detectors: {concat_circuit.num_detectors}\")\n",
    "print(f\"Total observables: {concat_circuit.num_observables}\")\n",
    "\n",
    "# Get detector slices from experiment\n",
    "slices = concat_exp.get_detector_slices()\n",
    "print(f\"\\nDetector slices from experiment:\")\n",
    "for key, val in slices.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "# Build Template DEM for inner code\n",
    "print(f\"\\n--- Template DEM for Inner Code ---\")\n",
    "template_exp = CSSMemoryExperiment(\n",
    "    code=inner,\n",
    "    rounds=ROUNDS,\n",
    "    noise_model=noise,\n",
    "    basis='Z'\n",
    ")\n",
    "template_circuit = template_exp.to_stim()\n",
    "noisy_template = noise.apply(template_circuit)\n",
    "template_dem = noisy_template.detector_error_model(decompose_errors=True)\n",
    "\n",
    "print(f\"Template circuit detectors: {template_circuit.num_detectors}\")\n",
    "print(f\"Template circuit observables: {template_circuit.num_observables}\")\n",
    "print(f\"Template DEM detectors: {template_dem.num_detectors}\")\n",
    "print(f\"Template DEM observables: {template_dem.num_observables}\")\n",
    "\n",
    "# Check inner block size from concatenated circuit\n",
    "if 'inner_slices' in slices:\n",
    "    inner_slices = slices['inner_slices']\n",
    "    if len(inner_slices) > 0:\n",
    "        first_block_start, first_block_end = inner_slices[0]\n",
    "        actual_inner_dets = first_block_end - first_block_start\n",
    "        print(f\"\\nActual inner block 0 detector count: {actual_inner_dets}\")\n",
    "        print(f\"Template DEM detector count: {template_dem.num_detectors}\")\n",
    "        print(f\"MATCH: {actual_inner_dets == template_dem.num_detectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab30d075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: SoftHierarchical Initialization\n",
      "======================================================================\n",
      "\n",
      "Warnings during initialization:\n",
      "  - SoftHierarchicalDecoder is deprecated. Use SoftMessagePassingDecoder instead for more robust hierarchical decoding with adaptive detector slicing.\n",
      "  - SoftHierarchicalDecoder: DEM has 1 observables, expected 10 (1 main + 9 inner blocks). Using code-based soft information estimation (may be less accurate).\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  - This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "\n",
      "--- SoftHierarchical State ---\n",
      "_inner_decoder_method: template_dem\n",
      "_has_inner_observables: False\n",
      "n_blocks: 9\n",
      "inner_slices: {0: (0, 6), 1: (6, 12), 2: (12, 18), 3: (18, 24), 4: (24, 30), 5: (30, 36), 6: (36, 42), 7: (42, 48), 8: (48, 54)}\n",
      "Number of inner_decoders: 9\n",
      "\n",
      "Inner decoder details:\n",
      "  Block 0:\n",
      "    decoder: bposd_decoder\n",
      "    obs_matrix shape: (1, 22)\n",
      "  Block 1:\n",
      "    decoder: bposd_decoder\n",
      "    obs_matrix shape: (1, 22)\n",
      "  Block 2:\n",
      "    decoder: bposd_decoder\n",
      "    obs_matrix shape: (1, 22)\n"
     ]
    }
   ],
   "source": [
    "# Debug: Test SoftHierarchical initialization directly\n",
    "import warnings\n",
    "from qectostim.decoders.soft_hierarchical_decoder import SoftHierarchicalDecoder\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: SoftHierarchical Initialization\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Capture all warnings during initialization\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    \n",
    "    soft_hier = SoftHierarchicalDecoder(\n",
    "        code=concat,\n",
    "        dem=concat_dem,\n",
    "        rounds=ROUNDS,\n",
    "        basis='Z'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nWarnings during initialization:\")\n",
    "    for warning in w:\n",
    "        print(f\"  - {warning.message}\")\n",
    "\n",
    "print(f\"\\n--- SoftHierarchical State ---\")\n",
    "print(f\"_inner_decoder_method: {soft_hier._inner_decoder_method}\")\n",
    "print(f\"_has_inner_observables: {soft_hier._has_inner_observables}\")\n",
    "print(f\"n_blocks: {soft_hier.n_blocks}\")\n",
    "print(f\"inner_slices: {soft_hier.inner_slices}\")\n",
    "print(f\"Number of inner_decoders: {len(soft_hier.inner_decoders)}\")\n",
    "\n",
    "# Check what's in inner_decoders\n",
    "print(f\"\\nInner decoder details:\")\n",
    "for block_id in range(min(3, soft_hier.n_blocks)):\n",
    "    decoder = soft_hier.inner_decoders.get(block_id)\n",
    "    obs_mat = soft_hier.inner_obs_matrices.get(block_id)\n",
    "    print(f\"  Block {block_id}:\")\n",
    "    print(f\"    decoder: {type(decoder).__name__ if decoder else None}\")\n",
    "    if obs_mat is not None:\n",
    "        print(f\"    obs_matrix shape: {obs_mat.shape}\")\n",
    "    else:\n",
    "        print(f\"    obs_matrix: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ed170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Decode a single shot step by step\n",
      "======================================================================\n",
      "No shots with errors found, using shot 0\n",
      "Shot 0: syndrome weight = 0, true observable = [False]\n",
      "\n",
      "Block 8 syndrome: [0 0 0 0 0 0] (weight=0)\n",
      "Template obs_matrix shape: (1, 22)\n",
      "Error pattern shape: (22,), weight: 0\n",
      "Observable matrix:\n",
      "[[0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1]]\n",
      "Hard prediction: 0\n",
      "\n",
      "LLRs shape: (22,)\n",
      "LLRs: min=0.00, max=0.00, mean=0.00\n",
      "LLRs all zero: True\n",
      "First 10 LLRs: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/2689492938.py:53: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  hard_pred = int(obs_dense @ error_pattern % 2)\n"
     ]
    }
   ],
   "source": [
    "# Debug: Test actual decoding on a sample shot\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Decode a single shot step by step\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample with higher error rate to get more errors\n",
    "high_noise = CircuitDepolarizingNoise(p1=0.05, p2=0.05, before_measure_flip=0.05)\n",
    "high_noise_exp = ConcatenatedMemoryExperiment(concat, noise_model=0.05, rounds=ROUNDS)\n",
    "high_noise_circuit = high_noise_exp.to_stim()\n",
    "\n",
    "sampler = high_noise_circuit.compile_detector_sampler()\n",
    "det_sample, obs_sample = sampler.sample(shots=100, separate_observables=True)\n",
    "\n",
    "# Find a shot with non-zero syndrome\n",
    "shot_idx = None\n",
    "for i in range(100):\n",
    "    if det_sample[i].sum() > 0:\n",
    "        shot_idx = i\n",
    "        break\n",
    "\n",
    "if shot_idx is None:\n",
    "    print(\"No shots with errors found, using shot 0\")\n",
    "    shot_idx = 0\n",
    "\n",
    "syndrome = det_sample[shot_idx].astype(np.uint8)\n",
    "true_obs = obs_sample[shot_idx]\n",
    "\n",
    "print(f\"Shot {shot_idx}: syndrome weight = {syndrome.sum()}, true observable = {true_obs}\")\n",
    "\n",
    "# Find block with non-zero syndrome\n",
    "for block_id in range(soft_hier.n_blocks):\n",
    "    det_start, det_stop = soft_hier.inner_slices[block_id]\n",
    "    block_syndrome = syndrome[det_start:det_stop]\n",
    "    if block_syndrome.sum() > 0:\n",
    "        break\n",
    "\n",
    "print(f\"\\nBlock {block_id} syndrome: {block_syndrome} (weight={block_syndrome.sum()})\")\n",
    "\n",
    "# Get the decoder and observable matrix\n",
    "decoder = soft_hier.inner_decoders[block_id]\n",
    "obs_matrix = soft_hier.inner_obs_matrices[block_id]\n",
    "\n",
    "print(f\"Template obs_matrix shape: {obs_matrix.shape}\")\n",
    "\n",
    "# Decode\n",
    "try:\n",
    "    error_pattern = decoder.decode(block_syndrome)\n",
    "    print(f\"Error pattern shape: {error_pattern.shape}, weight: {error_pattern.sum()}\")\n",
    "    \n",
    "    # Check observable\n",
    "    if obs_matrix is not None:\n",
    "        obs_dense = obs_matrix.toarray() if hasattr(obs_matrix, 'toarray') else np.asarray(obs_matrix)\n",
    "        hard_pred = int(obs_dense @ error_pattern % 2)\n",
    "        print(f\"Observable matrix:\\n{obs_dense}\")\n",
    "        print(f\"Hard prediction: {hard_pred}\")\n",
    "    \n",
    "    # Check LLRs\n",
    "    if hasattr(decoder, 'log_prob_ratios'):\n",
    "        llrs = decoder.log_prob_ratios\n",
    "        print(f\"\\nLLRs shape: {llrs.shape if llrs is not None else None}\")\n",
    "        if llrs is not None and len(llrs) > 0:\n",
    "            print(f\"LLRs: min={llrs.min():.2f}, max={llrs.max():.2f}, mean={llrs.mean():.2f}\")\n",
    "            print(f\"LLRs all zero: {np.all(llrs == 0)}\")\n",
    "            print(f\"First 10 LLRs: {llrs[:10]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Decode failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e5689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Find shot with actual syndrome\n",
      "======================================================================\n",
      "Using error rate p=0.05\n",
      "Circuit detectors: 62\n",
      "SoftHierarchical _inner_decoder_method: template_dem\n",
      "\n",
      "Shots with syndrome: 0/1000\n",
      "No shot with inner syndrome found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/2464530077.py:16: DeprecationWarning: SoftHierarchicalDecoder is deprecated. Use SoftMessagePassingDecoder instead for more robust hierarchical decoding with adaptive detector slicing.\n",
      "  soft_hier_high = SoftHierarchicalDecoder(\n",
      "/Users/scottjones_admin/Library/Mobile Documents/com~apple~CloudDocs/Mac files/Repos/QECToStim/src/qectostim/decoders/soft_hierarchical_decoder.py:190: UserWarning: SoftHierarchicalDecoder: DEM has 1 observables, expected 10 (1 main + 9 inner blocks). Using code-based soft information estimation (may be less accurate).\n",
      "  warnings.warn(\n",
      "/Users/scottjones_admin/Library/Mobile Documents/com~apple~CloudDocs/Mac files/Repos/QECToStim/my_venv/lib/python3.11/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Debug: Find a shot with actual syndrome and decode it properly\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Find shot with actual syndrome\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build circuit with HIGHER error rate for testing\n",
    "P_HIGH = 0.05  # 5% error rate\n",
    "high_exp = ConcatenatedMemoryExperiment(concat, noise_model=P_HIGH, rounds=ROUNDS)\n",
    "high_circuit = high_exp.to_stim()\n",
    "high_dem = high_circuit.detector_error_model(decompose_errors=True)\n",
    "\n",
    "print(f\"Using error rate p={P_HIGH}\")\n",
    "print(f\"Circuit detectors: {high_circuit.num_detectors}\")\n",
    "\n",
    "# Also rebuild soft_hier with this DEM\n",
    "soft_hier_high = SoftHierarchicalDecoder(\n",
    "    code=concat,\n",
    "    dem=high_dem,\n",
    "    rounds=ROUNDS,\n",
    "    basis='Z'\n",
    ")\n",
    "print(f\"SoftHierarchical _inner_decoder_method: {soft_hier_high._inner_decoder_method}\")\n",
    "\n",
    "# Sample shots\n",
    "sampler = high_circuit.compile_detector_sampler()\n",
    "det_sample, obs_sample = sampler.sample(shots=1000, separate_observables=True)\n",
    "\n",
    "# Count shots with syndrome\n",
    "shots_with_syndrome = np.sum(det_sample.sum(axis=1) > 0)\n",
    "print(f\"\\nShots with syndrome: {shots_with_syndrome}/1000\")\n",
    "\n",
    "# Find a shot with inner syndrome\n",
    "test_shot_idx = None\n",
    "test_block_id = None\n",
    "for i in range(1000):\n",
    "    for block_id in range(soft_hier_high.n_blocks):\n",
    "        det_start, det_stop = soft_hier_high.inner_slices[block_id]\n",
    "        if det_sample[i, det_start:det_stop].sum() > 0:\n",
    "            test_shot_idx = i\n",
    "            test_block_id = block_id\n",
    "            break\n",
    "    if test_shot_idx is not None:\n",
    "        break\n",
    "\n",
    "if test_shot_idx is not None:\n",
    "    print(f\"\\nFound shot {test_shot_idx} with syndrome in block {test_block_id}\")\n",
    "    \n",
    "    syndrome = det_sample[test_shot_idx].astype(np.uint8)\n",
    "    det_start, det_stop = soft_hier_high.inner_slices[test_block_id]\n",
    "    block_syndrome = syndrome[det_start:det_stop]\n",
    "    \n",
    "    print(f\"Block {test_block_id} syndrome: {block_syndrome}\")\n",
    "    \n",
    "    # Decode\n",
    "    decoder = soft_hier_high.inner_decoders[test_block_id]\n",
    "    obs_matrix = soft_hier_high.inner_obs_matrices[test_block_id]\n",
    "    \n",
    "    error_pattern = decoder.decode(block_syndrome)\n",
    "    print(f\"Error pattern sum: {error_pattern.sum()}\")\n",
    "    \n",
    "    # Check LLRs\n",
    "    llrs = decoder.log_prob_ratios\n",
    "    print(f\"\\nLLRs all zero: {np.all(llrs == 0)}\")\n",
    "    if not np.all(llrs == 0):\n",
    "        print(f\"LLRs: min={llrs.min():.2f}, max={llrs.max():.2f}\")\n",
    "        \n",
    "        # Compute soft info\n",
    "        obs_dense = obs_matrix.toarray() if hasattr(obs_matrix, 'toarray') else np.asarray(obs_matrix)\n",
    "        \n",
    "        # Convert LLRs to probabilities\n",
    "        # LLR = log(P(no error) / P(error)) => P(error) = 1 / (1 + exp(LLR))\n",
    "        posteriors = 1.0 / (1.0 + np.exp(llrs))\n",
    "        print(f\"Posteriors: min={posteriors.min():.4f}, max={posteriors.max():.4f}\")\n",
    "        \n",
    "        # Use soft XOR to compute P(logical error)\n",
    "        logical_support = obs_dense.flatten()\n",
    "        p_logical = 0.0\n",
    "        for i in range(len(logical_support)):\n",
    "            if logical_support[i]:\n",
    "                p_i = posteriors[i]\n",
    "                p_logical = p_logical * (1 - p_i) + p_i * (1 - p_logical)\n",
    "        print(f\"Soft P(logical error): {p_logical:.4f}\")\n",
    "    else:\n",
    "        print(\"LLRs are all zero - BP didn't converge or no errors\")\n",
    "else:\n",
    "    print(\"No shot with inner syndrome found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e7f840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Verify circuit has noise\n",
      "======================================================================\n",
      "DEM num_errors: 0\n",
      "DEM num_detectors: 62\n",
      "\n",
      "First 20 DEM instructions:\n",
      "  shift_detectors(0, 0, 1) 0\n",
      "  detector(0, 0, 0) D0\n",
      "  detector(0, 1, 0) D1\n",
      "  detector(0, 2, 0) D2\n",
      "  detector(0, 0, 1) D3\n",
      "  detector(0, 1, 1) D4\n",
      "  detector(0, 2, 1) D5\n",
      "  detector(1, 0, 0) D6\n",
      "  detector(1, 1, 0) D7\n",
      "  detector(1, 2, 0) D8\n",
      "  detector(1, 0, 1) D9\n",
      "  detector(1, 1, 1) D10\n",
      "  detector(1, 2, 1) D11\n",
      "  detector(2, 0, 0) D12\n",
      "  detector(2, 1, 0) D13\n",
      "  detector(2, 2, 0) D14\n",
      "  detector(2, 0, 1) D15\n",
      "  detector(2, 1, 1) D16\n",
      "  detector(2, 2, 1) D17\n",
      "  detector(3, 0, 0) D18\n",
      "\n",
      "Circuit does NOT contain error operations ✗\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCircuit does NOT contain error operations ✗\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Try stim's noise injection directly\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m test_circuit = \u001b[43mstim\u001b[49m.Circuit()\n\u001b[32m     26\u001b[39m test_circuit.append(\u001b[33m\"\u001b[39m\u001b[33mH\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[32m0\u001b[39m])\n\u001b[32m     27\u001b[39m test_circuit.append(\u001b[33m\"\u001b[39m\u001b[33mDEPOLARIZE1\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[32m0\u001b[39m], \u001b[32m0.1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'stim' is not defined"
     ]
    }
   ],
   "source": [
    "# Debug: Verify circuit is actually noisy\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Verify circuit has noise\")  \n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check DEM has errors\n",
    "print(f\"DEM num_errors: {high_dem.num_errors}\")\n",
    "print(f\"DEM num_detectors: {high_dem.num_detectors}\")\n",
    "\n",
    "# Print first few DEM instructions\n",
    "print(f\"\\nFirst 20 DEM instructions:\")\n",
    "dem_str = str(high_dem)\n",
    "lines = dem_str.split('\\n')[:20]\n",
    "for line in lines:\n",
    "    print(f\"  {line}\")\n",
    "\n",
    "# Also check raw circuit has DEPOLARIZE\n",
    "circuit_str = str(high_circuit)\n",
    "if 'DEPOLARIZE' in circuit_str or 'X_ERROR' in circuit_str:\n",
    "    print(\"\\nCircuit contains error operations ✓\")\n",
    "else:\n",
    "    print(\"\\nCircuit does NOT contain error operations ✗\")\n",
    "    \n",
    "# Try stim's noise injection directly\n",
    "test_circuit = stim.Circuit()\n",
    "test_circuit.append(\"H\", [0])\n",
    "test_circuit.append(\"DEPOLARIZE1\", [0], 0.1)\n",
    "test_circuit.append(\"M\", [0])\n",
    "\n",
    "test_sampler = test_circuit.compile_sampler()\n",
    "test_samples = test_sampler.sample(100)\n",
    "print(f\"\\nTest circuit: {test_samples.sum()}/100 shots had '1' measurement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87c2042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Proper noise application\n",
      "======================================================================\n",
      "Ideal circuit: 62 detectors\n",
      "Ideal circuit has DEPOLARIZE: False\n",
      "\n",
      "Noisy circuit has DEPOLARIZE: True\n",
      "Noisy DEM: 303 errors, 62 detectors\n",
      "\n",
      "Shots with syndrome: 100/100\n",
      "\n",
      "======================================================================\n",
      "Testing SoftHierarchical with properly noisy circuit\n",
      "======================================================================\n",
      "_inner_decoder_method: template_dem\n",
      "\n",
      "Found shot 0 with syndrome in block 0\n",
      "Block 0 syndrome: [0 0 1 1 1 0]\n",
      "LLRs all zero: False\n",
      "LLRs: min=0.61, max=4.90, mean=2.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/465652225.py:39: DeprecationWarning: SoftHierarchicalDecoder is deprecated. Use SoftMessagePassingDecoder instead for more robust hierarchical decoding with adaptive detector slicing.\n",
      "  soft_hier_noisy = SoftHierarchicalDecoder(\n"
     ]
    }
   ],
   "source": [
    "# Debug: Build circuit WITH PROPER NOISE APPLICATION\n",
    "import stim\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Proper noise application\")  \n",
    "print(\"=\"*70)\n",
    "\n",
    "P_TEST = 0.05\n",
    "noise = CircuitDepolarizingNoise(p1=P_TEST, p2=P_TEST, before_measure_flip=P_TEST)\n",
    "\n",
    "# Build experiment  \n",
    "test_exp = ConcatenatedMemoryExperiment(concat, noise_model=noise, rounds=ROUNDS)\n",
    "\n",
    "# Get ideal circuit\n",
    "ideal_circuit = test_exp.to_stim()\n",
    "print(f\"Ideal circuit: {ideal_circuit.num_detectors} detectors\")\n",
    "print(f\"Ideal circuit has DEPOLARIZE: {'DEPOLARIZE' in str(ideal_circuit)}\")\n",
    "\n",
    "# Apply noise \n",
    "noisy_circuit = noise.apply(ideal_circuit)\n",
    "print(f\"\\nNoisy circuit has DEPOLARIZE: {'DEPOLARIZE' in str(noisy_circuit)}\")\n",
    "\n",
    "# Build DEM (allow hyperedges for concatenated code)\n",
    "noisy_dem = noisy_circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
    "print(f\"Noisy DEM: {noisy_dem.num_errors} errors, {noisy_dem.num_detectors} detectors\")\n",
    "\n",
    "# Sample with noise\n",
    "sampler = noisy_circuit.compile_detector_sampler()\n",
    "det_sample, obs_sample = sampler.sample(shots=100, separate_observables=True)\n",
    "\n",
    "shots_with_syndrome = np.sum(det_sample.sum(axis=1) > 0)\n",
    "print(f\"\\nShots with syndrome: {shots_with_syndrome}/100\")\n",
    "\n",
    "# Now test SoftHierarchical with this properly noisy circuit/DEM\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Testing SoftHierarchical with properly noisy circuit\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Rebuild SoftHierarchical with the noisy DEM\n",
    "soft_hier_noisy = SoftHierarchicalDecoder(\n",
    "    code=concat,\n",
    "    dem=noisy_dem,\n",
    "    rounds=ROUNDS,\n",
    "    basis='Z'\n",
    ")\n",
    "print(f\"_inner_decoder_method: {soft_hier_noisy._inner_decoder_method}\")\n",
    "\n",
    "# Find shot with inner syndrome\n",
    "test_shot_idx = None\n",
    "test_block_id = None\n",
    "for i in range(100):\n",
    "    for block_id in range(soft_hier_noisy.n_blocks):\n",
    "        det_start, det_stop = soft_hier_noisy.inner_slices[block_id]\n",
    "        if det_sample[i, det_start:det_stop].sum() > 0:\n",
    "            test_shot_idx = i\n",
    "            test_block_id = block_id\n",
    "            break\n",
    "    if test_shot_idx is not None:\n",
    "        break\n",
    "\n",
    "if test_shot_idx is not None:\n",
    "    print(f\"\\nFound shot {test_shot_idx} with syndrome in block {test_block_id}\")\n",
    "    \n",
    "    syndrome = det_sample[test_shot_idx].astype(np.uint8)\n",
    "    det_start, det_stop = soft_hier_noisy.inner_slices[test_block_id]\n",
    "    block_syndrome = syndrome[det_start:det_stop]\n",
    "    \n",
    "    print(f\"Block {test_block_id} syndrome: {block_syndrome}\")\n",
    "    \n",
    "    # Decode the block\n",
    "    decoder = soft_hier_noisy.inner_decoders[test_block_id]\n",
    "    error_pattern = decoder.decode(block_syndrome)\n",
    "    \n",
    "    # Check LLRs\n",
    "    llrs = decoder.log_prob_ratios\n",
    "    print(f\"LLRs all zero: {np.all(llrs == 0)}\")\n",
    "    if not np.all(llrs == 0):\n",
    "        print(f\"LLRs: min={llrs.min():.2f}, max={llrs.max():.2f}, mean={llrs.mean():.2f}\")\n",
    "else:\n",
    "    print(\"No shot with inner syndrome found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98aa83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST: SoftHierarchical full decode with proper noise\n",
      "======================================================================\n",
      "Samples: 1000 shots\n",
      "Shots with syndrome: 1000/1000\n",
      "\n",
      "SoftHierarchical LER: 0.5000\n",
      "Errors: 500/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ERROR: OSD order '10' invalid. The 'osd_method' is set to 'OSD_0'. The osd order must therefore be set to 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstimbposd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdem_to_matrices\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detector_error_model_to_check_matrices\n\u001b[32m     27\u001b[39m matrices = detector_error_model_to_check_matrices(noisy_dem, allow_undecomposed_hyperedges=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m bposd = \u001b[43mbposd_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatrices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannel_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatrices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpriors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbp_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduct_sum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mosd_order\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m bposd_predictions = []\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(SHOTS):\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc_python/ldpc/bposd_decoder/_bposd_decoder.pyx:66\u001b[39m, in \u001b[36mldpc.bposd_decoder._bposd_decoder.BpOsdDecoder.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc_python/ldpc/bposd_decoder/_bposd_decoder.pyx:227\u001b[39m, in \u001b[36mldpc.bposd_decoder._bposd_decoder.BpOsdDecoder.osd_order.__set__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: ERROR: OSD order '10' invalid. The 'osd_method' is set to 'OSD_0'. The osd order must therefore be set to 0."
     ]
    }
   ],
   "source": [
    "# Test full decode and compute LER\n",
    "print(\"=\"*70)\n",
    "print(\"TEST: SoftHierarchical full decode with proper noise\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample more shots\n",
    "SHOTS = 1000\n",
    "det_samples, obs_samples = sampler.sample(shots=SHOTS, separate_observables=True)\n",
    "\n",
    "print(f\"Samples: {SHOTS} shots\")\n",
    "print(f\"Shots with syndrome: {np.sum(det_samples.sum(axis=1) > 0)}/{SHOTS}\")\n",
    "\n",
    "# Decode all shots\n",
    "predictions = soft_hier_noisy.decode_batch(det_samples.astype(np.uint8))\n",
    "\n",
    "# Compute LER\n",
    "errors = np.sum(predictions.flatten() != obs_samples.flatten())\n",
    "ler = errors / SHOTS\n",
    "\n",
    "print(f\"\\nSoftHierarchical LER: {ler:.4f}\")\n",
    "print(f\"Errors: {errors}/{SHOTS}\")\n",
    "\n",
    "# Compare with BPOSD\n",
    "from ldpc import bposd_decoder\n",
    "from stimbposd.dem_to_matrices import detector_error_model_to_check_matrices\n",
    "\n",
    "matrices = detector_error_model_to_check_matrices(noisy_dem, allow_undecomposed_hyperedges=True)\n",
    "bposd = bposd_decoder(\n",
    "    matrices.check_matrix,\n",
    "    channel_probs=matrices.priors,\n",
    "    max_iter=50,\n",
    "    bp_method=\"product_sum\",\n",
    "    osd_order=10,\n",
    ")\n",
    "\n",
    "bposd_predictions = []\n",
    "for i in range(SHOTS):\n",
    "    error_pattern = bposd.decode(det_samples[i].astype(np.uint8))\n",
    "    obs_dense = matrices.observables_matrix.toarray()\n",
    "    pred = int(obs_dense @ error_pattern % 2)\n",
    "    bposd_predictions.append(pred)\n",
    "bposd_predictions = np.array(bposd_predictions)\n",
    "\n",
    "bposd_errors = np.sum(bposd_predictions != obs_samples.flatten())\n",
    "bposd_ler = bposd_errors / SHOTS\n",
    "\n",
    "print(f\"\\nBPOSD LER: {bposd_ler:.4f}\")\n",
    "print(f\"Errors: {bposd_errors}/{SHOTS}\")\n",
    "\n",
    "print(f\"\\nRatio: SoftHierarchical / BPOSD = {ler/bposd_ler:.1f}x\" if bposd_ler > 0 else \"BPOSD perfect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74b59c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Trace soft info computation for one block\n",
      "======================================================================\n",
      "Shot 0: true observable = [False]\n",
      "\n",
      "Block 0: syndrome = [0 0 0 1 1 1], weight = 3\n",
      "  Error pattern weight: 1\n",
      "  Hard prediction: 0\n",
      "  LLRs: min=-0.50, max=5.67\n",
      "  Posteriors: min=0.0034, max=0.6223\n",
      "  P(logical error) via soft XOR: 0.4469\n",
      "  P(logical error) from decoder method: 0.4469\n",
      "\n",
      "--- Full _decode_inner_block output ---\n",
      "  hard = 0, p_logical = 0.4469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/1753067461.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  hard_pred = int(obs_dense @ error_pattern % 2)\n"
     ]
    }
   ],
   "source": [
    "# Debug: Trace the soft information computation step by step\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Trace soft info computation for one block\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Pick a shot with syndrome\n",
    "test_idx = 0\n",
    "syndrome = det_samples[test_idx].astype(np.uint8)\n",
    "true_obs = obs_samples[test_idx]\n",
    "\n",
    "print(f\"Shot {test_idx}: true observable = {true_obs}\")\n",
    "\n",
    "# Find block with syndrome\n",
    "for block_id in range(soft_hier_noisy.n_blocks):\n",
    "    det_start, det_stop = soft_hier_noisy.inner_slices[block_id]\n",
    "    block_syn = syndrome[det_start:det_stop]\n",
    "    if block_syn.sum() > 0:\n",
    "        print(f\"\\nBlock {block_id}: syndrome = {block_syn}, weight = {block_syn.sum()}\")\n",
    "        \n",
    "        # Get decoder and decode\n",
    "        decoder = soft_hier_noisy.inner_decoders[block_id]\n",
    "        obs_matrix = soft_hier_noisy.inner_obs_matrices[block_id]\n",
    "        \n",
    "        error_pattern = decoder.decode(block_syn)\n",
    "        print(f\"  Error pattern weight: {error_pattern.sum()}\")\n",
    "        \n",
    "        # Hard prediction\n",
    "        obs_dense = obs_matrix.toarray() if hasattr(obs_matrix, 'toarray') else np.asarray(obs_matrix)\n",
    "        hard_pred = int(obs_dense @ error_pattern % 2)\n",
    "        print(f\"  Hard prediction: {hard_pred}\")\n",
    "        \n",
    "        # LLRs\n",
    "        llrs = decoder.log_prob_ratios\n",
    "        print(f\"  LLRs: min={llrs.min():.2f}, max={llrs.max():.2f}\")\n",
    "        \n",
    "        # Convert LLRs to probabilities\n",
    "        # LLR = log(P(no error) / P(error)) => P(error) = 1 / (1 + exp(LLR))\n",
    "        posteriors = 1.0 / (1.0 + np.exp(llrs))\n",
    "        print(f\"  Posteriors: min={posteriors.min():.4f}, max={posteriors.max():.4f}\")\n",
    "        \n",
    "        # Compute P(logical error) via soft XOR\n",
    "        logical_support = obs_dense.flatten()\n",
    "        p_logical = 0.0\n",
    "        for i in range(min(len(logical_support), len(posteriors))):\n",
    "            if logical_support[i]:\n",
    "                p_i = posteriors[i]\n",
    "                p_logical = p_logical * (1 - p_i) + p_i * (1 - p_logical)\n",
    "        print(f\"  P(logical error) via soft XOR: {p_logical:.4f}\")\n",
    "        \n",
    "        # What does the decoder's _compute_logical_error_prob_from_llrs return?\n",
    "        p_from_decoder = soft_hier_noisy._compute_logical_error_prob_from_llrs(\n",
    "            llrs, obs_matrix, error_pattern\n",
    "        )\n",
    "        print(f\"  P(logical error) from decoder method: {p_from_decoder:.4f}\")\n",
    "        \n",
    "        break  # Just one block for now\n",
    "\n",
    "# Now check what _decode_inner_block returns\n",
    "print(\"\\n--- Full _decode_inner_block output ---\")\n",
    "hard, p_logical = soft_hier_noisy._decode_inner_block(block_id, block_syn)\n",
    "print(f\"  hard = {hard}, p_logical = {p_logical:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "976f2d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Check dimension alignment\n",
      "======================================================================\n",
      "Template circuit: 6 detectors, 1 observables\n",
      "Template DEM: 6 detectors, 1 observables, 31 errors\n",
      "\n",
      "Template matrices:\n",
      "  check_matrix shape: (6, 22)\n",
      "  observables_matrix shape: (1, 22)\n",
      "  priors length: 22\n",
      "\n",
      "Actual inner block:\n",
      "  detectors: 6\n",
      "  check_matrix rows: 6\n",
      "\n",
      "Decoder output (error_pattern):\n",
      "  shape: (22,)\n",
      "  obs_matrix shape: (1, 22)\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check dimension alignment\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Check dimension alignment\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get Template DEM matrices for inner code\n",
    "template_exp = CSSMemoryExperiment(\n",
    "    code=inner,\n",
    "    rounds=ROUNDS,\n",
    "    noise_model=noise,\n",
    "    basis='Z'\n",
    ")\n",
    "template_circuit = template_exp.to_stim()\n",
    "noisy_template = noise.apply(template_circuit)\n",
    "template_dem = noisy_template.detector_error_model(decompose_errors=True)\n",
    "\n",
    "print(f\"Template circuit: {noisy_template.num_detectors} detectors, {noisy_template.num_observables} observables\")\n",
    "print(f\"Template DEM: {template_dem.num_detectors} detectors, {template_dem.num_observables} observables, {template_dem.num_errors} errors\")\n",
    "\n",
    "# Get matrices\n",
    "from stimbposd.dem_to_matrices import detector_error_model_to_check_matrices\n",
    "template_matrices = detector_error_model_to_check_matrices(template_dem, allow_undecomposed_hyperedges=True)\n",
    "\n",
    "print(f\"\\nTemplate matrices:\")\n",
    "print(f\"  check_matrix shape: {template_matrices.check_matrix.shape}\")  # (n_detectors, n_error_vars)\n",
    "print(f\"  observables_matrix shape: {template_matrices.observables_matrix.shape}\")  # (n_obs, n_error_vars)\n",
    "print(f\"  priors length: {len(template_matrices.priors)}\")\n",
    "\n",
    "# Compare with actual inner block\n",
    "block_id = 0\n",
    "det_start, det_stop = soft_hier_noisy.inner_slices[block_id]\n",
    "actual_inner_dets = det_stop - det_start\n",
    "\n",
    "print(f\"\\nActual inner block:\")\n",
    "print(f\"  detectors: {actual_inner_dets}\")\n",
    "print(f\"  check_matrix rows: {template_matrices.check_matrix.shape[0]}\")\n",
    "\n",
    "# The issue: Template DEM has more error variables than the block syndrome\n",
    "# When we decode block_syndrome (6 elements) with a decoder built for 6-detector DEM,\n",
    "# everything aligns. BUT the observables_matrix has 22 columns (error vars) which\n",
    "# must match the decoder output.\n",
    "\n",
    "decoder = soft_hier_noisy.inner_decoders[block_id]\n",
    "error_pattern = decoder.decode(block_syn)\n",
    "print(f\"\\nDecoder output (error_pattern):\")\n",
    "print(f\"  shape: {error_pattern.shape}\")\n",
    "print(f\"  obs_matrix shape: {soft_hier_noisy.inner_obs_matrices[block_id].shape}\")\n",
    "\n",
    "# The issue is that:\n",
    "# - Block syndrome has 6 detectors\n",
    "# - Template DEM has 6 detectors  \n",
    "# - But Template DEM has 22 error variables (columns in check_matrix)\n",
    "# - obs_matrix has shape (1, 22)\n",
    "# - error_pattern has 22 elements (matches!)\n",
    "# So dimensions align correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "450943af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Full decode path for one shot\n",
      "======================================================================\n",
      "Shot 0: true observable = [False], syndrome weight = 19\n",
      "\n",
      "--- Step 1: Inner block decoding ---\n",
      "  Block 0: syn_wt=3, hard=0, p_log=0.4469\n",
      "  Block 1: syn_wt=2, hard=0, p_log=0.3612\n",
      "  Block 2: syn_wt=2, hard=0, p_log=0.1678\n",
      "  Block 3: syn_wt=2, hard=0, p_log=0.3878\n",
      "  Block 4: syn_wt=2, hard=0, p_log=0.3612\n",
      "  Block 6: syn_wt=2, hard=0, p_log=0.3612\n",
      "  Block 7: syn_wt=1, hard=1, p_log=0.5113\n",
      "  Block 8: syn_wt=2, hard=0, p_log=0.3648\n",
      "\n",
      "Inner hard decisions: [0 0 0 0 0 0 0 1 0]\n",
      "Inner logical probs: [0.44692213 0.36123086 0.16779634 0.38778383 0.36123086 0.01\n",
      " 0.36123086 0.51131064 0.36484584]\n",
      "\n",
      "--- Step 2: Outer syndrome and decoding ---\n",
      "Outer slice: (54, 62)\n",
      "Raw outer syndrome: [1 1 1 0 0 0 0 0], weight = 3\n",
      "H_outer shape: (4, 9)\n",
      "Inner contribution to outer syndrome: [0 0 1 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m inner_contrib = (inner_hard_decisions @ H_outer.T) % \u001b[32m2\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInner contribution to outer syndrome: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_contrib\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m effective_outer = \u001b[43mraw_outer_syndrome\u001b[49m\u001b[43m \u001b[49m\u001b[43m^\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_contrib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEffective outer syndrome: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meffective_outer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Check if outer decoder exists\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (8,) (4,) "
     ]
    }
   ],
   "source": [
    "# Debug: Trace the full decode path for one shot\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Full decode path for one shot\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_idx = 0\n",
    "syndrome = det_samples[test_idx].astype(np.uint8)\n",
    "true_obs = obs_samples[test_idx]\n",
    "\n",
    "print(f\"Shot {test_idx}: true observable = {true_obs}, syndrome weight = {syndrome.sum()}\")\n",
    "\n",
    "# Step 1: Decode all inner blocks\n",
    "inner_hard_decisions = np.zeros(soft_hier_noisy.n_blocks, dtype=np.uint8)\n",
    "inner_logical_probs = np.zeros(soft_hier_noisy.n_blocks, dtype=np.float64)\n",
    "\n",
    "print(\"\\n--- Step 1: Inner block decoding ---\")\n",
    "for block_id in range(soft_hier_noisy.n_blocks):\n",
    "    det_start, det_stop = soft_hier_noisy.inner_slices[block_id]\n",
    "    block_syn = syndrome[det_start:det_stop]\n",
    "    \n",
    "    hard, p_logical = soft_hier_noisy._decode_inner_block(block_id, block_syn)\n",
    "    inner_hard_decisions[block_id] = hard\n",
    "    inner_logical_probs[block_id] = p_logical\n",
    "    \n",
    "    if block_syn.sum() > 0:\n",
    "        print(f\"  Block {block_id}: syn_wt={block_syn.sum()}, hard={hard}, p_log={p_logical:.4f}\")\n",
    "\n",
    "print(f\"\\nInner hard decisions: {inner_hard_decisions}\")\n",
    "print(f\"Inner logical probs: {inner_logical_probs}\")\n",
    "\n",
    "# Step 2: Outer decoding\n",
    "print(\"\\n--- Step 2: Outer syndrome and decoding ---\")\n",
    "outer_start, outer_stop = soft_hier_noisy.outer_slice\n",
    "raw_outer_syndrome = syndrome[outer_start:outer_stop].astype(np.uint8)\n",
    "print(f\"Outer slice: {soft_hier_noisy.outer_slice}\")\n",
    "print(f\"Raw outer syndrome: {raw_outer_syndrome}, weight = {raw_outer_syndrome.sum()}\")\n",
    "\n",
    "# Inner logical errors flip outer stabilizers\n",
    "H_outer = soft_hier_noisy.H_outer\n",
    "print(f\"H_outer shape: {H_outer.shape}\")\n",
    "\n",
    "inner_contrib = (inner_hard_decisions @ H_outer.T) % 2\n",
    "print(f\"Inner contribution to outer syndrome: {inner_contrib}\")\n",
    "\n",
    "effective_outer = raw_outer_syndrome ^ inner_contrib.astype(np.uint8)\n",
    "print(f\"Effective outer syndrome: {effective_outer}\")\n",
    "\n",
    "# Check if outer decoder exists\n",
    "print(f\"\\nOuter decoder exists: {soft_hier_noisy.outer_decoder is not None}\")\n",
    "if soft_hier_noisy.outer_decoder is not None:\n",
    "    print(f\"Outer decoder type: {type(soft_hier_noisy.outer_decoder).__name__}\")\n",
    "    print(f\"Outer base channel probs: {soft_hier_noisy._outer_base_channel_probs}\")\n",
    "    print(f\"_has_inner_observables: {soft_hier_noisy._has_inner_observables}\")\n",
    "\n",
    "# Step 3: Final prediction\n",
    "print(\"\\n--- Step 3: Final prediction ---\")\n",
    "outer_logical_support = soft_hier_noisy.outer_logical_support\n",
    "print(f\"Outer logical support: {outer_logical_support}\")\n",
    "\n",
    "inner_parity = 0\n",
    "for block_id in outer_logical_support:\n",
    "    if block_id < soft_hier_noisy.n_blocks:\n",
    "        inner_parity ^= inner_hard_decisions[block_id]\n",
    "print(f\"Inner parity (from blocks in outer logical support): {inner_parity}\")\n",
    "\n",
    "# Full decode\n",
    "full_pred = soft_hier_noisy._decode_single_shot(syndrome)\n",
    "print(f\"\\nFull prediction: {full_pred}\")\n",
    "print(f\"True observable: {int(true_obs[0])}\")\n",
    "print(f\"Correct: {full_pred == int(true_obs[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "158a8866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Outer syndrome dimension mismatch\n",
      "======================================================================\n",
      "Outer slice: (54, 62)\n",
      "Raw outer syndrome shape: (8,)\n",
      "H_outer shape: (4, 9)\n",
      "n_outer_stabs (from decoder): 4\n",
      "\n",
      "Outer code: RotatedSurfaceCode\n",
      "  n=9, k=1\n",
      "  hx shape: (4, 9)\n",
      "  hz shape: (4, 9)\n",
      "  Total stabs: 8\n",
      "\n",
      "Slices from experiment:\n",
      "  outer_dets: 8\n",
      "  total_detectors: 62\n",
      "  basis: Z\n",
      "\n",
      "H_outer matrix:\n",
      "[[0 0 0 1 0 0 1 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 1]\n",
      " [0 0 1 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Investigate the outer syndrome mismatch\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Outer syndrome dimension mismatch\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Outer slice: {soft_hier_noisy.outer_slice}\")\n",
    "print(f\"Raw outer syndrome shape: {raw_outer_syndrome.shape}\")\n",
    "print(f\"H_outer shape: {soft_hier_noisy.H_outer.shape}\")\n",
    "print(f\"n_outer_stabs (from decoder): {soft_hier_noisy.n_outer_stabs}\")\n",
    "\n",
    "# Check outer code\n",
    "outer_code = soft_hier_noisy.outer_code\n",
    "print(f\"\\nOuter code: {outer_code.name}\")\n",
    "print(f\"  n={outer_code.n}, k={outer_code.k}\")\n",
    "print(f\"  hx shape: {outer_code.hx.shape}\")\n",
    "print(f\"  hz shape: {outer_code.hz.shape}\")\n",
    "print(f\"  Total stabs: {outer_code.hx.shape[0] + outer_code.hz.shape[0]}\")\n",
    "\n",
    "# The outer syndrome has 8 elements, but H_outer has only 4 rows\n",
    "# This is because:\n",
    "# - RotatedSurfaceCode(d=3) has 4 X-stabilizers + 4 Z-stabilizers = 8 total\n",
    "# - But in Z-basis memory, only Z-stabilizers are measured\n",
    "# - OR the detector slicing is including both time-like and space-like\n",
    "\n",
    "# Check experiment slices\n",
    "print(f\"\\nSlices from experiment:\")\n",
    "slices = concat_exp.get_detector_slices()\n",
    "print(f\"  outer_dets: {slices['outer_dets']}\")\n",
    "print(f\"  total_detectors: {slices['total_detectors']}\")\n",
    "print(f\"  basis: {slices['basis']}\")\n",
    "\n",
    "# The issue: For Z-basis memory with rounds=1:\n",
    "# - We have time-like detectors (comparing rounds) and space-like (comparing final measurement)\n",
    "# - For rounds=1, there's no previous round, so time-like = 0\n",
    "# - Space-like detectors = Z-stabilizers for Z-basis\n",
    "# BUT the outer syndrome has 8 elements, which is 4 (Z-stabs) * 2 (time-like + space-like)?\n",
    "\n",
    "# Actually for rounds=1:\n",
    "# - Inner blocks: 6 detectors each (3 Z-stabs × 2 for time-like + space-like?)\n",
    "# - Outer: 8 detectors\n",
    "\n",
    "# Let's check how H_outer is built\n",
    "print(f\"\\nH_outer matrix:\")\n",
    "print(soft_hier_noisy.H_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc1da229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Detector structure in concatenated circuit\n",
      "======================================================================\n",
      "Outer code X-stabilizers (hx): shape (4, 9)\n",
      "[[1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 1 1 0]\n",
      " [0 1 1 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1]]\n",
      "\n",
      "Outer code Z-stabilizers (hz): shape (4, 9)\n",
      "[[0 0 0 1 0 0 1 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 1]\n",
      " [0 0 1 0 0 1 0 0 0]]\n",
      "\n",
      "Current H_outer in decoder (using hz):\n",
      "[[0 0 0 1 0 0 1 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 1]\n",
      " [0 0 1 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Understand detector structure in concatenated circuit\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Detector structure in concatenated circuit\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# For a CSS code in Z-basis memory:\n",
    "# - X stabilizers detect Z errors\n",
    "# - Z stabilizers detect X errors\n",
    "# \n",
    "# For concatenation:\n",
    "# - Inner blocks: each has (inner_x_stabs + inner_z_stabs) detectors\n",
    "# - Steane code: 3 X-stabs + 3 Z-stabs = 6 detectors per block\n",
    "#\n",
    "# For Z-basis memory (protecting Z logical):\n",
    "# - Physical X errors → flip Z stabilizers\n",
    "# - Physical Z errors → flip X stabilizers\n",
    "# - Inner logical Z error = product of Z on L_z support\n",
    "# - Inner logical Z error flips which OUTER stabilizers?\n",
    "\n",
    "# In concatenation, the inner code's n physical qubits become \"logical\" qubits\n",
    "# of the outer code. So:\n",
    "# - Outer X-stabilizer acts on a subset of inner blocks\n",
    "# - If inner block i has a logical Z error, this is like a \"Z error\" on \n",
    "#   outer qubit i, which flips outer X-stabilizers that include i\n",
    "\n",
    "# Therefore for Z-basis:\n",
    "# - Inner Z-type logical errors flip OUTER X-stabilizers\n",
    "# - H_outer should be outer_code.hx, not outer_code.hz!\n",
    "\n",
    "print(f\"Outer code X-stabilizers (hx): shape {outer_code.hx.shape}\")\n",
    "print(outer_code.hx)\n",
    "print(f\"\\nOuter code Z-stabilizers (hz): shape {outer_code.hz.shape}\")\n",
    "print(outer_code.hz)\n",
    "\n",
    "print(f\"\\nCurrent H_outer in decoder (using hz):\")\n",
    "print(soft_hier_noisy.H_outer)\n",
    "\n",
    "# The bug: H_outer uses hz but should use hx for Z-basis\n",
    "# Because inner Z-logical errors (which affect the Z measurement outcome)\n",
    "# manifest as outer X-stabilizer violations\n",
    "\n",
    "# Fix: For Z-basis, use hx; for X-basis, use hz\n",
    "# (This is the CSS duality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd0dc732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST: Fix H_outer to use hx for Z-basis\n",
      "======================================================================\n",
      "Fixed H_outer shape: (4, 9)\n",
      "Fixed n_outer_stabs: 4\n",
      "\n",
      "SoftHierarchical LER (with hx fix): 0.5240\n",
      "Errors: 262/500\n",
      "✗ Still near random - not the fix\n"
     ]
    }
   ],
   "source": [
    "# THEORY: For Z-basis, H_outer should be hx, not hz\n",
    "# Let's test by manually fixing the decoder and re-running\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST: Fix H_outer to use hx for Z-basis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Manually patch the decoder to use hx instead of hz\n",
    "# For Z-basis: Z errors flip X-stabilizers\n",
    "soft_hier_noisy.H_outer = np.array(outer_code.hx, dtype=np.uint8)\n",
    "soft_hier_noisy.n_outer_stabs = soft_hier_noisy.H_outer.shape[0]\n",
    "\n",
    "print(f\"Fixed H_outer shape: {soft_hier_noisy.H_outer.shape}\")\n",
    "print(f\"Fixed n_outer_stabs: {soft_hier_noisy.n_outer_stabs}\")\n",
    "\n",
    "# Re-test LER\n",
    "SHOTS = 500\n",
    "det_samples2, obs_samples2 = sampler.sample(shots=SHOTS, separate_observables=True)\n",
    "\n",
    "predictions = soft_hier_noisy.decode_batch(det_samples2.astype(np.uint8))\n",
    "errors = np.sum(predictions.flatten() != obs_samples2.flatten())\n",
    "ler = errors / SHOTS\n",
    "\n",
    "print(f\"\\nSoftHierarchical LER (with hx fix): {ler:.4f}\")\n",
    "print(f\"Errors: {errors}/{SHOTS}\")\n",
    "\n",
    "# Check if this is better than random (0.50)\n",
    "if ler < 0.45:\n",
    "    print(\"✓ Better than random!\")\n",
    "else:\n",
    "    print(\"✗ Still near random - not the fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41ea68ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Outer decoder state\n",
      "======================================================================\n",
      "outer_decoder: <ldpc._legacy_ldpc_v1._legacy_bposd_decoder.bposd_decoder object at 0x131200520>\n",
      "outer_decoder type: <class 'ldpc._legacy_ldpc_v1._legacy_bposd_decoder.bposd_decoder'>\n",
      "outer_matrices: DemMatrices(check_matrix=<Compressed Sparse Column sparse matrix of dtype 'uint8'\n",
      "\twith 22 stored elements and shape (8, 13)>, observables_matrix=<Compressed Sparse Column sparse matrix of dtype 'uint8'\n",
      "\twith 4 stored elements and shape (1, 13)>, edge_check_matrix=<Compressed Sparse Column sparse matrix of dtype 'uint8'\n",
      "\twith 22 stored elements and shape (8, 13)>, edge_observables_matrix=<Compressed Sparse Column sparse matrix of dtype 'uint8'\n",
      "\twith 4 stored elements and shape (1, 13)>, hyperedge_to_edge_matrix=<Compressed Sparse Column sparse matrix of dtype 'uint8'\n",
      "\twith 13 stored elements and shape (13, 13)>, priors=array([0.06965543, 0.01      , 0.03613333, 0.01      , 0.03613333,\n",
      "       0.01      , 0.06965543, 0.02666667, 0.11822827, 0.02666667,\n",
      "       0.17611187, 0.17611187, 0.11822827]))\n",
      "outer_obs_matrix: <Compressed Sparse Column sparse matrix of dtype 'uint8'\n",
      "\twith 4 stored elements and shape (1, 13)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "_outer_base_channel_probs: [0.06965543 0.01       0.03613333 0.01       0.03613333 0.01\n",
      " 0.06965543 0.02666667 0.11822827 0.02666667 0.17611187 0.17611187\n",
      " 0.11822827]\n",
      "_has_inner_observables: False\n",
      "\n",
      "--- Let's check what _build_outer_decoder does ---\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check if outer decoder even exists\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Outer decoder state\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"outer_decoder: {soft_hier_noisy.outer_decoder}\")\n",
    "print(f\"outer_decoder type: {type(soft_hier_noisy.outer_decoder)}\")\n",
    "print(f\"outer_matrices: {soft_hier_noisy.outer_matrices}\")\n",
    "print(f\"outer_obs_matrix: {soft_hier_noisy.outer_obs_matrix}\")\n",
    "print(f\"_outer_base_channel_probs: {soft_hier_noisy._outer_base_channel_probs}\")\n",
    "print(f\"_has_inner_observables: {soft_hier_noisy._has_inner_observables}\")\n",
    "\n",
    "# The issue might be that the outer decoder isn't being built at all!\n",
    "# Or it's not being used properly\n",
    "\n",
    "# Check the _build_outer_decoder method behavior\n",
    "print(\"\\n--- Let's check what _build_outer_decoder does ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45857516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST: Renormalization fix for Template DEM\n",
      "======================================================================\n",
      "_inner_decoder_method: template_dem\n",
      "_has_inner_observables: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/2372481172.py:12: DeprecationWarning: SoftHierarchicalDecoder is deprecated. Use SoftMessagePassingDecoder instead for more robust hierarchical decoding with adaptive detector slicing.\n",
      "  soft_hier_fixed = SoftHierarchicalDecoder(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SoftHierarchical LER (with renormalization fix): 0.4620\n",
      "Errors: 231/500\n",
      "✗ Still near random\n"
     ]
    }
   ],
   "source": [
    "# Test the renormalization fix\n",
    "import importlib\n",
    "from qectostim.decoders import soft_hierarchical_decoder\n",
    "importlib.reload(soft_hierarchical_decoder)\n",
    "from qectostim.decoders.soft_hierarchical_decoder import SoftHierarchicalDecoder\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST: Renormalization fix for Template DEM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Rebuild decoder with reloaded module\n",
    "soft_hier_fixed = SoftHierarchicalDecoder(\n",
    "    code=concat,\n",
    "    dem=noisy_dem,\n",
    "    rounds=ROUNDS,\n",
    "    basis='Z'\n",
    ")\n",
    "\n",
    "print(f\"_inner_decoder_method: {soft_hier_fixed._inner_decoder_method}\")\n",
    "print(f\"_has_inner_observables: {soft_hier_fixed._has_inner_observables}\")\n",
    "\n",
    "# Test LER\n",
    "SHOTS = 500\n",
    "det_samples_test, obs_samples_test = sampler.sample(shots=SHOTS, separate_observables=True)\n",
    "\n",
    "predictions_test = soft_hier_fixed.decode_batch(det_samples_test.astype(np.uint8))\n",
    "errors_test = np.sum(predictions_test.flatten() != obs_samples_test.flatten())\n",
    "ler_test = errors_test / SHOTS\n",
    "\n",
    "print(f\"\\nSoftHierarchical LER (with renormalization fix): {ler_test:.4f}\")\n",
    "print(f\"Errors: {errors_test}/{SHOTS}\")\n",
    "\n",
    "if ler_test < 0.45:\n",
    "    print(\"✓ Better than random!\")\n",
    "else:\n",
    "    print(\"✗ Still near random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ae03890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: Trace renormalization\n",
      "======================================================================\n",
      "has_accurate_soft_info check:\n",
      "  _has_inner_observables = False\n",
      "  _inner_decoder_method = template_dem\n",
      "  => has_accurate_soft_info = True\n",
      "\n",
      "outer_decoder = <ldpc._legacy_ldpc_v1._legacy_bposd_decoder.bposd_decoder object at 0x131203070>\n",
      "_outer_base_channel_probs = [0.06965543 0.01       0.03613333 0.01       0.03613333 0.01\n",
      " 0.06965543 0.02666667 0.11822827 0.02666667 0.17611187 0.17611187\n",
      " 0.11822827]\n",
      "\n",
      "Inner logical probs: [0.01, 0.37328855457566834, 0.378090452486859, 0.44663457286115593, 0.3955197538656247, 0.44692212764341704, 0.36123086294994866, 0.579546310990514, 0.41879781841372743]\n",
      "Mean inner prob: 0.3789\n",
      "\n",
      "Base channel probs (first 9): [0.06965543 0.01       0.03613333 0.01       0.03613333 0.01\n",
      " 0.06965543 0.02666667 0.11822827]\n",
      "Inner probs would update these to: [0.01, 0.37328855457566834, 0.378090452486859, 0.44663457286115593, 0.3955197538656247, 0.44692212764341704, 0.36123086294994866, 0.579546310990514, 0.41879781841372743]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Trace renormalization in decode path\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING: Trace renormalization\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if renormalization is happening\n",
    "print(f\"has_accurate_soft_info check:\")\n",
    "print(f\"  _has_inner_observables = {soft_hier_fixed._has_inner_observables}\")\n",
    "print(f\"  _inner_decoder_method = {soft_hier_fixed._inner_decoder_method}\")\n",
    "print(f\"  => has_accurate_soft_info = {soft_hier_fixed._has_inner_observables or soft_hier_fixed._inner_decoder_method == 'template_dem'}\")\n",
    "\n",
    "print(f\"\\nouter_decoder = {soft_hier_fixed.outer_decoder}\")\n",
    "print(f\"_outer_base_channel_probs = {soft_hier_fixed._outer_base_channel_probs}\")\n",
    "\n",
    "# Manually trace a decode\n",
    "test_idx = 0\n",
    "syndrome = det_samples_test[test_idx].astype(np.uint8)\n",
    "\n",
    "# Get inner soft info\n",
    "inner_probs = []\n",
    "for block_id in range(soft_hier_fixed.n_blocks):\n",
    "    det_start, det_stop = soft_hier_fixed.inner_slices[block_id]\n",
    "    block_syn = syndrome[det_start:det_stop]\n",
    "    _, p_logical = soft_hier_fixed._decode_inner_block(block_id, block_syn)\n",
    "    inner_probs.append(p_logical)\n",
    "\n",
    "print(f\"\\nInner logical probs: {inner_probs}\")\n",
    "print(f\"Mean inner prob: {np.mean(inner_probs):.4f}\")\n",
    "\n",
    "# Check if probs are being used\n",
    "print(f\"\\nBase channel probs (first {soft_hier_fixed.n_blocks}): {soft_hier_fixed._outer_base_channel_probs[:soft_hier_fixed.n_blocks]}\")\n",
    "print(f\"Inner probs would update these to: {inner_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f3d1c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FULL DECODE TRACE FOR SINGLE SHOT\n",
      "======================================================================\n",
      "Actual logical: True\n",
      "\n",
      "--- STEP 1: Inner Decoding ---\n",
      "  Block 0: syn=[0 0 0 0 0 0], hard=0, p_log=0.0100\n",
      "  Block 1: syn=[1 0 0 1 1 1], hard=1, p_log=0.3733\n",
      "  Block 2: syn=[0 0 1 0 0 1], hard=0, p_log=0.3781\n",
      "  Block 3: syn=[0 1 0 0 0 0], hard=1, p_log=0.4466\n",
      "  Block 4: syn=[1 0 1 1 0 1], hard=0, p_log=0.3955\n",
      "  Block 5: syn=[0 0 0 1 1 1], hard=0, p_log=0.4469\n",
      "  Block 6: syn=[0 1 0 0 1 0], hard=0, p_log=0.3612\n",
      "  Block 7: syn=[1 1 0 0 0 0], hard=1, p_log=0.5795\n",
      "  Block 8: syn=[1 0 0 0 1 0], hard=1, p_log=0.4188\n",
      "\n",
      "Inner hard: [0 1 0 1 0 0 0 1 1]\n",
      "Inner probs: [0.01       0.37328855 0.37809045 0.44663457 0.39551975 0.44692213\n",
      " 0.36123086 0.57954631 0.41879782]\n",
      "\n",
      "--- STEP 2: Renormalization ---\n",
      "has_accurate_soft_info: True\n",
      "outer_decoder: True\n",
      "_outer_base_channel_probs: True\n",
      "=> Renormalization WILL happen!\n",
      "Base probs: [0.06965543 0.01       0.03613333 0.01       0.03613333 0.01\n",
      " 0.06965543 0.02666667 0.11822827 0.02666667 0.17611187 0.17611187\n",
      " 0.11822827]\n",
      "Updated probs: [0.01       0.37328855 0.37809045 0.44663457 0.39551975 0.44692213\n",
      " 0.36123086 0.57954631 0.41879782 0.02666667 0.17611187 0.17611187\n",
      " 0.11822827]\n",
      "\n",
      "--- STEP 3: Outer Syndrome ---\n",
      "Outer slice: [54, 62)\n",
      "Raw outer syndrome: [0 0 1 1 0 1 0 1]\n",
      "H_outer shape: (4, 9)\n",
      "n_blocks_use=9, n_stabs_use=4\n",
      "Inner contribution: [1 0 0 0]\n",
      "Effective outer syndrome: [1 0 1 1 0 1 0 1]\n",
      "\n",
      "--- STEP 4: Outer Decode ---\n",
      "Outer error pattern: [0 0 1 0 0 0 1 0 0 0 1 0 1]\n",
      "outer_obs_matrix: <Compressed Sparse Column sparse matrix of dtype 'uint8'\n",
      "\twith 4 stored elements and shape (1, 13)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "outer_obs_matrix shape: (1, 13)\n",
      "Outer logical: 0\n",
      "\n",
      "--- STEP 5: Final Combination ---\n",
      "outer_logical_support: {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "  Block 0: inner_hard=0, cumulative parity=0\n",
      "  Block 1: inner_hard=1, cumulative parity=1\n",
      "  Block 2: inner_hard=0, cumulative parity=1\n",
      "  Block 3: inner_hard=1, cumulative parity=0\n",
      "  Block 4: inner_hard=0, cumulative parity=0\n",
      "  Block 5: inner_hard=0, cumulative parity=0\n",
      "  Block 6: inner_hard=0, cumulative parity=0\n",
      "  Block 7: inner_hard=1, cumulative parity=1\n",
      "  Block 8: inner_hard=1, cumulative parity=0\n",
      "\n",
      "Final = outer_logical(0) XOR inner_parity(0) = 0\n",
      "Actual: True, Match: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/475073588.py:73: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  outer_logical = int(obs_dense @ outer_error % 2)\n"
     ]
    }
   ],
   "source": [
    "# Trace FULL decode flow for ONE shot\n",
    "print(\"=\"*70)\n",
    "print(\"FULL DECODE TRACE FOR SINGLE SHOT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_idx = 0\n",
    "syndrome = det_samples_test[test_idx].astype(np.uint8)\n",
    "actual = obs_samples_test[test_idx, 0]\n",
    "\n",
    "print(f\"Actual logical: {actual}\")\n",
    "\n",
    "# Step 1: Inner decoding\n",
    "print(f\"\\n--- STEP 1: Inner Decoding ---\")\n",
    "inner_hard = np.zeros(soft_hier_fixed.n_blocks, dtype=np.uint8)\n",
    "inner_probs = np.zeros(soft_hier_fixed.n_blocks, dtype=np.float64)\n",
    "\n",
    "for block_id in range(soft_hier_fixed.n_blocks):\n",
    "    det_start, det_stop = soft_hier_fixed.inner_slices[block_id]\n",
    "    block_syn = syndrome[det_start:det_stop]\n",
    "    hard, p_log = soft_hier_fixed._decode_inner_block(block_id, block_syn)\n",
    "    inner_hard[block_id] = hard\n",
    "    inner_probs[block_id] = p_log\n",
    "    print(f\"  Block {block_id}: syn={block_syn}, hard={hard}, p_log={p_log:.4f}\")\n",
    "\n",
    "print(f\"\\nInner hard: {inner_hard}\")\n",
    "print(f\"Inner probs: {inner_probs}\")\n",
    "\n",
    "# Step 2: Renormalization check\n",
    "print(f\"\\n--- STEP 2: Renormalization ---\")\n",
    "has_accurate = soft_hier_fixed._has_inner_observables or soft_hier_fixed._inner_decoder_method == 'template_dem'\n",
    "print(f\"has_accurate_soft_info: {has_accurate}\")\n",
    "print(f\"outer_decoder: {soft_hier_fixed.outer_decoder is not None}\")\n",
    "print(f\"_outer_base_channel_probs: {soft_hier_fixed._outer_base_channel_probs is not None}\")\n",
    "\n",
    "if has_accurate and soft_hier_fixed.outer_decoder and soft_hier_fixed._outer_base_channel_probs is not None:\n",
    "    print(\"=> Renormalization WILL happen!\")\n",
    "    updated_probs = soft_hier_fixed._outer_base_channel_probs.copy()\n",
    "    print(f\"Base probs: {updated_probs}\")\n",
    "    \n",
    "    for block_id in range(min(soft_hier_fixed.n_blocks, len(updated_probs))):\n",
    "        updated_probs[block_id] = inner_probs[block_id]\n",
    "    print(f\"Updated probs: {updated_probs}\")\n",
    "else:\n",
    "    print(\"=> NO renormalization!\")\n",
    "\n",
    "# Step 3: Effective outer syndrome\n",
    "print(f\"\\n--- STEP 3: Outer Syndrome ---\")\n",
    "outer_start, outer_stop = soft_hier_fixed.outer_slice\n",
    "raw_outer = syndrome[outer_start:outer_stop].astype(np.uint8)\n",
    "print(f\"Outer slice: [{outer_start}, {outer_stop})\")\n",
    "print(f\"Raw outer syndrome: {raw_outer}\")\n",
    "\n",
    "print(f\"H_outer shape: {soft_hier_fixed.H_outer.shape}\")\n",
    "n_blocks_use = min(soft_hier_fixed.n_blocks, soft_hier_fixed.H_outer.shape[1])\n",
    "n_stabs_use = min(soft_hier_fixed.n_outer_stabs, len(raw_outer))\n",
    "print(f\"n_blocks_use={n_blocks_use}, n_stabs_use={n_stabs_use}\")\n",
    "\n",
    "inner_contrib = (inner_hard[:n_blocks_use] @ soft_hier_fixed.H_outer[:n_stabs_use, :n_blocks_use].T) % 2\n",
    "print(f\"Inner contribution: {inner_contrib}\")\n",
    "\n",
    "effective_syn = raw_outer.copy()\n",
    "effective_syn[:n_stabs_use] ^= inner_contrib.astype(np.uint8)\n",
    "print(f\"Effective outer syndrome: {effective_syn}\")\n",
    "\n",
    "# Step 4: Outer decode\n",
    "print(f\"\\n--- STEP 4: Outer Decode ---\")\n",
    "outer_error = soft_hier_fixed.outer_decoder.decode(effective_syn.astype(np.uint8))\n",
    "print(f\"Outer error pattern: {outer_error}\")\n",
    "print(f\"outer_obs_matrix: {soft_hier_fixed.outer_obs_matrix}\")\n",
    "if soft_hier_fixed.outer_obs_matrix is not None:\n",
    "    print(f\"outer_obs_matrix shape: {soft_hier_fixed.outer_obs_matrix.shape}\")\n",
    "    obs_dense = soft_hier_fixed.outer_obs_matrix.toarray() if hasattr(soft_hier_fixed.outer_obs_matrix, 'toarray') else soft_hier_fixed.outer_obs_matrix\n",
    "    outer_logical = int(obs_dense @ outer_error % 2)\n",
    "    print(f\"Outer logical: {outer_logical}\")\n",
    "else:\n",
    "    outer_logical = 0\n",
    "    print(f\"No outer_obs_matrix, outer_logical=0\")\n",
    "\n",
    "# Step 5: Final combination\n",
    "print(f\"\\n--- STEP 5: Final Combination ---\")\n",
    "inner_parity = 0\n",
    "print(f\"outer_logical_support: {soft_hier_fixed.outer_logical_support}\")\n",
    "for block_id in soft_hier_fixed.outer_logical_support:\n",
    "    if block_id < soft_hier_fixed.n_blocks:\n",
    "        inner_parity ^= inner_hard[block_id]\n",
    "        print(f\"  Block {block_id}: inner_hard={inner_hard[block_id]}, cumulative parity={inner_parity}\")\n",
    "\n",
    "final = outer_logical ^ inner_parity\n",
    "print(f\"\\nFinal = outer_logical({outer_logical}) XOR inner_parity({inner_parity}) = {final}\")\n",
    "print(f\"Actual: {actual}, Match: {final == actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06181e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OUTER DECODER STRUCTURE ANALYSIS\n",
      "======================================================================\n",
      "Decoder attributes related to outer:\n",
      "  H_outer: <class 'numpy.ndarray'>\n",
      "  _outer_base_channel_probs: <class 'numpy.ndarray'>\n",
      "  _outer_n_data_errors: <class 'int'>\n",
      "  n_outer_stabs: <class 'int'>\n",
      "  outer_code: <class 'qectostim.codes.surface.rotated_surface.RotatedSurfaceCode'>\n",
      "  outer_decoder: <class 'ldpc._legacy_ldpc_v1._legacy_bposd_decoder.bposd_decoder'>\n",
      "  outer_logical_support: <class 'set'>\n",
      "  outer_matrices: <class 'stimbposd.dem_to_matrices.DemMatrices'>\n",
      "  outer_obs_matrix: <class 'scipy.sparse._csc.csc_matrix'>\n",
      "  outer_slice: <class 'tuple'>\n",
      "\n",
      "H_outer shape: (4, 9)\n",
      "H_outer:\n",
      "[[0 0 0 1 0 0 1 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 1]\n",
      " [0 0 1 0 0 1 0 0 0]]\n",
      "\n",
      "Outer code hx shape: (4, 9)\n",
      "Outer code hz shape: (4, 9)\n",
      "Outer code hx (X stabilizers):\n",
      "[[1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 1 1 0]\n",
      " [0 1 1 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1]]\n",
      "Outer code hz (Z stabilizers):\n",
      "[[0 0 0 1 0 0 1 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 1]\n",
      " [0 0 1 0 0 1 0 0 0]]\n",
      "\n",
      "outer_obs_matrix shape: (1, 13)\n",
      "outer_obs_matrix:\n",
      "[[1 1 0 1 0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "n_outer_stabs: 4\n",
      "outer_slice: (54, 62)\n",
      "\n",
      "Outer syndrome length: 8\n",
      "H_outer rows: 4\n",
      "MISMATCH: True\n"
     ]
    }
   ],
   "source": [
    "# Understand the outer decoder structure\n",
    "print(\"=\"*70)\n",
    "print(\"OUTER DECODER STRUCTURE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# What attributes exist?\n",
    "print(\"Decoder attributes related to outer:\")\n",
    "for attr in dir(soft_hier_fixed):\n",
    "    if 'outer' in attr.lower():\n",
    "        val = getattr(soft_hier_fixed, attr, None)\n",
    "        if not callable(val):\n",
    "            print(f\"  {attr}: {type(val)}\")\n",
    "\n",
    "# What is H_outer built from?\n",
    "print(f\"\\nH_outer shape: {soft_hier_fixed.H_outer.shape}\")\n",
    "print(f\"H_outer:\\n{soft_hier_fixed.H_outer}\")\n",
    "\n",
    "# Compare to outer code\n",
    "print(f\"\\nOuter code hx shape: {outer.hx.shape}\")\n",
    "print(f\"Outer code hz shape: {outer.hz.shape}\")\n",
    "print(f\"Outer code hx (X stabilizers):\\n{outer.hx}\")\n",
    "print(f\"Outer code hz (Z stabilizers):\\n{outer.hz}\")\n",
    "\n",
    "# Observable matrix\n",
    "print(f\"\\nouter_obs_matrix shape: {soft_hier_fixed.outer_obs_matrix.shape}\")\n",
    "print(f\"outer_obs_matrix:\\n{soft_hier_fixed.outer_obs_matrix.toarray()}\")\n",
    "\n",
    "# n_outer_stabs\n",
    "print(f\"\\nn_outer_stabs: {soft_hier_fixed.n_outer_stabs}\")\n",
    "print(f\"outer_slice: {soft_hier_fixed.outer_slice}\")\n",
    "\n",
    "# Key insight: outer syndrome has 8 elements but H_outer only has 4 rows!\n",
    "outer_start, outer_stop = soft_hier_fixed.outer_slice\n",
    "print(f\"\\nOuter syndrome length: {outer_stop - outer_start}\")\n",
    "print(f\"H_outer rows: {soft_hier_fixed.H_outer.shape[0]}\")\n",
    "print(f\"MISMATCH: {(outer_stop - outer_start) != soft_hier_fixed.H_outer.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "723dcc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DETECTOR ORDERING IN OUTER SYNDROME\n",
      "======================================================================\n",
      "Outer code stabilizers:\n",
      "  4 X-stabilizers (hx): detect Z errors on data\n",
      "  4 Z-stabilizers (hz): detect X errors on data\n",
      "\n",
      "For the Z-logical observable we track:\n",
      "  Z_L on inner block → Z on outer data qubit\n",
      "  Z errors detected by X-stabilizers (hx)\n",
      "\n",
      "But wait - the inner code logical is also Z-type\n",
      "  Inner Z_L affects outer Z stabilizers? No!\n",
      "  Inner Z_L = Z error on logical qubit = data qubit of outer code\n",
      "  Z error on outer data is detected by outer X stabilizers (hx)\n",
      "\n",
      "*** BUG: H_outer should be hx, not hz! ***\n",
      "\n",
      "--- Inner X logical errors ---\n",
      "  Inner X_L = X error on logical = X on outer data\n",
      "  X errors on outer data detected by Z stabilizers (hz)\n",
      "\n",
      "--- Template DEM gives P(inner Z_L) ---\n",
      "Inner Z_L error → Z error on outer data → detected by outer hx\n",
      "So H_outer should be hx to compute Z's contribution to X stabilizers\n",
      "But we're using hz!!\n"
     ]
    }
   ],
   "source": [
    "# KEY INSIGHT: CSS outer code needs BOTH hx AND hz\n",
    "# - Inner logical X errors flip outer Z stabilizers (hz)\n",
    "# - Inner logical Z errors flip outer X stabilizers (hx)\n",
    "\n",
    "# For single logical observable (typically Z), we care about X errors on inner blocks\n",
    "# Inner X logical errors → data qubit X errors → detected by hz\n",
    "\n",
    "# But we need FULL H_outer matrix:\n",
    "# H_outer_full = [hx]  <- X stabilizers detect Z errors\n",
    "#                [hz]  <- Z stabilizers detect X errors\n",
    "\n",
    "# The current H_outer = hz only (shape 4x9)\n",
    "# But outer_syndrome has 8 detectors (4 X + 4 Z)\n",
    "\n",
    "# Let's see the detector ordering\n",
    "print(\"=\"*70)\n",
    "print(\"DETECTOR ORDERING IN OUTER SYNDROME\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Outer code stabilizers:\")\n",
    "print(f\"  4 X-stabilizers (hx): detect Z errors on data\")\n",
    "print(f\"  4 Z-stabilizers (hz): detect X errors on data\")\n",
    "\n",
    "print(f\"\\nFor the Z-logical observable we track:\")\n",
    "print(f\"  Z_L on inner block → Z on outer data qubit\")\n",
    "print(f\"  Z errors detected by X-stabilizers (hx)\")\n",
    "\n",
    "print(f\"\\nBut wait - the inner code logical is also Z-type\")\n",
    "print(f\"  Inner Z_L affects outer Z stabilizers? No!\")\n",
    "print(f\"  Inner Z_L = Z error on logical qubit = data qubit of outer code\")\n",
    "print(f\"  Z error on outer data is detected by outer X stabilizers (hx)\")\n",
    "\n",
    "print(f\"\\n*** BUG: H_outer should be hx, not hz! ***\")\n",
    "\n",
    "# What about inner X_L?\n",
    "print(f\"\\n--- Inner X logical errors ---\")\n",
    "print(f\"  Inner X_L = X error on logical = X on outer data\")\n",
    "print(f\"  X errors on outer data detected by Z stabilizers (hz)\")\n",
    "\n",
    "# But our decoder only tracks Z logical from inner\n",
    "# Template DEM observable = inner Z_L\n",
    "# So inner p_logical is P(Z_L error on inner block)\n",
    "\n",
    "print(f\"\\n--- Template DEM gives P(inner Z_L) ---\")\n",
    "print(f\"Inner Z_L error → Z error on outer data → detected by outer hx\")\n",
    "print(f\"So H_outer should be hx to compute Z's contribution to X stabilizers\")\n",
    "print(f\"But we're using hz!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fed81834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OUTER DEM MATRICES FROM stimbposd\n",
      "======================================================================\n",
      "Type: <class 'stimbposd.dem_to_matrices.DemMatrices'>\n",
      "check_matrix shape: (8, 13)\n",
      "observables_matrix shape: (1, 13)\n",
      "priors shape: (13,)\n",
      "\n",
      "check_matrix (H):\n",
      "[[0 0 1 0 0 1 0 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 1 0 0 0 1 0]\n",
      " [0 1 0 0 1 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "observables_matrix (L):\n",
      "[[1 1 0 1 0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "priors (channel probs):\n",
      "[0.06965543 0.01       0.03613333 0.01       0.03613333 0.01\n",
      " 0.06965543 0.02666667 0.11822827 0.02666667 0.17611187 0.17611187\n",
      " 0.11822827]\n"
     ]
    }
   ],
   "source": [
    "# Look at the outer_matrices from stimbposd\n",
    "print(\"=\"*70)\n",
    "print(\"OUTER DEM MATRICES FROM stimbposd\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "om = soft_hier_fixed.outer_matrices\n",
    "print(f\"Type: {type(om)}\")\n",
    "print(f\"check_matrix shape: {om.check_matrix.shape}\")\n",
    "print(f\"observables_matrix shape: {om.observables_matrix.shape}\")\n",
    "print(f\"priors shape: {om.priors.shape}\")\n",
    "\n",
    "print(f\"\\ncheck_matrix (H):\")\n",
    "print(om.check_matrix.toarray())\n",
    "\n",
    "print(f\"\\nobservables_matrix (L):\")\n",
    "print(om.observables_matrix.toarray())\n",
    "\n",
    "print(f\"\\npriors (channel probs):\")\n",
    "print(om.priors)\n",
    "\n",
    "# So the outer decoder has 8 rows in check_matrix!\n",
    "# This is what BPOSD uses\n",
    "# The issue is that H_outer used for syndrome correction only has 4 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0201aa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FIX: Use outer check_matrix instead of H_outer\n",
      "======================================================================\n",
      "Correct H_outer shape: (8, 9)\n",
      "Correct H_outer:\n",
      "[[0 0 1 0 0 1 0 1 1]\n",
      " [1 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 1 1 0]\n",
      " [0 1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Inner hard: [0 1 0 1 0 0 0 1 1]\n",
      "Inner contrib (CORRECT): [0 1 0 1 1 0 0 0]\n",
      "Inner contrib (old buggy): [1 0 0 0]\n",
      "\n",
      "Raw outer syndrome: [0 0 1 1 0 1 0 1]\n",
      "Effective syndrome (CORRECT): [0 1 1 0 1 1 0 1]\n",
      "Effective syndrome (buggy): [1 0 1 1 0 1 0 1]\n",
      "\n",
      "Outer error (correct): [0 0 1 1 1 0 1 0 1 0 1 0 1]\n",
      "Outer logical (correct): 1\n",
      "\n",
      "Final prediction (correct): 1\n",
      "Actual: True\n",
      "Match: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/1557605424.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  outer_log_correct = int(obs_dense @ outer_error_correct % 2)\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSIS: The inner_syndrome_contrib computation is WRONG\n",
    "# \n",
    "# Current code uses H_outer = outer_code.hz (4 rows)\n",
    "# But outer DEM has 8 detectors!\n",
    "#\n",
    "# The outer check_matrix (8 rows) from DEM has:\n",
    "# - First 4 rows: complex stabilizer combinations\n",
    "# - Last 4 rows: nearly identity on columns 9-12 (extra errors)\n",
    "#\n",
    "# The inner_syndrome_contrib should compute:\n",
    "#   \"What outer syndrome bits flip if inner block i has a logical error?\"\n",
    "#\n",
    "# This is given by the FIRST n_blocks columns of outer check_matrix!\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FIX: Use outer check_matrix instead of H_outer\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "H_outer_correct = soft_hier_fixed.outer_matrices.check_matrix.toarray()[:, :soft_hier_fixed.n_blocks]\n",
    "print(f\"Correct H_outer shape: {H_outer_correct.shape}\")\n",
    "print(f\"Correct H_outer:\")\n",
    "print(H_outer_correct)\n",
    "\n",
    "# Recompute inner_syndrome_contrib with correct H\n",
    "raw_outer = det_samples_test[test_idx][54:62].astype(np.uint8)\n",
    "inner_contrib_correct = (inner_hard @ H_outer_correct.T) % 2\n",
    "print(f\"\\nInner hard: {inner_hard}\")\n",
    "print(f\"Inner contrib (CORRECT): {inner_contrib_correct}\")\n",
    "print(f\"Inner contrib (old buggy): {(inner_hard[:9] @ soft_hier_fixed.H_outer[:4, :9].T) % 2}\")\n",
    "\n",
    "effective_correct = raw_outer ^ inner_contrib_correct.astype(np.uint8)\n",
    "print(f\"\\nRaw outer syndrome: {raw_outer}\")\n",
    "print(f\"Effective syndrome (CORRECT): {effective_correct}\")\n",
    "print(f\"Effective syndrome (buggy): {effective_syn}\")\n",
    "\n",
    "# Now decode with correct effective syndrome\n",
    "outer_error_correct = soft_hier_fixed.outer_decoder.decode(effective_correct.astype(np.uint8))\n",
    "print(f\"\\nOuter error (correct): {outer_error_correct}\")\n",
    "obs_dense = soft_hier_fixed.outer_obs_matrix.toarray()\n",
    "outer_log_correct = int(obs_dense @ outer_error_correct % 2)\n",
    "print(f\"Outer logical (correct): {outer_log_correct}\")\n",
    "\n",
    "# Final with correct\n",
    "final_correct = outer_log_correct ^ inner_parity\n",
    "print(f\"\\nFinal prediction (correct): {final_correct}\")\n",
    "print(f\"Actual: {actual}\")\n",
    "print(f\"Match: {final_correct == actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c80ad598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST FIX ON ALL SHOTS\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/3490747254.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  outer_logical = int(obs_dense @ outer_error % 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed LER: 0.4980 (249/500 errors)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'error_count_fixed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFixed LER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mler_fixed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors_fixed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(det_samples_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m errors)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Compare to original\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m ler_orig = \u001b[43merror_count_fixed\u001b[49m / \u001b[38;5;28mlen\u001b[39m(det_samples_test)\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal LER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mler_orig\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ler_fixed < \u001b[32m0.1\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'error_count_fixed' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the fix on all shots\n",
    "print(\"=\"*70)\n",
    "print(\"TEST FIX ON ALL SHOTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get correct H_outer\n",
    "H_outer_correct = soft_hier_fixed.outer_matrices.check_matrix.toarray()[:, :soft_hier_fixed.n_blocks].astype(np.uint8)\n",
    "\n",
    "def decode_with_fix(decoder, syndrome, H_outer_correct):\n",
    "    \"\"\"Decode with corrected H_outer.\"\"\"\n",
    "    # Step 1: Inner decoding\n",
    "    inner_hard = np.zeros(decoder.n_blocks, dtype=np.uint8)\n",
    "    inner_probs = np.zeros(decoder.n_blocks, dtype=np.float64)\n",
    "    \n",
    "    for block_id in range(decoder.n_blocks):\n",
    "        det_start, det_stop = decoder.inner_slices[block_id]\n",
    "        block_syn = syndrome[det_start:det_stop]\n",
    "        hard, p_log = decoder._decode_inner_block(block_id, block_syn)\n",
    "        inner_hard[block_id] = hard\n",
    "        inner_probs[block_id] = p_log\n",
    "    \n",
    "    # Step 2: Renormalization\n",
    "    updated_probs = decoder._outer_base_channel_probs.copy()\n",
    "    for block_id in range(min(decoder.n_blocks, len(updated_probs))):\n",
    "        updated_probs[block_id] = inner_probs[block_id]\n",
    "    decoder.outer_decoder.update_channel_probs(updated_probs)\n",
    "    \n",
    "    # Step 3: Effective outer syndrome with CORRECT H_outer\n",
    "    outer_start, outer_stop = decoder.outer_slice\n",
    "    raw_outer = syndrome[outer_start:outer_stop].astype(np.uint8)\n",
    "    inner_contrib = (inner_hard @ H_outer_correct.T) % 2\n",
    "    effective = raw_outer ^ inner_contrib.astype(np.uint8)\n",
    "    \n",
    "    # Step 4: Decode outer\n",
    "    outer_error = decoder.outer_decoder.decode(effective.astype(np.uint8))\n",
    "    obs_dense = decoder.outer_obs_matrix.toarray() if hasattr(decoder.outer_obs_matrix, 'toarray') else decoder.outer_obs_matrix\n",
    "    outer_logical = int(obs_dense @ outer_error % 2)\n",
    "    if hasattr(outer_logical, '__len__'):\n",
    "        outer_logical = int(outer_logical[0])\n",
    "    \n",
    "    # Step 5: Combine\n",
    "    inner_parity = 0\n",
    "    for block_id in decoder.outer_logical_support:\n",
    "        if block_id < decoder.n_blocks:\n",
    "            inner_parity ^= inner_hard[block_id]\n",
    "    \n",
    "    return outer_logical ^ inner_parity\n",
    "\n",
    "# Test\n",
    "errors_fixed = 0\n",
    "for i in range(len(det_samples_test)):\n",
    "    pred = decode_with_fix(soft_hier_fixed, det_samples_test[i].astype(np.uint8), H_outer_correct)\n",
    "    actual = obs_samples_test[i, 0]\n",
    "    if pred != actual:\n",
    "        errors_fixed += 1\n",
    "\n",
    "ler_fixed = errors_fixed / len(det_samples_test)\n",
    "print(f\"Fixed LER: {ler_fixed:.4f} ({errors_fixed}/{len(det_samples_test)} errors)\")\n",
    "\n",
    "# Compare to original\n",
    "ler_orig = error_count_fixed / len(det_samples_test)\n",
    "print(f\"Original LER: {ler_orig:.4f}\")\n",
    "\n",
    "if ler_fixed < 0.1:\n",
    "    print(\"✓ FIX WORKS! Much better than random.\")\n",
    "else:\n",
    "    print(\"✗ Still high LER.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc9e0d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUG: outer_logical_support\n",
      "======================================================================\n",
      "outer_logical_support: {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "This says ALL blocks are in the logical support!\n",
      "\n",
      "Outer observable (from DEM): [[1 1 0 1 0 1 0 0 0 0 0 0 0]]\n",
      "Non-zero positions: [0 1 3 5]\n",
      "\n",
      "*** BUG: outer_logical_support should only be blocks in observable support ***\n",
      "Correct support: {np.int64(0), np.int64(1), np.int64(3), np.int64(5)}\n"
     ]
    }
   ],
   "source": [
    "# Debug: Is the outer_logical_support correct?\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUG: outer_logical_support\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"outer_logical_support: {soft_hier_fixed.outer_logical_support}\")\n",
    "print(f\"This says ALL blocks are in the logical support!\")\n",
    "\n",
    "# The outer observable from DEM\n",
    "obs_mat = soft_hier_fixed.outer_obs_matrix.toarray()\n",
    "print(f\"\\nOuter observable (from DEM): {obs_mat}\")\n",
    "print(f\"Non-zero positions: {np.where(obs_mat[0] != 0)[0]}\")\n",
    "\n",
    "# Positions 0, 1, 3, 5 have value 1\n",
    "# These correspond to inner blocks 0, 1, 3, 5\n",
    "# So the logical is: block0 XOR block1 XOR block3 XOR block5\n",
    "\n",
    "# But outer_logical_support is {0,1,2,3,4,5,6,7,8} = ALL blocks!\n",
    "print(f\"\\n*** BUG: outer_logical_support should only be blocks in observable support ***\")\n",
    "\n",
    "# Let's compute what the correct support should be\n",
    "correct_support = set(np.where(obs_mat[0, :soft_hier_fixed.n_blocks] != 0)[0])\n",
    "print(f\"Correct support: {correct_support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9913eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST WITH BOTH FIXES\n",
      "======================================================================\n",
      "Fixed H_outer shape: (8, 9)\n",
      "Fixed logical support: {np.int64(0), np.int64(1), np.int64(3), np.int64(5)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/3511614239.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  outer_logical = int(obs_dense @ outer_error % 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LER with BOTH fixes: 0.5060 (253/500 errors)\n",
      "✗ Still high LER, more bugs?\n"
     ]
    }
   ],
   "source": [
    "# Test with BOTH fixes:\n",
    "# 1. Correct H_outer from DEM check_matrix\n",
    "# 2. Correct outer_logical_support from DEM observable\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST WITH BOTH FIXES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Correct H_outer\n",
    "H_outer_fix = soft_hier_fixed.outer_matrices.check_matrix.toarray()[:, :soft_hier_fixed.n_blocks].astype(np.uint8)\n",
    "\n",
    "# Correct logical support  \n",
    "obs_mat = soft_hier_fixed.outer_obs_matrix.toarray()\n",
    "logical_support_fix = set(np.where(obs_mat[0, :soft_hier_fixed.n_blocks] != 0)[0])\n",
    "\n",
    "print(f\"Fixed H_outer shape: {H_outer_fix.shape}\")\n",
    "print(f\"Fixed logical support: {logical_support_fix}\")\n",
    "\n",
    "def decode_with_both_fixes(decoder, syndrome, H_outer_fix, logical_support_fix):\n",
    "    \"\"\"Decode with both corrections.\"\"\"\n",
    "    # Step 1: Inner decoding\n",
    "    inner_hard = np.zeros(decoder.n_blocks, dtype=np.uint8)\n",
    "    inner_probs = np.zeros(decoder.n_blocks, dtype=np.float64)\n",
    "    \n",
    "    for block_id in range(decoder.n_blocks):\n",
    "        det_start, det_stop = decoder.inner_slices[block_id]\n",
    "        block_syn = syndrome[det_start:det_stop]\n",
    "        hard, p_log = decoder._decode_inner_block(block_id, block_syn)\n",
    "        inner_hard[block_id] = hard\n",
    "        inner_probs[block_id] = p_log\n",
    "    \n",
    "    # Step 2: Renormalization\n",
    "    updated_probs = decoder._outer_base_channel_probs.copy()\n",
    "    for block_id in range(min(decoder.n_blocks, len(updated_probs))):\n",
    "        updated_probs[block_id] = inner_probs[block_id]\n",
    "    decoder.outer_decoder.update_channel_probs(updated_probs)\n",
    "    \n",
    "    # Step 3: Effective outer syndrome with CORRECT H_outer\n",
    "    outer_start, outer_stop = decoder.outer_slice\n",
    "    raw_outer = syndrome[outer_start:outer_stop].astype(np.uint8)\n",
    "    inner_contrib = (inner_hard @ H_outer_fix.T) % 2\n",
    "    effective = raw_outer ^ inner_contrib.astype(np.uint8)\n",
    "    \n",
    "    # Step 4: Decode outer\n",
    "    outer_error = decoder.outer_decoder.decode(effective.astype(np.uint8))\n",
    "    obs_dense = decoder.outer_obs_matrix.toarray() if hasattr(decoder.outer_obs_matrix, 'toarray') else decoder.outer_obs_matrix\n",
    "    outer_logical = int(obs_dense @ outer_error % 2)\n",
    "    if hasattr(outer_logical, '__len__'):\n",
    "        outer_logical = int(outer_logical[0])\n",
    "    \n",
    "    # Step 5: Combine with CORRECT logical support\n",
    "    inner_parity = 0\n",
    "    for block_id in logical_support_fix:\n",
    "        if block_id < decoder.n_blocks:\n",
    "            inner_parity ^= inner_hard[block_id]\n",
    "    \n",
    "    return outer_logical ^ inner_parity\n",
    "\n",
    "# Test\n",
    "errors_both_fixes = 0\n",
    "for i in range(len(det_samples_test)):\n",
    "    pred = decode_with_both_fixes(soft_hier_fixed, det_samples_test[i].astype(np.uint8), H_outer_fix, logical_support_fix)\n",
    "    actual = obs_samples_test[i, 0]\n",
    "    if pred != actual:\n",
    "        errors_both_fixes += 1\n",
    "\n",
    "ler_both = errors_both_fixes / len(det_samples_test)\n",
    "print(f\"\\nLER with BOTH fixes: {ler_both:.4f} ({errors_both_fixes}/{len(det_samples_test)} errors)\")\n",
    "\n",
    "if ler_both < 0.1:\n",
    "    print(\"✓ BOTH FIXES WORK! Much better than random.\")\n",
    "elif ler_both < 0.3:\n",
    "    print(\"~ Improved but not great\")\n",
    "else:\n",
    "    print(\"✗ Still high LER, more bugs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fc43920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST DIFFERENT COMBINATION STRATEGIES\n",
      "======================================================================\n",
      "LER variants:\n",
      "  outer_only: 0.4900 (245/500) ✗\n",
      "  outer_xor_all: 0.4980 (249/500) ✗\n",
      "  outer_xor_obs: 0.5060 (253/500) ✗\n",
      "  no_effective: 0.4320 (216/500) ✗\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/1867549132.py:35: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  outer_logical = int(obs_dense @ outer_error % 2)\n",
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/1867549132.py:81: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  outer_logical = int(obs_dense @ outer_error % 2)\n"
     ]
    }
   ],
   "source": [
    "# Let's try simpler approaches - maybe the combination is wrong\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST DIFFERENT COMBINATION STRATEGIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def decode_variants(decoder, syndrome, H_outer_fix, logical_support_fix):\n",
    "    \"\"\"Try different decode strategies.\"\"\"\n",
    "    # Inner decoding\n",
    "    inner_hard = np.zeros(decoder.n_blocks, dtype=np.uint8)\n",
    "    inner_probs = np.zeros(decoder.n_blocks, dtype=np.float64)\n",
    "    \n",
    "    for block_id in range(decoder.n_blocks):\n",
    "        det_start, det_stop = decoder.inner_slices[block_id]\n",
    "        block_syn = syndrome[det_start:det_stop]\n",
    "        hard, p_log = decoder._decode_inner_block(block_id, block_syn)\n",
    "        inner_hard[block_id] = hard\n",
    "        inner_probs[block_id] = p_log\n",
    "    \n",
    "    # Renormalization\n",
    "    updated_probs = decoder._outer_base_channel_probs.copy()\n",
    "    for block_id in range(min(decoder.n_blocks, len(updated_probs))):\n",
    "        updated_probs[block_id] = inner_probs[block_id]\n",
    "    decoder.outer_decoder.update_channel_probs(updated_probs)\n",
    "    \n",
    "    # Effective outer syndrome\n",
    "    outer_start, outer_stop = decoder.outer_slice\n",
    "    raw_outer = syndrome[outer_start:outer_stop].astype(np.uint8)\n",
    "    inner_contrib = (inner_hard @ H_outer_fix.T) % 2\n",
    "    effective = raw_outer ^ inner_contrib.astype(np.uint8)\n",
    "    \n",
    "    # Decode outer\n",
    "    outer_error = decoder.outer_decoder.decode(effective.astype(np.uint8))\n",
    "    obs_dense = decoder.outer_obs_matrix.toarray()\n",
    "    outer_logical = int(obs_dense @ outer_error % 2)\n",
    "    if hasattr(outer_logical, '__len__'):\n",
    "        outer_logical = int(outer_logical[0])\n",
    "    \n",
    "    # Inner parity variants\n",
    "    inner_parity_all = np.sum(inner_hard) % 2  # All blocks\n",
    "    inner_parity_obs = 0\n",
    "    for b in logical_support_fix:\n",
    "        if b < len(inner_hard):\n",
    "            inner_parity_obs ^= inner_hard[b]\n",
    "    \n",
    "    return {\n",
    "        'outer_only': outer_logical,\n",
    "        'outer_xor_all': outer_logical ^ inner_parity_all,\n",
    "        'outer_xor_obs': outer_logical ^ inner_parity_obs,\n",
    "        'inner_parity_all': inner_parity_all,\n",
    "        'inner_parity_obs': inner_parity_obs,\n",
    "    }\n",
    "\n",
    "# Also try without effective syndrome correction\n",
    "def decode_no_effective(decoder, syndrome):\n",
    "    \"\"\"Try without effective syndrome - just use raw outer.\"\"\"\n",
    "    # Inner decoding\n",
    "    inner_hard = np.zeros(decoder.n_blocks, dtype=np.uint8)\n",
    "    inner_probs = np.zeros(decoder.n_blocks, dtype=np.float64)\n",
    "    \n",
    "    for block_id in range(decoder.n_blocks):\n",
    "        det_start, det_stop = decoder.inner_slices[block_id]\n",
    "        block_syn = syndrome[det_start:det_stop]\n",
    "        hard, p_log = decoder._decode_inner_block(block_id, block_syn)\n",
    "        inner_hard[block_id] = hard\n",
    "        inner_probs[block_id] = p_log\n",
    "    \n",
    "    # Renormalization\n",
    "    updated_probs = decoder._outer_base_channel_probs.copy()\n",
    "    for block_id in range(min(decoder.n_blocks, len(updated_probs))):\n",
    "        updated_probs[block_id] = inner_probs[block_id]\n",
    "    decoder.outer_decoder.update_channel_probs(updated_probs)\n",
    "    \n",
    "    # Raw outer syndrome (NO inner_contrib correction)\n",
    "    outer_start, outer_stop = decoder.outer_slice\n",
    "    raw_outer = syndrome[outer_start:outer_stop].astype(np.uint8)\n",
    "    \n",
    "    # Decode outer\n",
    "    outer_error = decoder.outer_decoder.decode(raw_outer)\n",
    "    obs_dense = decoder.outer_obs_matrix.toarray()\n",
    "    outer_logical = int(obs_dense @ outer_error % 2)\n",
    "    if hasattr(outer_logical, '__len__'):\n",
    "        outer_logical = int(outer_logical[0])\n",
    "    \n",
    "    return outer_logical\n",
    "\n",
    "# Test all variants\n",
    "results = {'outer_only': 0, 'outer_xor_all': 0, 'outer_xor_obs': 0, 'no_effective': 0}\n",
    "\n",
    "for i in range(len(det_samples_test)):\n",
    "    syn = det_samples_test[i].astype(np.uint8)\n",
    "    actual = obs_samples_test[i, 0]\n",
    "    \n",
    "    v = decode_variants(soft_hier_fixed, syn, H_outer_fix, logical_support_fix)\n",
    "    n = decode_no_effective(soft_hier_fixed, syn)\n",
    "    \n",
    "    if v['outer_only'] != actual:\n",
    "        results['outer_only'] += 1\n",
    "    if v['outer_xor_all'] != actual:\n",
    "        results['outer_xor_all'] += 1\n",
    "    if v['outer_xor_obs'] != actual:\n",
    "        results['outer_xor_obs'] += 1\n",
    "    if n != actual:\n",
    "        results['no_effective'] += 1\n",
    "\n",
    "print(f\"LER variants:\")\n",
    "for k, v in results.items():\n",
    "    ler = v / len(det_samples_test)\n",
    "    status = \"✓\" if ler < 0.1 else \"~\" if ler < 0.3 else \"✗\"\n",
    "    print(f\"  {k}: {ler:.4f} ({v}/{len(det_samples_test)}) {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056cdb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST: Outer BPOSD with perfect inner info\n",
      "======================================================================\n",
      "Outer H shape: (8, 13)\n",
      "Outer L shape: (1, 13)\n",
      "Outer priors: [0.06965543 0.01       0.03613333 0.01       0.03613333 0.01\n",
      " 0.06965543 0.02666667 0.11822827 0.02666667 0.17611187 0.17611187\n",
      " 0.11822827]\n",
      "\n",
      "Outer BPOSD direct (no inner correction): LER = 0.4600\n",
      "Inner-only (parity on obs support): LER = 0.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/b8rfjwj12jn7gld5g0b3c2x80000gn/T/ipykernel_5243/2058746596.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred = int(outer_L @ outer_error % 2)\n"
     ]
    }
   ],
   "source": [
    "# Test: Is the outer BPOSD decoder working at all?\n",
    "# Let's test it with perfect inner information\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST: Outer BPOSD with perfect inner info\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create fresh outer decoder with base probs\n",
    "from ldpc import bposd_decoder\n",
    "\n",
    "outer_H = soft_hier_fixed.outer_matrices.check_matrix.toarray()\n",
    "outer_L = soft_hier_fixed.outer_matrices.observables_matrix.toarray()\n",
    "outer_priors = soft_hier_fixed.outer_matrices.priors.copy()\n",
    "\n",
    "print(f\"Outer H shape: {outer_H.shape}\")\n",
    "print(f\"Outer L shape: {outer_L.shape}\")\n",
    "print(f\"Outer priors: {outer_priors}\")\n",
    "\n",
    "# Create decoder\n",
    "outer_dec = bposd_decoder(\n",
    "    outer_H,\n",
    "    error_rate=0.1,  # placeholder, we'll update\n",
    "    bp_method=\"ms\",\n",
    "    max_iter=100,\n",
    "    osd_method=\"osd_cs\",\n",
    "    osd_order=10\n",
    ")\n",
    "\n",
    "# Test: just decode outer syndromes directly with base priors\n",
    "outer_dec.update_channel_probs(outer_priors)\n",
    "\n",
    "errors_outer_direct = 0\n",
    "for i in range(len(det_samples_test)):\n",
    "    outer_start, outer_stop = soft_hier_fixed.outer_slice\n",
    "    outer_syn = det_samples_test[i, outer_start:outer_stop].astype(np.uint8)\n",
    "    \n",
    "    outer_error = outer_dec.decode(outer_syn)\n",
    "    pred = int(outer_L @ outer_error % 2)\n",
    "    if hasattr(pred, '__len__'):\n",
    "        pred = int(pred[0])\n",
    "    \n",
    "    actual = obs_samples_test[i, 0]\n",
    "    if pred != actual:\n",
    "        errors_outer_direct += 1\n",
    "\n",
    "ler_outer_direct = errors_outer_direct / len(det_samples_test)\n",
    "print(f\"\\nOuter BPOSD direct (no inner correction): LER = {ler_outer_direct:.4f}\")\n",
    "\n",
    "# What about just inner decoding?\n",
    "errors_inner_only = 0\n",
    "for i in range(len(det_samples_test)):\n",
    "    syn = det_samples_test[i].astype(np.uint8)\n",
    "    \n",
    "    # Decode all inner blocks\n",
    "    inner_logicals = []\n",
    "    for block_id in range(soft_hier_fixed.n_blocks):\n",
    "        det_start, det_stop = soft_hier_fixed.inner_slices[block_id]\n",
    "        block_syn = syn[det_start:det_stop]\n",
    "        hard, _ = soft_hier_fixed._decode_inner_block(block_id, block_syn)\n",
    "        inner_logicals.append(hard)\n",
    "    \n",
    "    # Just use inner parity on observable support\n",
    "    obs_support = [0, 1, 3, 5]  # From DEM observable\n",
    "    pred = sum(inner_logicals[b] for b in obs_support) % 2\n",
    "    \n",
    "    actual = obs_samples_test[i, 0]\n",
    "    if pred != actual:\n",
    "        errors_inner_only += 1\n",
    "\n",
    "ler_inner_only = errors_inner_only / len(det_samples_test)\n",
    "print(f\"Inner-only (parity on obs support): LER = {ler_inner_only:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2c9b790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE BPOSD ANALYSIS\n",
      "======================================================================\n",
      "Full concatenated DEM:\n",
      "  num_detectors: 62\n",
      "  num_observables: 1\n",
      "\n",
      "Full check_matrix shape: (62, 274)\n",
      "Full observable_matrix shape: (1, 274)\n",
      "Full priors shape: (274,)\n",
      "\n",
      "Our outer decoder:\n",
      "  check_matrix shape: (8, 13)\n",
      "\n",
      "*** ARCHITECTURAL PROBLEM ***\n",
      "BPOSD uses ALL 62 detectors = full (62, 274)\n",
      "Our outer DEM only has 8 detectors\n",
      "\n",
      "The hierarchical decoder tries to:\n",
      "  1. Decode inner blocks separately (6 dets each × 9 blocks = 54 dets)\n",
      "  2. Decode outer part (8 dets)\n",
      "  3. Combine results\n",
      "\n",
      "But the outer DEM was built from the CONCATENATED circuit!\n",
      "The outer decoder sees a problem it can't solve alone.\n"
     ]
    }
   ],
   "source": [
    "# Check baseline BPOSD - it decodes the FULL concatenated DEM\n",
    "print(\"=\"*70)\n",
    "print(\"BASELINE BPOSD ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Regenerate DEM\n",
    "dem = noisy_circuit.detector_error_model(decompose_errors=True, ignore_decomposition_failures=True)\n",
    "\n",
    "# What DEM does baseline BPOSD use?\n",
    "print(f\"Full concatenated DEM:\")\n",
    "print(f\"  num_detectors: {dem.num_detectors}\")\n",
    "print(f\"  num_observables: {dem.num_observables}\")\n",
    "\n",
    "# Get the full matrices using the function\n",
    "from stimbposd.dem_to_matrices import detector_error_model_to_check_matrices\n",
    "full_matrices = detector_error_model_to_check_matrices(dem)\n",
    "print(f\"\\nFull check_matrix shape: {full_matrices.check_matrix.shape}\")\n",
    "print(f\"Full observable_matrix shape: {full_matrices.observables_matrix.shape}\")\n",
    "print(f\"Full priors shape: {full_matrices.priors.shape}\")\n",
    "\n",
    "# What does our outer decoder have?\n",
    "print(f\"\\nOur outer decoder:\")\n",
    "print(f\"  check_matrix shape: {soft_hier_fixed.outer_matrices.check_matrix.shape}\")\n",
    "\n",
    "# The fundamental issue:\n",
    "print(f\"\\n*** ARCHITECTURAL PROBLEM ***\")\n",
    "print(f\"BPOSD uses ALL {dem.num_detectors} detectors = full {full_matrices.check_matrix.shape}\")\n",
    "print(f\"Our outer DEM only has {soft_hier_fixed.outer_matrices.check_matrix.shape[0]} detectors\")\n",
    "print(f\"\\nThe hierarchical decoder tries to:\")\n",
    "print(f\"  1. Decode inner blocks separately (6 dets each × 9 blocks = 54 dets)\")\n",
    "print(f\"  2. Decode outer part (8 dets)\")\n",
    "print(f\"  3. Combine results\")\n",
    "print(f\"\\nBut the outer DEM was built from the CONCATENATED circuit!\")\n",
    "print(f\"The outer decoder sees a problem it can't solve alone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00b92010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANALYZING ACTUAL DEM STRUCTURE\n",
      "======================================================================\n",
      "Outer detector range: [54, 62)\n",
      "\n",
      "Found 137 errors touching outer detectors\n",
      "  0: p=0.0267, outer=[1], inner=[0, 1]..., obs=True\n",
      "  1: p=0.0519, outer=[1], inner=[1]..., obs=True\n",
      "  2: p=0.0640, outer=[1], inner=[1, 2]..., obs=True\n",
      "  3: p=0.0267, outer=[5], inner=[1, 2]..., obs=True\n",
      "  4: p=0.0640, outer=[1], inner=[2]..., obs=True\n",
      "  5: p=0.0135, outer=[1], inner=[2, 1]..., obs=True\n",
      "  6: p=0.0267, outer=[5], inner=[2, 4]..., obs=True\n",
      "  7: p=0.0267, outer=[1], inner=[4]..., obs=True\n",
      "  8: p=0.0622, outer=[5], inner=[4]..., obs=True\n",
      "  9: p=0.0622, outer=[5], inner=[4, 5]..., obs=True\n",
      "\n",
      "Errors touching BOTH inner and outer: 127\n",
      "Pure outer errors: 10\n"
     ]
    }
   ],
   "source": [
    "# Let's understand the TRUE relationship between inner logical errors and outer detectors\n",
    "# by looking at the actual concatenated DEM structure\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ANALYZING ACTUAL DEM STRUCTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find errors in full DEM that have inner observables\n",
    "# The DEM was generated without inner observables (num_observables=1)\n",
    "# So we need to look at the TEMPLATE DEM which has inner observables\n",
    "\n",
    "# Actually, let's check what errors affect outer detectors\n",
    "outer_start, outer_stop = soft_hier_fixed.outer_slice\n",
    "print(f\"Outer detector range: [{outer_start}, {outer_stop})\")\n",
    "\n",
    "# Find all errors touching outer detectors\n",
    "errors_touching_outer = []\n",
    "for instr in dem.flattened():\n",
    "    if instr.type != \"error\":\n",
    "        continue\n",
    "    prob = instr.args_copy()[0]\n",
    "    targets = instr.targets_copy()\n",
    "    \n",
    "    outer_dets = []\n",
    "    inner_dets = []\n",
    "    has_main_obs = False\n",
    "    \n",
    "    for t in targets:\n",
    "        if t.is_relative_detector_id():\n",
    "            if outer_start <= t.val < outer_stop:\n",
    "                outer_dets.append(t.val - outer_start)\n",
    "            else:\n",
    "                inner_dets.append(t.val)\n",
    "        elif t.is_logical_observable_id() and t.val == 0:\n",
    "            has_main_obs = True\n",
    "    \n",
    "    if outer_dets:\n",
    "        errors_touching_outer.append({\n",
    "            'prob': prob,\n",
    "            'outer_dets': outer_dets,\n",
    "            'inner_dets': inner_dets,\n",
    "            'has_obs': has_main_obs\n",
    "        })\n",
    "\n",
    "print(f\"\\nFound {len(errors_touching_outer)} errors touching outer detectors\")\n",
    "\n",
    "# Show some\n",
    "for i, e in enumerate(errors_touching_outer[:10]):\n",
    "    print(f\"  {i}: p={e['prob']:.4f}, outer={e['outer_dets']}, inner={e['inner_dets'][:5]}..., obs={e['has_obs']}\")\n",
    "\n",
    "# Key insight: errors that touch BOTH inner and outer detectors\n",
    "mixed_errors = [e for e in errors_touching_outer if e['inner_dets']]\n",
    "print(f\"\\nErrors touching BOTH inner and outer: {len(mixed_errors)}\")\n",
    "\n",
    "pure_outer_errors = [e for e in errors_touching_outer if not e['inner_dets']]\n",
    "print(f\"Pure outer errors: {len(pure_outer_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ca8739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST: Synthetic outer code decoder\n",
      "======================================================================\n",
      "Decoder basis: Z\n",
      "H_full shape: (8, 9)\n",
      "\n",
      "Outer observable (from DEM):\n",
      "[[1 1 0 1 0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "For d=3 rotated surface code:\n",
      "  9 data qubits in 3x3 grid\n",
      "  Logical Z = column of qubits\n",
      "  Support = 3 qubits... but observable has 4 blocks?\n",
      "\n",
      "Outer code logicals:\n",
      "  outer.k = 1\n"
     ]
    }
   ],
   "source": [
    "# APPROACH: Build synthetic outer decoder from outer code structure\n",
    "# \n",
    "# The key insight from the literature (Poulin 2006, etc.):\n",
    "# - Inner decoder gives P(logical_i) for each block\n",
    "# - Outer decoder sees \"effective channel\" where each data qubit has error prob P(logical_i)\n",
    "# - Outer stabilizers detect combinations of these effective errors\n",
    "#\n",
    "# But the OUTER SYNDROME from the concatenated circuit is NOT the syndrome of this effective channel!\n",
    "# It's the syndrome of the PHYSICAL circuit.\n",
    "#\n",
    "# The hierarchical algorithm needs to:\n",
    "# 1. Decode inner blocks → hard decisions + soft info\n",
    "# 2. Correct outer syndrome: subtract contribution from inner hard decisions\n",
    "# 3. Decode corrected outer syndrome with updated channel probs\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST: Synthetic outer code decoder\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build outer decoder purely from outer code structure\n",
    "# H_outer = hx (for Z-logical) or hz (for X-logical)\n",
    "# For Z-logical, we track X errors on data qubits\n",
    "# X errors are detected by Z stabilizers (hz)\n",
    "\n",
    "# Actually wait - what basis are we decoding?\n",
    "print(f\"Decoder basis: {soft_hier_fixed.basis}\")\n",
    "\n",
    "# For Z-basis decoding:\n",
    "# - We track Z errors (which flip X stabilizers)\n",
    "# - Inner Z-logical errors are Z errors on outer data qubits  \n",
    "# - Z errors on outer data detected by X stabilizers (hx)\n",
    "\n",
    "# Let's build a proper outer decoder\n",
    "from ldpc import bposd_decoder\n",
    "\n",
    "# Full parity check for CSS: stack hx and hz\n",
    "H_full = np.vstack([outer.hx, outer.hz])  # (8, 9)\n",
    "print(f\"H_full shape: {H_full.shape}\")\n",
    "\n",
    "# For Z-logical (tracked observable):\n",
    "# Logical Z of outer code\n",
    "logical_z = np.zeros((1, 9), dtype=np.uint8)\n",
    "for i in range(9):\n",
    "    # Logical Z has support... let me check\n",
    "    pass\n",
    "\n",
    "# Actually, the outer observable from DEM should tell us\n",
    "print(f\"\\nOuter observable (from DEM):\")\n",
    "print(soft_hier_fixed.outer_obs_matrix.toarray())\n",
    "# [1 1 0 1 0 1 0 0 0 0 0 0 0] \n",
    "# Positions 0,1,3,5 = first 4 blocks... but wait, this is error positions, not qubit positions\n",
    "\n",
    "# The observable is on ERROR VARIABLES not DATA QUBITS\n",
    "# Error vars 0-8 are inner logical errors\n",
    "# So observable = block 0 XOR block 1 XOR block 3 XOR block 5\n",
    "\n",
    "# This makes sense for a d=3 surface code where the logical is a string of 4 qubits\n",
    "print(f\"\\nFor d=3 rotated surface code:\")\n",
    "print(f\"  9 data qubits in 3x3 grid\")\n",
    "print(f\"  Logical Z = column of qubits\")\n",
    "print(f\"  Support = 3 qubits... but observable has 4 blocks?\")\n",
    "\n",
    "# Let me check the outer code logical\n",
    "print(f\"\\nOuter code logicals:\")\n",
    "print(f\"  outer.k = {outer.k}\")\n",
    "# We need to find logical Z support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0426cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST: Weighted Inner-Only Decoding\n",
      "======================================================================\n",
      "Weighted inner-only LER: 0.4720\n",
      "Simple XOR on obs support: 0.5140\n"
     ]
    }
   ],
   "source": [
    "# SIMPLEST APPROACH: Just use inner soft info for weighted prediction\n",
    "# This ignores the outer decoder entirely but should work if Template DEM is good\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST: Weighted Inner-Only Decoding\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# The observable has support on blocks 0, 1, 3, 5\n",
    "obs_support = [0, 1, 3, 5]\n",
    "\n",
    "def decode_weighted_inner_only(decoder, syndrome, obs_support):\n",
    "    \"\"\"Decode using only inner soft info, weighted by confidence.\"\"\"\n",
    "    # Decode all inner blocks\n",
    "    inner_hard = np.zeros(decoder.n_blocks, dtype=np.uint8)\n",
    "    inner_probs = np.zeros(decoder.n_blocks, dtype=np.float64)  # P(logical error)\n",
    "    \n",
    "    for block_id in range(decoder.n_blocks):\n",
    "        det_start, det_stop = decoder.inner_slices[block_id]\n",
    "        block_syn = syndrome[det_start:det_stop]\n",
    "        hard, p_log = decoder._decode_inner_block(block_id, block_syn)\n",
    "        inner_hard[block_id] = hard\n",
    "        inner_probs[block_id] = p_log\n",
    "    \n",
    "    # Weighted vote based on soft info\n",
    "    # For blocks in observable support, compute weighted prediction\n",
    "    total_weight = 0\n",
    "    weighted_sum = 0\n",
    "    \n",
    "    for b in obs_support:\n",
    "        if b < len(inner_hard):\n",
    "            # Weight = confidence = 1 - 2*min(p, 1-p)\n",
    "            # More confident when p close to 0 or 1\n",
    "            p = inner_probs[b]\n",
    "            confidence = abs(1 - 2 * p)  # 0 at p=0.5, 1 at p=0 or p=1\n",
    "            \n",
    "            # Vote = hard decision weighted by confidence\n",
    "            weighted_sum += inner_hard[b] * confidence\n",
    "            total_weight += confidence\n",
    "    \n",
    "    # Threshold at 0.5\n",
    "    if total_weight > 0:\n",
    "        weighted_avg = weighted_sum / total_weight\n",
    "        return int(weighted_avg > 0.5)\n",
    "    else:\n",
    "        # Fallback to simple parity\n",
    "        return sum(inner_hard[b] for b in obs_support if b < len(inner_hard)) % 2\n",
    "\n",
    "# Test\n",
    "errors_weighted = 0\n",
    "for i in range(len(det_samples_test)):\n",
    "    pred = decode_weighted_inner_only(soft_hier_fixed, det_samples_test[i].astype(np.uint8), obs_support)\n",
    "    actual = obs_samples_test[i, 0]\n",
    "    if pred != actual:\n",
    "        errors_weighted += 1\n",
    "\n",
    "ler_weighted = errors_weighted / len(det_samples_test)\n",
    "print(f\"Weighted inner-only LER: {ler_weighted:.4f}\")\n",
    "\n",
    "# Also try simple XOR (no weighting)\n",
    "errors_simple_xor = 0\n",
    "for i in range(len(det_samples_test)):\n",
    "    syn = det_samples_test[i].astype(np.uint8)\n",
    "    inner_hard = []\n",
    "    for block_id in range(soft_hier_fixed.n_blocks):\n",
    "        det_start, det_stop = soft_hier_fixed.inner_slices[block_id]\n",
    "        block_syn = syn[det_start:det_stop]\n",
    "        hard, _ = soft_hier_fixed._decode_inner_block(block_id, block_syn)\n",
    "        inner_hard.append(hard)\n",
    "    \n",
    "    pred = sum(inner_hard[b] for b in obs_support if b < len(inner_hard)) % 2\n",
    "    if pred != obs_samples_test[i, 0]:\n",
    "        errors_simple_xor += 1\n",
    "\n",
    "ler_simple_xor = errors_simple_xor / len(det_samples_test)\n",
    "print(f\"Simple XOR on obs support: {ler_simple_xor:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38565c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INNER DECODING QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "--- Shot 0 (actual=True) ---\n",
      "Block results (hard, p_log, syn_weight):\n",
      "  *Block 0: hard=0, p_log=0.010, syn_wt=0\n",
      "  *Block 1: hard=1, p_log=0.373, syn_wt=4\n",
      "   Block 2: hard=0, p_log=0.378, syn_wt=2\n",
      "  *Block 3: hard=1, p_log=0.447, syn_wt=1\n",
      "   Block 4: hard=0, p_log=0.396, syn_wt=4\n",
      "  *Block 5: hard=0, p_log=0.447, syn_wt=3\n",
      "   Block 6: hard=0, p_log=0.361, syn_wt=2\n",
      "   Block 7: hard=1, p_log=0.580, syn_wt=2\n",
      "   Block 8: hard=1, p_log=0.419, syn_wt=2\n",
      "XOR on obs_support: 0, actual: True, match: False\n",
      "\n",
      "--- Shot 1 (actual=True) ---\n",
      "Block results (hard, p_log, syn_weight):\n",
      "  *Block 0: hard=0, p_log=0.010, syn_wt=0\n",
      "  *Block 1: hard=1, p_log=0.485, syn_wt=2\n",
      "   Block 2: hard=1, p_log=0.447, syn_wt=4\n",
      "  *Block 3: hard=1, p_log=0.461, syn_wt=3\n",
      "   Block 4: hard=0, p_log=0.361, syn_wt=2\n",
      "  *Block 5: hard=0, p_log=0.361, syn_wt=2\n",
      "   Block 6: hard=0, p_log=0.010, syn_wt=0\n",
      "   Block 7: hard=1, p_log=0.526, syn_wt=2\n",
      "   Block 8: hard=0, p_log=0.378, syn_wt=2\n",
      "XOR on obs_support: 0, actual: True, match: False\n",
      "\n",
      "--- Shot 2 (actual=False) ---\n",
      "Block results (hard, p_log, syn_weight):\n",
      "  *Block 0: hard=1, p_log=0.511, syn_wt=1\n",
      "  *Block 1: hard=1, p_log=0.447, syn_wt=1\n",
      "   Block 2: hard=0, p_log=0.383, syn_wt=3\n",
      "  *Block 3: hard=0, p_log=0.386, syn_wt=4\n",
      "   Block 4: hard=1, p_log=0.449, syn_wt=2\n",
      "  *Block 5: hard=1, p_log=0.511, syn_wt=1\n",
      "   Block 6: hard=0, p_log=0.388, syn_wt=2\n",
      "   Block 7: hard=1, p_log=0.457, syn_wt=5\n",
      "   Block 8: hard=0, p_log=0.010, syn_wt=0\n",
      "XOR on obs_support: 1, actual: False, match: False\n",
      "\n",
      "--- Shot 3 (actual=True) ---\n",
      "Block results (hard, p_log, syn_weight):\n",
      "  *Block 0: hard=1, p_log=0.425, syn_wt=4\n",
      "  *Block 1: hard=0, p_log=0.010, syn_wt=0\n",
      "   Block 2: hard=0, p_log=0.010, syn_wt=0\n",
      "  *Block 3: hard=0, p_log=0.010, syn_wt=0\n",
      "   Block 4: hard=0, p_log=0.440, syn_wt=4\n",
      "  *Block 5: hard=0, p_log=0.168, syn_wt=2\n",
      "   Block 6: hard=0, p_log=0.010, syn_wt=0\n",
      "   Block 7: hard=1, p_log=0.580, syn_wt=2\n",
      "   Block 8: hard=0, p_log=0.010, syn_wt=0\n",
      "XOR on obs_support: 1, actual: True, match: True\n",
      "\n",
      "--- Shot 4 (actual=False) ---\n",
      "Block results (hard, p_log, syn_weight):\n",
      "  *Block 0: hard=1, p_log=0.369, syn_wt=3\n",
      "  *Block 1: hard=0, p_log=0.492, syn_wt=3\n",
      "   Block 2: hard=0, p_log=0.010, syn_wt=0\n",
      "  *Block 3: hard=0, p_log=0.383, syn_wt=3\n",
      "   Block 4: hard=0, p_log=0.010, syn_wt=0\n",
      "  *Block 5: hard=1, p_log=0.485, syn_wt=2\n",
      "   Block 6: hard=0, p_log=0.419, syn_wt=5\n",
      "   Block 7: hard=0, p_log=0.394, syn_wt=2\n",
      "   Block 8: hard=0, p_log=0.450, syn_wt=3\n",
      "XOR on obs_support: 0, actual: False, match: True\n"
     ]
    }
   ],
   "source": [
    "# Check inner decoding quality\n",
    "print(\"=\"*70)\n",
    "print(\"INNER DECODING QUALITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# For this we need to know the TRUE inner logical errors\n",
    "# But the concatenated DEM only has 1 observable!\n",
    "# We don't have ground truth for individual inner blocks\n",
    "\n",
    "# Wait - we CAN generate ground truth by looking at the error propagation\n",
    "# An inner logical error on block i means the inner code's Z-logical was flipped\n",
    "\n",
    "# Actually let's check if the inner decoders are even remotely correct\n",
    "# by looking at syndrome patterns\n",
    "\n",
    "# Check a few shots\n",
    "for test_idx in range(5):\n",
    "    syn = det_samples_test[test_idx].astype(np.uint8)\n",
    "    actual_obs = obs_samples_test[test_idx, 0]\n",
    "    \n",
    "    print(f\"\\n--- Shot {test_idx} (actual={actual_obs}) ---\")\n",
    "    \n",
    "    inner_results = []\n",
    "    for block_id in range(soft_hier_fixed.n_blocks):\n",
    "        det_start, det_stop = soft_hier_fixed.inner_slices[block_id]\n",
    "        block_syn = syn[det_start:det_stop]\n",
    "        hard, p_log = soft_hier_fixed._decode_inner_block(block_id, block_syn)\n",
    "        inner_results.append((hard, p_log, np.sum(block_syn)))\n",
    "        \n",
    "    # Show\n",
    "    print(f\"Block results (hard, p_log, syn_weight):\")\n",
    "    for b, (h, p, w) in enumerate(inner_results):\n",
    "        marker = \"*\" if b in obs_support else \" \"\n",
    "        print(f\"  {marker}Block {b}: hard={h}, p_log={p:.3f}, syn_wt={w}\")\n",
    "    \n",
    "    pred_xor = sum(inner_results[b][0] for b in obs_support) % 2\n",
    "    print(f\"XOR on obs_support: {pred_xor}, actual: {actual_obs}, match: {pred_xor == actual_obs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d523d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OBSERVABLE ANALYSIS\n",
      "======================================================================\n",
      "Full DEM observable matrix shape: (1, 274)\n",
      "Full DEM observable matrix:\n",
      "Non-zero positions (of 274): [  4  11  12  13  17  18  23  24  25  26  27  32  39  40  44  45  50  51\n",
      "  52  53  54  55  62  66  67  71  73  74  75  80  81  82  83  84 255]\n",
      "\n",
      "Our outer DEM observable:\n",
      "[1 1 0 1 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Check the actual observable from the FULL concatenated DEM\n",
    "print(\"=\"*70)\n",
    "print(\"OBSERVABLE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"Full DEM observable matrix shape:\", full_matrices.observables_matrix.shape)\n",
    "print(\"Full DEM observable matrix:\")\n",
    "obs_full = full_matrices.observables_matrix.toarray()[0]\n",
    "print(f\"Non-zero positions (of {len(obs_full)}): {np.where(obs_full != 0)[0]}\")\n",
    "\n",
    "# What do these positions correspond to?\n",
    "# The full DEM has 274 error variables\n",
    "# Need to map back to understand what errors contribute to the observable\n",
    "\n",
    "print(f\"\\nOur outer DEM observable:\")\n",
    "print(soft_hier_fixed.outer_obs_matrix.toarray()[0])\n",
    "\n",
    "# The outer observable was built from errors that flip L0 in the OUTER slice\n",
    "# But the full observable is much more complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "757b0a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE BPOSD vs HIERARCHICAL COMPARISON\n",
      "======================================================================\n",
      "BPOSD uses:\n",
      "  - Full check_matrix: (62, 274)\n",
      "  - Full observable: (1, 274) with 35 non-zero entries\n",
      "\n",
      "Our outer decoder uses:\n",
      "  - Outer check_matrix: (8, 13)\n",
      "  - Outer observable: (1, 13) with 4 non-zero entries\n",
      "\n",
      "*** The hierarchical outer decoder is a GROSS SIMPLIFICATION ***\n",
      "It can't possibly capture the full error structure!\n",
      "\n",
      "======================================================================\n",
      "IDEA: The problem might be code-specific\n",
      "======================================================================\n",
      "Steane code has 6 stabilizers (3X + 3Z)\n",
      "Surface code has 8 stabilizers (4X + 4Z)\n",
      "The interaction between them creates complex correlations\n",
      "\n",
      "For simpler codes (like repetition inside surface), it might work better.\n"
     ]
    }
   ],
   "source": [
    "# Let's compare: what does baseline BPOSD do vs what we're trying?\n",
    "print(\"=\"*70)\n",
    "print(\"BASELINE BPOSD vs HIERARCHICAL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# BPOSD approach:\n",
    "# 1. Full DEM: 62 detectors, 274 error vars, 1 observable\n",
    "# 2. Decode using FULL parity check matrix (62 x 274)\n",
    "# 3. Compute observable from error pattern using FULL observable matrix (1 x 274)\n",
    "\n",
    "# Our hierarchical approach:\n",
    "# 1. Decode inner blocks: 9 blocks × 6 detectors = 54 inner dets\n",
    "# 2. Get hard/soft decisions per block\n",
    "# 3. Decode outer: 8 detectors, 13 error vars\n",
    "# 4. Combine\n",
    "\n",
    "# The fundamental issue:\n",
    "# - BPOSD uses ALL 274 error variables and their correlations\n",
    "# - We try to reduce to 13 outer error vars (9 inner logicals + 4 extras)\n",
    "# - But the reduction loses critical information!\n",
    "\n",
    "print(\"BPOSD uses:\")\n",
    "print(f\"  - Full check_matrix: {full_matrices.check_matrix.shape}\")\n",
    "print(f\"  - Full observable: {full_matrices.observables_matrix.shape} with {np.sum(full_matrices.observables_matrix.toarray() != 0)} non-zero entries\")\n",
    "\n",
    "print(\"\\nOur outer decoder uses:\")\n",
    "print(f\"  - Outer check_matrix: {soft_hier_fixed.outer_matrices.check_matrix.shape}\")\n",
    "print(f\"  - Outer observable: {soft_hier_fixed.outer_obs_matrix.shape} with {np.sum(soft_hier_fixed.outer_obs_matrix.toarray() != 0)} non-zero entries\")\n",
    "\n",
    "print(\"\\n*** The hierarchical outer decoder is a GROSS SIMPLIFICATION ***\")\n",
    "print(\"It can't possibly capture the full error structure!\")\n",
    "\n",
    "# But... the literature says soft hierarchical should work!\n",
    "# The key is that for PROPER concatenated codes, the structure is cleaner\n",
    "# Steane + Surface code has complex interactions because both are CSS codes\n",
    "\n",
    "# What if we try a simpler test case?\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IDEA: The problem might be code-specific\")\n",
    "print(\"=\"*70)\n",
    "print(\"Steane code has 6 stabilizers (3X + 3Z)\")\n",
    "print(\"Surface code has 8 stabilizers (4X + 4Z)\")\n",
    "print(\"The interaction between them creates complex correlations\")\n",
    "print(\"\")\n",
    "print(\"For simpler codes (like repetition inside surface), it might work better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3845fab",
   "metadata": {},
   "source": [
    "# Root Cause Analysis Summary\n",
    "\n",
    "## Problem\n",
    "SoftHierarchicalDecoder gives LER ≈ 0.50 (random) when using Template DEM approach, while BPOSD baseline achieves LER ≈ 0.003.\n",
    "\n",
    "## Root Cause\n",
    "The outer decoder is fundamentally broken because:\n",
    "\n",
    "1. **Outer DEM is wrong**: The outer DEM is built with only 8 detectors and 13 error variables, trying to model the \"effective channel\" where inner blocks contribute logical errors.\n",
    "\n",
    "2. **Full DEM has 274 error variables**: BPOSD uses the full concatenated DEM with 62 detectors and 274 error variables. The hierarchical approach loses most of this information.\n",
    "\n",
    "3. **Observable mismatch**: The full observable depends on 35 error variables. Our outer observable only has 4 non-zero entries.\n",
    "\n",
    "4. **Correlation loss**: The concatenated Steane + Surface code has complex detector-error correlations that span inner and outer boundaries. These are lost in the hierarchical decomposition.\n",
    "\n",
    "## Why This Happens\n",
    "The `_build_outer_decoder` method constructs an artificial outer DEM that doesn't match the actual error propagation. It:\n",
    "- Assumes inner logical errors affect outer stabilizers via `H_outer = outer_code.hz`\n",
    "- But the actual DEM shows errors affect **both** inner and outer detectors simultaneously\n",
    "- The hierarchical decomposition assumes independence that doesn't exist\n",
    "\n",
    "## Possible Fixes\n",
    "\n",
    "### Option 1: Use TURBO-style iteration\n",
    "Instead of one-shot inner→outer decode, iterate:\n",
    "1. Decode inner blocks → soft info\n",
    "2. Use soft info to condition outer decode\n",
    "3. Use outer result to re-decode inner\n",
    "4. Repeat until convergence\n",
    "\n",
    "### Option 2: Build proper effective outer DEM\n",
    "Construct the outer DEM properly by:\n",
    "1. Taking the full DEM\n",
    "2. Marginalizing out inner detectors (summing over all inner error patterns)\n",
    "3. This is computationally expensive but correct\n",
    "\n",
    "### Option 3: Use global soft info without outer decoder\n",
    "Skip the outer BPOSD decoder entirely:\n",
    "1. Decode each inner block with Template DEM\n",
    "2. Combine inner logical decisions using the FULL observable structure\n",
    "3. This requires knowing the correct combination rule\n",
    "\n",
    "### Option 4: Accept that hierarchical doesn't work for this code\n",
    "Some concatenated code combinations may not be amenable to hierarchical decoding. The Steane + Surface combination might have too much cross-talk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
