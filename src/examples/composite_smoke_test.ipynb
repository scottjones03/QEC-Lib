{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a049f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n",
      "  ConcatenatedTopologicalCSSCode: <class 'qectostim.codes.composite.concatenated.ConcatenatedTopologicalCSSCode'>\n",
      "  HomologicalProductCode: <class 'qectostim.codes.composite.homological_product.HomologicalProductCode'>\n",
      "  DualCode: <class 'qectostim.codes.composite.dual.DualCode'>\n",
      "  Decoders loaded: ['PyMatching', 'FusionBlossom', 'BeliefMatching', 'BPOSD', 'Tesseract', 'UnionFind', 'MLE', 'Hypergraph', 'Chromobius', 'Concatenated', 'FlatConcat', 'Hierarchical', 'SingleShot']\n",
      "  ConcatenatedDecoder available: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 1: Setup and Imports\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure src is in path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Clear all qectostim module cache BEFORE importing (fresh start)\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "# Also clear the bytecode cache\n",
    "import importlib\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# Import testing utilities from qectostim.testing\n",
    "from qectostim.testing import (\n",
    "    clear_qectostim_modules,\n",
    "    test_composite_construction,\n",
    "    test_code_circuit,\n",
    "    test_decoder_on_code,\n",
    "    load_all_decoders,\n",
    "    STATUS_OK, STATUS_WARN, STATUS_SKIP, STATUS_FAIL,\n",
    ")\n",
    "\n",
    "# Import qectostim\n",
    "from qectostim.codes import discover_all_codes\n",
    "from qectostim.codes.composite import (\n",
    "    ConcatenatedTopologicalCSSCode,\n",
    "    HomologicalProductCode,\n",
    "    DualCode,\n",
    ")\n",
    "from qectostim.codes.abstract_css import CSSCodeWithComplex\n",
    "from qectostim.decoders import PyMatchingDecoder\n",
    "\n",
    "# Load all available decoders\n",
    "decoder_classes = load_all_decoders()\n",
    "\n",
    "# Try to import ConcatenatedDecoder\n",
    "try:\n",
    "    from qectostim.decoders.concatenated_decoder import ConcatenatedDecoder\n",
    "    HAS_CONCAT_DECODER = True\n",
    "except ImportError as e:\n",
    "    HAS_CONCAT_DECODER = False\n",
    "    print(f\"Note: ConcatenatedDecoder not available: {e}\")\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"  ConcatenatedTopologicalCSSCode: {ConcatenatedTopologicalCSSCode}\")\n",
    "print(f\"  HomologicalProductCode: {HomologicalProductCode}\")\n",
    "print(f\"  DualCode: {DualCode}\")\n",
    "print(f\"  Decoders loaded: {list(decoder_classes.keys())}\")\n",
    "print(f\"  ConcatenatedDecoder available: {HAS_CONCAT_DECODER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bac643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DISCOVERING BUILDING BLOCK CODES\n",
      "======================================================================\n",
      "\n",
      "Total discovered: 58\n",
      "CSS codes with k>0: 53\n",
      "\n",
      "By size:\n",
      "  Small (n≤10): 14\n",
      "  Medium (10<n≤30): 17\n",
      "  Surface-like: 11\n",
      "  Other: 11\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Code Name                                   n   k   d\n",
      "----------------------------------------------------------------------\n",
      "Repetition_3                                3   1   3\n",
      "FourQubit422_[[4,2,2]]                      4   2   2\n",
      "Repetition_5                                5   1   5\n",
      "C6                                          6   2   2\n",
      "Steane_713                                  7   1   3\n",
      "Hamming_CSS_7                               7   1   3\n",
      "Repetition_7                                7   1   7\n",
      "TriangularColour_d3                         7   1   3\n",
      "TetrahedralColorCode                        7   1   ?\n",
      "Code_832                                    8   3   2\n",
      "LoopToricCode4D                             8   2   ?\n",
      "HexagonalColour_d2                          8   2   2\n",
      "Shor_91                                     9   1   3\n",
      "RotatedSurface_[[9,1,3]]                    9   1   3\n",
      "XZZX_Surface_3                              9   1   3\n",
      "Colour488_[[9,1,3]]                         9   1   3\n",
      "BaconShor_3x3                               9   5   3\n",
      "Hyperbolic57Code                           13   1   5\n",
      "ProjectivePlaneSurface_[[13,1,None]]       13   1   ?\n",
      "QuantumPinCode_d3_m2                       13   1   3\n",
      "... and 33 more\n",
      "\n",
      "Total discovered: 58\n",
      "CSS codes with k>0: 53\n",
      "\n",
      "By size:\n",
      "  Small (n≤10): 14\n",
      "  Medium (10<n≤30): 17\n",
      "  Surface-like: 11\n",
      "  Other: 11\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Code Name                                   n   k   d\n",
      "----------------------------------------------------------------------\n",
      "Repetition_3                                3   1   3\n",
      "FourQubit422_[[4,2,2]]                      4   2   2\n",
      "Repetition_5                                5   1   5\n",
      "C6                                          6   2   2\n",
      "Steane_713                                  7   1   3\n",
      "Hamming_CSS_7                               7   1   3\n",
      "Repetition_7                                7   1   7\n",
      "TriangularColour_d3                         7   1   3\n",
      "TetrahedralColorCode                        7   1   ?\n",
      "Code_832                                    8   3   2\n",
      "LoopToricCode4D                             8   2   ?\n",
      "HexagonalColour_d2                          8   2   2\n",
      "Shor_91                                     9   1   3\n",
      "RotatedSurface_[[9,1,3]]                    9   1   3\n",
      "XZZX_Surface_3                              9   1   3\n",
      "Colour488_[[9,1,3]]                         9   1   3\n",
      "BaconShor_3x3                               9   5   3\n",
      "Hyperbolic57Code                           13   1   5\n",
      "ProjectivePlaneSurface_[[13,1,None]]       13   1   ?\n",
      "QuantumPinCode_d3_m2                       13   1   3\n",
      "... and 33 more\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 2: Discover Building Block Codes\"\"\"\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DISCOVERING BUILDING BLOCK CODES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Discover codes - use smaller size for composite building\n",
    "all_codes = discover_all_codes(\n",
    "    max_qubits=50,  # Smaller for composition\n",
    "    include_qldpc=True,\n",
    "    include_subsystem=False,  # Skip subsystem for CSS operations\n",
    "    include_floquet=False,    # Skip floquet for CSS operations\n",
    "    include_bosonic=False,\n",
    "    include_qudit=False,\n",
    "    include_non_css=True,\n",
    "    timeout_per_code=3.0,\n",
    ")\n",
    "\n",
    "# Filter to CSS codes only (required for concatenation and homological product)\n",
    "css_codes = {}\n",
    "for name, code in all_codes.items():\n",
    "    if hasattr(code, 'hx') and hasattr(code, 'hz'):\n",
    "        # Additional check: must have k > 0\n",
    "        if code.k > 0:\n",
    "            # Verify CSS condition: hx @ hz.T == 0 (mod 2)\n",
    "            try:\n",
    "                import numpy as np\n",
    "                from scipy import sparse\n",
    "                hx = code.hx\n",
    "                hz = code.hz\n",
    "                # Handle sparse matrices\n",
    "                if sparse.issparse(hx):\n",
    "                    hx = hx.toarray()\n",
    "                if sparse.issparse(hz):\n",
    "                    hz = hz.toarray()\n",
    "                product = (hx @ hz.T) % 2\n",
    "                if np.any(product != 0):\n",
    "                    print(f\"  Skipping {name}: hx @ hz.T != 0 (not valid CSS)\")\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"  Skipping {name}: CSS check failed ({e})\")\n",
    "                continue  # Skip if CSS check fails\n",
    "            css_codes[name] = code\n",
    "\n",
    "print(f\"\\nTotal discovered: {len(all_codes)}\")\n",
    "print(f\"CSS codes with k>0: {len(css_codes)}\")\n",
    "\n",
    "# Categorize for smart pairing\n",
    "small_codes = {}   # n <= 10, good for inner codes\n",
    "medium_codes = {}  # 10 < n <= 30\n",
    "surface_codes = {} # Surface-like, good for outer codes\n",
    "other_codes = {}\n",
    "\n",
    "for name, code in css_codes.items():\n",
    "    n = code.n\n",
    "    if 'Surface' in name or 'Toric' in name:\n",
    "        surface_codes[name] = code\n",
    "    elif n <= 10:\n",
    "        small_codes[name] = code\n",
    "    elif n <= 30:\n",
    "        medium_codes[name] = code\n",
    "    else:\n",
    "        other_codes[name] = code\n",
    "\n",
    "print(f\"\\nBy size:\")\n",
    "print(f\"  Small (n≤10): {len(small_codes)}\")\n",
    "print(f\"  Medium (10<n≤30): {len(medium_codes)}\")\n",
    "print(f\"  Surface-like: {len(surface_codes)}\")\n",
    "print(f\"  Other: {len(other_codes)}\")\n",
    "\n",
    "\n",
    "# List codes\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"{'Code Name':<40} {'n':>4} {'k':>3} {'d':>3}\")\n",
    "print(\"-\"*70)\n",
    "for name, code in sorted(css_codes.items(), key=lambda x: x[1].n)[:20]:\n",
    "    d = code.metadata.get('distance', '?')\n",
    "    print(f\"{name:<40} {code.n:>4} {code.k:>3} {d:>3}\")\n",
    "if len(css_codes) > 20:\n",
    "    print(f\"... and {len(css_codes) - 20} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c05a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hom_results and dual_results if not defined\n",
    "if 'hom_results' not in dir():\n",
    "    hom_results = []\n",
    "if 'dual_results' not in dir():\n",
    "    dual_results = []\n",
    "\n",
    "# Also initialize codes_with_complex if needed\n",
    "if 'codes_with_complex' not in dir():\n",
    "    codes_with_complex = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eff5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting decoder smoke test results...\n",
      "  [1/7] NO CONCATENATION...\n",
      "  [2/7] CONCATENATED CODES...\n",
      "  [3/7] MULTI-LEVEL CONCATENATED...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 6a: Collect Decoder Smoke Test Results (no output)\n",
    "\n",
    "This cell collects all results for composite code decoder tests.\n",
    "Results are stored in `smoke_test_results` for display in the next cell.\n",
    "\n",
    "Structure:\n",
    "1. [NO CONCATENATION] - Baseline LER for outer codes only\n",
    "2. [CONCATENATED CODES] - Should have LOWER LER than baseline\n",
    "3. [MULTI-LEVEL CONCATENATED] - Additional concatenation layer  \n",
    "4. [BASE-BEFORE-HOMOLOGICAL-PRODUCT] - Baseline for codes before tensor product\n",
    "5. [HOMOLOGICAL PRODUCT - NO METACHECKS] - Product codes without metachecks\n",
    "6. [HOMOLOGICAL PRODUCT - WITH METACHECKS] - Product codes with metachecks\n",
    "7. [DUAL CODES] - Dual code tests\n",
    "\"\"\"\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Clear qectostim modules to pick up any code fixes\n",
    "modules_to_clear = [k for k in list(sys.modules.keys()) if 'qectostim' in k]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "# Re-import essential modules\n",
    "import numpy as np\n",
    "from qectostim.codes.discovery import discover_all_codes\n",
    "from qectostim.codes.composite.concatenated import ConcatenatedTopologicalCSSCode\n",
    "from qectostim.codes.composite import HomologicalProductCode, DualCode\n",
    "from qectostim.testing import test_decoder_on_code, load_all_decoders, STATUS_OK, STATUS_WARN, STATUS_SKIP, STATUS_FAIL\n",
    "\n",
    "# Reload decoder classes and code lists\n",
    "decoder_classes = load_all_decoders()\n",
    "all_codes = discover_all_codes()\n",
    "css_codes = {n: c for n, c in all_codes.items() \n",
    "             if hasattr(c, 'hx') and hasattr(c, 'hz') and c.k > 0}\n",
    "\n",
    "# Parameters\n",
    "P_ERR = 0.00075  # Error rate needs to be subthreshold\n",
    "SHOTS = 500000  # Increased shots for reliable LER estimates\n",
    "ROUNDS = 1\n",
    "\n",
    "# Storage for all results\n",
    "smoke_test_results = {\n",
    "    'params': {'p': P_ERR, 'shots': SHOTS, 'rounds': ROUNDS},\n",
    "    'decoder_names': [],\n",
    "    'sections': {},  # section_name -> list of row results\n",
    "    'baselines': {},  # code_name -> best_ler (for comparison)\n",
    "    'hom_base_lers': {},\n",
    "    'hom_no_meta_lers': {},\n",
    "}\n",
    "\n",
    "print(\"Collecting decoder smoke test results...\")\n",
    "\n",
    "if len(decoder_classes) == 0:\n",
    "    print(\"⚠️ No decoders available\")\n",
    "    smoke_test_results['decoder_names'] = []\n",
    "else:\n",
    "    # Use all available decoders (prioritize BPOSD, PyMatching)\n",
    "    primary_decoders = {}\n",
    "    for name in ['BPOSD', 'PyMatching']:\n",
    "        if name in decoder_classes:\n",
    "            primary_decoders[name] = decoder_classes[name]\n",
    "    for name, cls in decoder_classes.items():\n",
    "        if name not in primary_decoders:\n",
    "            primary_decoders[name] = cls\n",
    "    \n",
    "    decoder_names = list(primary_decoders.keys())\n",
    "    smoke_test_results['decoder_names'] = decoder_names\n",
    "    \n",
    "    def test_code_all_decoders(code, code_label, enable_metachecks=False):\n",
    "        \"\"\"Test a code with ALL decoders, return dict of results.\"\"\"\n",
    "        results = {'label': code_label, 'no_decode': None, 'decoders': {}}\n",
    "        for dec_name, dec_class in primary_decoders.items():\n",
    "            try:\n",
    "                res = test_decoder_on_code(\n",
    "                    code, dec_class, decoder_name=dec_name,\n",
    "                    code_type='CSS', p=P_ERR, shots=SHOTS, rounds=ROUNDS,\n",
    "                    enable_metachecks=enable_metachecks\n",
    "                )\n",
    "                if results['no_decode'] is None and res.ler_no_decode is not None:\n",
    "                    results['no_decode'] = res.ler_no_decode\n",
    "                results['decoders'][dec_name] = {'ler': res.ler, 'status': res.status}\n",
    "            except Exception as e:\n",
    "                results['decoders'][dec_name] = {'ler': None, 'status': 'FAIL', 'error': str(e)[:30]}\n",
    "        return results\n",
    "    \n",
    "    def get_best_ler(results):\n",
    "        \"\"\"Get best (minimum) LER from results dict.\"\"\"\n",
    "        lers = [r['ler'] for r in results['decoders'].values() if r.get('ler') is not None]\n",
    "        return min(lers) if lers else None\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. [NO CONCATENATION]\n",
    "    # =========================================================================\n",
    "    print(\"  [1/7] NO CONCATENATION...\")\n",
    "    smoke_test_results['sections']['NO_CONCAT'] = []\n",
    "    \n",
    "    outer_codes_tested = set()\n",
    "    if 'concat_results' in dir() or 'concat_results' in globals():\n",
    "        successful_concats = [r for r in concat_results if r['status'] == 'OK'][:5]\n",
    "        \n",
    "        for concat_res in successful_concats:\n",
    "            outer_name = concat_res['outer']\n",
    "            if outer_name in outer_codes_tested:\n",
    "                continue\n",
    "            outer_codes_tested.add(outer_name)\n",
    "            \n",
    "            outer_code = css_codes.get(outer_name)\n",
    "            if outer_code is None:\n",
    "                continue\n",
    "            \n",
    "            results = test_code_all_decoders(outer_code, outer_name, enable_metachecks=False)\n",
    "            best_ler = get_best_ler(results)\n",
    "            if best_ler is not None:\n",
    "                smoke_test_results['baselines'][outer_name] = best_ler\n",
    "            results['is_baseline'] = True\n",
    "            smoke_test_results['sections']['NO_CONCAT'].append(results)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. [CONCATENATED CODES]\n",
    "    # =========================================================================\n",
    "    print(\"  [2/7] CONCATENATED CODES...\")\n",
    "    smoke_test_results['sections']['CONCAT'] = []\n",
    "    \n",
    "    if 'concat_results' in dir() or 'concat_results' in globals():\n",
    "        successful_concats = [r for r in concat_results if r['status'] == 'OK'][:5]\n",
    "        \n",
    "        for concat_res in successful_concats:\n",
    "            outer_name = concat_res['outer']\n",
    "            inner_name = concat_res['inner']\n",
    "            \n",
    "            outer_code = css_codes.get(outer_name)\n",
    "            inner_code = css_codes.get(inner_name)\n",
    "            \n",
    "            if outer_code is None or inner_code is None:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                concat = ConcatenatedTopologicalCSSCode(outer_code, inner_code)\n",
    "                code_label = f\"{outer_name}∘{inner_name}\"\n",
    "                \n",
    "                results = test_code_all_decoders(concat, code_label, enable_metachecks=False)\n",
    "                results['baseline_key'] = outer_name\n",
    "                smoke_test_results['sections']['CONCAT'].append(results)\n",
    "                \n",
    "            except Exception as e:\n",
    "                smoke_test_results['sections']['CONCAT'].append({\n",
    "                    'label': f\"{outer_name}∘{inner_name}\",\n",
    "                    'error': str(e)[:50]\n",
    "                })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. [MULTI-LEVEL CONCATENATED]\n",
    "    # =========================================================================\n",
    "    print(\"  [3/7] MULTI-LEVEL CONCATENATED...\")\n",
    "    smoke_test_results['sections']['MULTI_CONCAT'] = []\n",
    "    \n",
    "    inner_422 = None\n",
    "    for name, code in css_codes.items():\n",
    "        if code.n == 4 and code.k == 2:\n",
    "            inner_422 = (name, code)\n",
    "            break\n",
    "    if inner_422 is None:\n",
    "        for name, code in sorted(css_codes.items(), key=lambda x: x[1].n):\n",
    "            if code.k >= 1 and code.n <= 7:\n",
    "                inner_422 = (name, code)\n",
    "                break\n",
    "    \n",
    "    outer_surface = None\n",
    "    for name, code in css_codes.items():\n",
    "        if 'Surface' in name or 'Toric' in name:\n",
    "            if code.n <= 25:\n",
    "                outer_surface = (name, code)\n",
    "                break\n",
    "    if outer_surface is None:\n",
    "        for name, code in sorted(css_codes.items(), key=lambda x: x[1].n):\n",
    "            if code.n >= 9 and code.n <= 30:\n",
    "                outer_surface = (name, code)\n",
    "                break\n",
    "    \n",
    "    if inner_422 and outer_surface:\n",
    "        inner_name, inner_code = inner_422\n",
    "        outer_name, outer_code = outer_surface\n",
    "        \n",
    "        try:\n",
    "            level1 = ConcatenatedTopologicalCSSCode(inner_code, inner_code)\n",
    "            level1_label = f\"({inner_name}∘{inner_name})\"\n",
    "            level2 = ConcatenatedTopologicalCSSCode(outer_code, level1)\n",
    "            level2_label = f\"{outer_name}∘{level1_label}\"\n",
    "            \n",
    "            results = test_code_all_decoders(level2, level2_label, enable_metachecks=False)\n",
    "            results['baseline_key'] = outer_name\n",
    "            smoke_test_results['sections']['MULTI_CONCAT'].append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['MULTI_CONCAT'].append({\n",
    "                'label': 'Multi-level concat',\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. [BASE-BEFORE-HOMOLOGICAL-PRODUCT]\n",
    "    # =========================================================================\n",
    "    print(\"  [4/7] BASE-BEFORE-HOMOLOGICAL-PRODUCT...\")\n",
    "    smoke_test_results['sections']['HOM_BASE'] = []\n",
    "    \n",
    "    codes_with_complex_local = {}\n",
    "    for name, code in css_codes.items():\n",
    "        if hasattr(code, 'chain_complex') and code.chain_complex is not None:\n",
    "            codes_with_complex_local[name] = code\n",
    "    \n",
    "    try:\n",
    "        from qectostim.codes.surface.toric_code_general import ToricCode\n",
    "        tc = ToricCode(Lx=2, Ly=2)\n",
    "        if hasattr(tc, 'chain_complex') and tc.chain_complex is not None:\n",
    "            codes_with_complex_local['ToricCode_2x2'] = tc\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for name, code in list(codes_with_complex_local.items())[:3]:\n",
    "        results = test_code_all_decoders(code, name, enable_metachecks=False)\n",
    "        best_ler = get_best_ler(results)\n",
    "        if best_ler is not None:\n",
    "            smoke_test_results['hom_base_lers'][name] = best_ler\n",
    "        results['is_baseline'] = True\n",
    "        smoke_test_results['sections']['HOM_BASE'].append(results)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. [HOMOLOGICAL PRODUCT - NO METACHECKS]\n",
    "    # =========================================================================\n",
    "    print(\"  [5/7] HOMOLOGICAL PRODUCT - NO METACHECKS...\")\n",
    "    smoke_test_results['sections']['HOM_NO_META'] = []\n",
    "    \n",
    "    hom_products = []\n",
    "    complex_list = list(codes_with_complex_local.items())[:2]\n",
    "    if len(complex_list) >= 1:\n",
    "        for name_a, code_a in complex_list:\n",
    "            try:\n",
    "                product = HomologicalProductCode(code_a, code_a)\n",
    "                code_label = f\"{name_a}⊗{name_a}\"\n",
    "                hom_products.append((code_label, product, name_a))\n",
    "                \n",
    "                results = test_code_all_decoders(product, code_label, enable_metachecks=False)\n",
    "                results['baseline_key'] = name_a\n",
    "                best_ler = get_best_ler(results)\n",
    "                if best_ler is not None:\n",
    "                    smoke_test_results['hom_no_meta_lers'][code_label] = best_ler\n",
    "                smoke_test_results['sections']['HOM_NO_META'].append(results)\n",
    "                \n",
    "            except Exception as e:\n",
    "                smoke_test_results['sections']['HOM_NO_META'].append({\n",
    "                    'label': f\"{name_a}⊗{name_a}\",\n",
    "                    'error': str(e)[:50]\n",
    "                })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 6. [HOMOLOGICAL PRODUCT - WITH METACHECKS]\n",
    "    # =========================================================================\n",
    "    print(\"  [6/7] HOMOLOGICAL PRODUCT - WITH METACHECKS...\")\n",
    "    smoke_test_results['sections']['HOM_META'] = []\n",
    "    \n",
    "    for code_label, product, name_a in hom_products:\n",
    "        try:\n",
    "            results = test_code_all_decoders(product, code_label, enable_metachecks=True)\n",
    "            results['baseline_key'] = code_label  # Compare to NO_META version\n",
    "            smoke_test_results['sections']['HOM_META'].append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['HOM_META'].append({\n",
    "                'label': code_label,\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 7. [5-CHAIN HOMOLOGICAL PRODUCTS - SINGLESHOT DECODER TEST]\n",
    "    # =========================================================================\n",
    "    print(\"  [7/9] 5-CHAIN HOMOLOGICAL PRODUCTS (SingleShot test)...\")\n",
    "    smoke_test_results['sections']['HOM_5CHAIN'] = []\n",
    "    \n",
    "    # Build 5-chain codes: 3-chain ⊗ 3-chain = 5-chain\n",
    "    # ToricCode, Steane, Shor all have 3-chain complexes\n",
    "    five_chain_products = []\n",
    "    \n",
    "    # Try ToricCode ⊗ ToricCode\n",
    "    try:\n",
    "        from qectostim.codes.surface.toric_code_general import ToricCode\n",
    "        tc_small = ToricCode(Lx=2, Ly=2)\n",
    "        if hasattr(tc_small, 'chain_complex') and tc_small.chain_complex is not None:\n",
    "            product_toric = HomologicalProductCode(tc_small, tc_small)\n",
    "            five_chain_products.append(('ToricCode_2x2⊗ToricCode_2x2', product_toric, tc_small))\n",
    "            print(f\"    Created ToricCode⊗ToricCode: n={product_toric.n}, chain_length={product_toric.chain_length}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ToricCode⊗ToricCode failed: {e}\")\n",
    "    \n",
    "    # Try Steane ⊗ Steane (both have 3-chain from CSSChainComplex3)\n",
    "    try:\n",
    "        from qectostim.codes.small.steane_713 import SteaneCode713\n",
    "        steane = SteaneCode713()\n",
    "        if hasattr(steane, 'chain_complex') and steane.chain_complex is not None:\n",
    "            product_steane = HomologicalProductCode(steane, steane)\n",
    "            five_chain_products.append(('Steane⊗Steane', product_steane, steane))\n",
    "            print(f\"    Created Steane⊗Steane: n={product_steane.n}, chain_length={product_steane.chain_length}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Steane⊗Steane failed: {e}\")\n",
    "    \n",
    "    # Test each 5-chain product with metachecks enabled (for SingleShot)\n",
    "    for code_label, product, base_code in five_chain_products:\n",
    "        # Check metachecks\n",
    "        has_meta_x = hasattr(product, 'meta_x') and product.meta_x is not None and product.meta_x.size > 0\n",
    "        has_meta_z = hasattr(product, 'meta_z') and product.meta_z is not None and product.meta_z.size > 0\n",
    "        print(f\"    {code_label}: meta_x={has_meta_x}, meta_z={has_meta_z}\")\n",
    "        \n",
    "        try:\n",
    "            results = test_code_all_decoders(product, code_label, enable_metachecks=True)\n",
    "            results['has_metachecks'] = has_meta_x or has_meta_z\n",
    "            results['chain_length'] = product.chain_length if hasattr(product, 'chain_length') else None\n",
    "            smoke_test_results['sections']['HOM_5CHAIN'].append(results)\n",
    "        except Exception as e:\n",
    "            smoke_test_results['sections']['HOM_5CHAIN'].append({\n",
    "                'label': code_label,\n",
    "                'error': str(e)[:50]\n",
    "            })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 8. [DUAL CODES]\n",
    "    # =========================================================================\n",
    "    print(\"  [8/9] DUAL CODES...\")\n",
    "    smoke_test_results['sections']['DUAL'] = []\n",
    "    \n",
    "    if 'dual_results' in dir() or 'dual_results' in globals():\n",
    "        successful_dual = [r for r in dual_results if r['status'] == 'OK'][:3]\n",
    "        \n",
    "        for dual_res in successful_dual:\n",
    "            orig_name = dual_res['original']\n",
    "            orig_code = css_codes.get(orig_name)\n",
    "            \n",
    "            if orig_code is None:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                dual = DualCode(orig_code)\n",
    "                code_label = f\"Dual({orig_name})\"\n",
    "                \n",
    "                results = test_code_all_decoders(dual, code_label, enable_metachecks=False)\n",
    "                smoke_test_results['sections']['DUAL'].append(results)\n",
    "                \n",
    "            except Exception as e:\n",
    "                smoke_test_results['sections']['DUAL'].append({\n",
    "                    'label': f\"Dual({orig_name})\",\n",
    "                    'error': str(e)[:50]\n",
    "                })\n",
    "\n",
    "print(\"\\n✓ Results collected. Run the next cell to display formatted output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aefd1b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "DECODER SMOKE TEST ON COMPOSITE CODES - COMPREHENSIVE COMPARISON\n",
      "========================================================================================================================\n",
      "\n",
      "Parameters: p=0.00075, shots=500000, rounds=1\n",
      "Expectation: More concatenation → LOWER LER; Metachecks → LOWER LER for homological products\n",
      "\n",
      "Testing with decoders: ['BPOSD', 'PyMatching', 'FusionBlossom', 'BeliefMatching', 'Tesseract', 'UnionFind', 'MLE', 'Hypergraph', 'Chromobius', 'Concatenated', 'FlatConcat', 'Hierarchical', 'SingleShot']\n",
      "\n",
      "  Code                                                     no-dec BPOSD        PyMatching   FusionBlosso BeliefMatchi Tesseract    UnionFind    MLE          Hypergraph   Chromobius   Concatenated FlatConcat   Hierarchical SingleShot    Status\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NO CONCATENATION] - Baseline LER for outer codes\n",
      "  RotatedSurface_[[9,1,3]]                                 0.0028 0.0000       0.0000       0.0000       0.0012       0.0000       0.0000       0.0000       0.0027       -skip        -skip        -skip        -skip        -skip         baseline\n",
      "\n",
      "[CONCATENATED CODES] - Should have LOWER LER than outer code baseline\n",
      "  RotatedSurface_[[9,1,3]]∘FourQubit422_[[4,2,2]]          0.0101 0.0000 ▲▲!   0.0001 ▲▲!   0.0034 ▲▲!   0.0021 ▲▲!   0.0000 ▲▲!   0.0002 ▲▲!   0.0001 ▲▲!   0.0116 ▲▲!   -skip        0.0000 ▼     0.0000 ▼     ✗fail        -skip         ✓ improved\n",
      "  RotatedSurface_[[9,1,3]]∘C6                              0.0114 0.0000 ▼▼    0.0001 ▲▲!   0.0003 ▲▲!   0.0005 ▲▲!   0.0000       0.0001 ▲▲!   -skip        0.0001 ▲▲!   -skip        0.0000 ▼▼    0.0000 ▼     ✗fail        -skip         ✓ improved\n",
      "  RotatedSurface_[[9,1,3]]∘Steane_713                      0.0191 0.0000 ▲▲!   0.0068 ▲▲!   0.0047 ▲▲!   ✗fail        0.0000 ▲     0.0068 ▲▲!   -skip        0.0125 ▲▲!   -skip        0.0206 ▲▲!   0.0207 ▲▲!   ✗fail        -skip         ⚠️ worse\n",
      "  RotatedSurface_[[9,1,3]]∘Shor_91                         0.0513 0.0002 ▲▲!   ✗fail        0.0209 ▲▲!   ✗fail        0.0002 ▲▲!   ✗fail        -skip        ✗fail        -skip        ✗fail        ✗fail        ✗fail        -skip         ✗ WORSE!\n",
      "  RotatedSurface_[[9,1,3]]∘Hamming_CSS_7                   0.0185 0.0000 ▲     0.0067 ▲▲!   0.0046 ▲▲!   ✗fail        0.0000 ▼     0.0069 ▲▲!   -skip        0.0127 ▲▲!   -skip        0.0209 ▲▲!   0.0207 ▲▲!   ✗fail        -skip         ✓ improved\n",
      "\n",
      "[MULTI-LEVEL CONCATENATED] - Double concatenation (even lower LER expected)\n",
      "  RotatedSurface_[[9,1,3]]∘(FourQubit422_[[4,2,...         0.0281 0.0001 ▲▲!   0.0012 ▲▲!   0.0184 ▲▲!   ✗fail        0.0001 ▲▲!   0.0012 ▲▲!   -skip        0.0248 ▲▲!   -skip        ✗fail        ✗fail        ✗fail        -skip         ✗ WORSE!\n",
      "\n",
      "[BASE-BEFORE-HOMOLOGICAL-PRODUCT] - Baseline codes for tensor product\n",
      "  FourQubit422_[[4,2,2]]                                   0.0020 0.0015       0.0020       0.0015       0.0018       0.0017       0.0020       0.0017       0.0015       -skip        -skip        -skip        -skip        -skip         baseline\n",
      "  Steane_713                                               0.0035 0.0018       0.0031       0.0031       0.0024       0.0012       0.0030       0.0012       0.0025       -skip        -skip        -skip        -skip        -skip         baseline\n",
      "  Shor_91                                                  0.0073 0.0024       0.0036       0.0025       0.0028       0.0022       0.0037       0.0022       0.0047       -skip        -skip        -skip        -skip        -skip         baseline\n",
      "\n",
      "[HOMOLOGICAL PRODUCT - NO METACHECKS] - 4D codes without metachecks\n",
      "  FourQubit422_[[4,2,2]]⊗FourQubit422_[[4,2,2]]            0.0065 0.0001 ▼▼    0.0001 ▼▼    0.0028 ▲▲!   ✗fail        0.0000 ▼▼    0.0001 ▼▼    0.0001 ▼▼    0.0001 ▼▼    -skip        -skip        -skip        -skip        ✗fail         ✓ MUCH better\n",
      "  Steane_713⊗Steane_713                                    0.0225 0.0000 ▼▼    ✗fail        0.0164 ▲▲!   ✗fail        0.0000 ▼▼    ✗fail        -skip        ✗fail        -skip        -skip        -skip        -skip        ✗fail         ✓ MUCH better\n",
      "\n",
      "[HOMOLOGICAL PRODUCT - WITH METACHECKS] - Should be BETTER than no metachecks\n",
      "  FourQubit422_[[4,2,2]]⊗FourQubit422_[[4,2,2]]            0.0068 0.0001       0.0001 ▲▲!   0.0029 ▲▲!   ✗fail        0.0000 ▼     0.0001 ▲▲!   0.0001 ▲     0.0001 ▲▲!   -skip        -skip        -skip        -skip        ✗fail         ✓ slightly better\n",
      "  Steane_713⊗Steane_713                                    0.0225 0.0000       ✗fail        0.0167       ✗fail        0.0000       ✗fail        -skip        ✗fail        -skip        -skip        -skip        -skip        ✗fail         ~ similar\n",
      "\n",
      "[5-CHAIN HOMOLOGICAL PRODUCTS] - ToricCode⊗ToricCode etc. for SingleShot decoder\n",
      "  ToricCode_2x2⊗ToricCode_2x2                              0.0126 0.0001       ✗fail        0.0106       ✗fail        0.0001       ✗fail        -skip        ✗fail        -skip        -skip        -skip        -skip        ✗fail         ---\n",
      "\n",
      "[DUAL CODES]\n",
      "  Dual(FourQubit422_[[4,2,2]])                             0.0019 0.0015       0.0020       0.0016       0.0018       0.0016       0.0021       0.0016       0.0016       -skip        -skip        -skip        -skip        -skip         ---\n",
      "  Dual(C6)                                                 0.0020 0.0012       0.0014       0.0013       0.0012       0.0013       0.0014       0.0012       0.0013       -skip        -skip        -skip        -skip        -skip         ---\n",
      "  Dual(Steane_713)                                         0.0036 0.0019       0.0030       0.0030       0.0024       0.0012       0.0029       0.0012       0.0024       -skip        -skip        -skip        -skip        -skip         ---\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Section                                       Avg LER      Min LER      Max LER    Count\n",
      "NO_CONCAT                                      0.0000       0.0000       0.0000        1\n",
      "CONCAT                                         0.0000       0.0000       0.0002        5\n",
      "MULTI_CONCAT                                   0.0001       0.0001       0.0001        1\n",
      "HOM_BASE                                       0.0016       0.0012       0.0022        3\n",
      "HOM_NO_META                                    0.0000       0.0000       0.0000        2\n",
      "HOM_META                                       0.0000       0.0000       0.0000        2\n",
      "HOM_5CHAIN                                     0.0001       0.0001       0.0001        1\n",
      "DUAL                                           0.0013       0.0012       0.0015        3\n",
      "\n",
      "Key Comparisons:\n",
      "  ✗ Concatenation: 0.0000 → 0.0000 (-586.7%)\n",
      "  ✗ Multi-concat: 0.0000 → 0.0001 (-1066.7%)\n",
      "  ✓ Metachecks (hom. product): 0.0000 → 0.0000 (+16.7%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 6b: Display Decoder Smoke Test Results\n",
    "\n",
    "Formats and displays results collected in the previous cell.\n",
    "\"\"\"\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Check if results exist\n",
    "if 'smoke_test_results' not in dir() and 'smoke_test_results' not in globals():\n",
    "    print(\"⚠️ Run Cell 6a first to collect results\")\n",
    "else:\n",
    "    params = smoke_test_results['params']\n",
    "    decoder_names = smoke_test_results['decoder_names']\n",
    "    sections = smoke_test_results['sections']\n",
    "    baselines = smoke_test_results['baselines']\n",
    "    hom_base_lers = smoke_test_results['hom_base_lers']\n",
    "    hom_no_meta_lers = smoke_test_results['hom_no_meta_lers']\n",
    "    \n",
    "    def format_ler_with_arrow(ler, baseline=None):\n",
    "        \"\"\"Format LER with trend arrow if baseline provided.\"\"\"\n",
    "        if ler is None:\n",
    "            return \"✗fail\"\n",
    "        ler_str = f\"{ler:.4f}\"\n",
    "        if baseline is not None and baseline > 0:\n",
    "            if ler < baseline * 0.5:\n",
    "                return f\"{ler_str} ▼▼\"\n",
    "            elif ler < baseline * 0.9:\n",
    "                return f\"{ler_str} ▼\"\n",
    "            elif ler > baseline * 1.5:\n",
    "                return f\"{ler_str} ▲▲!\"\n",
    "            elif ler > baseline * 1.1:\n",
    "                return f\"{ler_str} ▲\"\n",
    "        return ler_str\n",
    "    \n",
    "    def get_best_ler(results):\n",
    "        \"\"\"Get best LER from results.\"\"\"\n",
    "        if 'decoders' not in results:\n",
    "            return None\n",
    "        lers = [r['ler'] for r in results['decoders'].values() if r.get('ler') is not None]\n",
    "        return min(lers) if lers else None\n",
    "    \n",
    "    # Print header\n",
    "    print(\"=\" * 120)\n",
    "    print(\"DECODER SMOKE TEST ON COMPOSITE CODES - COMPREHENSIVE COMPARISON\")\n",
    "    print(\"=\" * 120)\n",
    "    print(f\"\\nParameters: p={params['p']}, shots={params['shots']}, rounds={params['rounds']}\")\n",
    "    print(\"Expectation: More concatenation → LOWER LER; Metachecks → LOWER LER for homological products\\n\")\n",
    "    print(f\"Testing with decoders: {decoder_names}\\n\")\n",
    "    \n",
    "    # Build header row\n",
    "    col_width = 12\n",
    "    code_col_width = 50\n",
    "    header = f\"  {'Code':<{code_col_width}} {'no-dec':>{col_width}}\"\n",
    "    for dec_name in decoder_names:\n",
    "        header += f\" {dec_name[:col_width]:<{col_width}}\"\n",
    "    header += \"  Status\"\n",
    "    sep_line = \"-\" * (code_col_width + 4 + col_width + (col_width + 1) * len(decoder_names) + 15)\n",
    "    \n",
    "    print(header)\n",
    "    print(sep_line)\n",
    "    \n",
    "    # Section display info\n",
    "    section_info = [\n",
    "        ('NO_CONCAT', '[NO CONCATENATION] - Baseline LER for outer codes', None),\n",
    "        ('CONCAT', '[CONCATENATED CODES] - Should have LOWER LER than outer code baseline', 'baselines'),\n",
    "        ('MULTI_CONCAT', '[MULTI-LEVEL CONCATENATED] - Double concatenation (even lower LER expected)', 'baselines'),\n",
    "        ('HOM_BASE', '[BASE-BEFORE-HOMOLOGICAL-PRODUCT] - Baseline codes for tensor product', None),\n",
    "        ('HOM_NO_META', '[HOMOLOGICAL PRODUCT - NO METACHECKS] - 4D codes without metachecks', 'hom_base_lers'),\n",
    "        ('HOM_META', '[HOMOLOGICAL PRODUCT - WITH METACHECKS] - Should be BETTER than no metachecks', 'hom_no_meta_lers'),\n",
    "        ('HOM_5CHAIN', '[5-CHAIN HOMOLOGICAL PRODUCTS] - ToricCode⊗ToricCode etc. for SingleShot decoder', None),\n",
    "        ('DUAL', '[DUAL CODES]', None),\n",
    "    ]\n",
    "    \n",
    "    all_section_lers = {}\n",
    "    \n",
    "    for sec_key, sec_title, baseline_source in section_info:\n",
    "        if sec_key not in sections or not sections[sec_key]:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{sec_title}\")\n",
    "        all_section_lers[sec_key] = []\n",
    "        \n",
    "        for results in sections[sec_key]:\n",
    "            label = results.get('label', '???')\n",
    "            if len(label) > code_col_width - 2:\n",
    "                label = label[:code_col_width - 5] + \"...\"\n",
    "            \n",
    "            # Handle error case\n",
    "            if 'error' in results:\n",
    "                print(f\"  {label:<{code_col_width}} ERROR: {results['error']}\")\n",
    "                continue\n",
    "            \n",
    "            # Get baseline for comparison\n",
    "            baseline = None\n",
    "            if baseline_source == 'baselines':\n",
    "                baseline = baselines.get(results.get('baseline_key'))\n",
    "            elif baseline_source == 'hom_base_lers':\n",
    "                baseline = hom_base_lers.get(results.get('baseline_key'))\n",
    "            elif baseline_source == 'hom_no_meta_lers':\n",
    "                baseline = hom_no_meta_lers.get(results.get('baseline_key'))\n",
    "            \n",
    "            # No-decode column\n",
    "            no_dec = results.get('no_decode')\n",
    "            no_dec_str = f\"{no_dec:.4f}\" if no_dec is not None else \"---\"\n",
    "            \n",
    "            row = f\"  {label:<{code_col_width}} {no_dec_str:>{col_width}}\"\n",
    "            \n",
    "            # Each decoder column\n",
    "            for dec_name in decoder_names:\n",
    "                dec_res = results.get('decoders', {}).get(dec_name, {})\n",
    "                ler = dec_res.get('ler')\n",
    "                if dec_res.get('status') == 'SKIP':\n",
    "                    row += f\" {'-skip':<{col_width}}\"\n",
    "                else:\n",
    "                    ler_str = format_ler_with_arrow(ler, baseline)\n",
    "                    row += f\" {ler_str:<{col_width}}\"\n",
    "            \n",
    "            # Status column\n",
    "            best_ler = get_best_ler(results)\n",
    "            if best_ler is not None:\n",
    "                all_section_lers[sec_key].append(best_ler)\n",
    "            \n",
    "            is_baseline = results.get('is_baseline', False)\n",
    "            if is_baseline:\n",
    "                row += \"  baseline\"\n",
    "            elif baseline is not None and best_ler is not None:\n",
    "                if best_ler < baseline * 0.3:\n",
    "                    row += f\"  {STATUS_OK} MUCH better\"\n",
    "                elif best_ler < baseline * 0.7:\n",
    "                    row += f\"  {STATUS_OK} improved\"\n",
    "                elif best_ler < baseline * 0.95:\n",
    "                    row += f\"  {STATUS_OK} slightly better\"\n",
    "                elif best_ler > baseline * 1.5:\n",
    "                    row += f\"  {STATUS_FAIL} WORSE!\"\n",
    "                elif best_ler > baseline * 1.1:\n",
    "                    row += f\"  {STATUS_WARN} worse\"\n",
    "                else:\n",
    "                    row += f\"  ~ similar\"\n",
    "            else:\n",
    "                row += \"  ---\"\n",
    "            \n",
    "            print(row)\n",
    "    \n",
    "    print(sep_line)\n",
    "    \n",
    "    # SUMMARY\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\n{'Section':<40} {'Avg LER':>12} {'Min LER':>12} {'Max LER':>12} {'Count':>8}\")\n",
    "    for sec_key in ['NO_CONCAT', 'CONCAT', 'MULTI_CONCAT', 'HOM_BASE', 'HOM_NO_META', 'HOM_META', 'HOM_5CHAIN', 'DUAL']:\n",
    "        if sec_key in all_section_lers and all_section_lers[sec_key]:\n",
    "            lers = all_section_lers[sec_key]\n",
    "            avg_ler = np.mean(lers)\n",
    "            min_ler = np.min(lers)\n",
    "            max_ler = np.max(lers)\n",
    "            print(f\"{sec_key:<40} {avg_ler:>12.4f} {min_ler:>12.4f} {max_ler:>12.4f} {len(lers):>8}\")\n",
    "    \n",
    "    # Key comparisons\n",
    "    print(\"\\nKey Comparisons:\")\n",
    "    \n",
    "    if 'NO_CONCAT' in all_section_lers and 'CONCAT' in all_section_lers:\n",
    "        base_avg = np.mean(all_section_lers['NO_CONCAT'])\n",
    "        concat_avg = np.mean(all_section_lers['CONCAT'])\n",
    "        if base_avg > 0:\n",
    "            improvement = (base_avg - concat_avg) / base_avg * 100\n",
    "            status = STATUS_OK if improvement > 20 else (STATUS_WARN if improvement > 0 else STATUS_FAIL)\n",
    "            print(f\"  {status} Concatenation: {base_avg:.4f} → {concat_avg:.4f} ({improvement:+.1f}%)\")\n",
    "    \n",
    "    if 'NO_CONCAT' in all_section_lers and 'MULTI_CONCAT' in all_section_lers:\n",
    "        base_avg = np.mean(all_section_lers['NO_CONCAT'])\n",
    "        multi_avg = np.mean(all_section_lers['MULTI_CONCAT'])\n",
    "        if base_avg > 0:\n",
    "            improvement = (base_avg - multi_avg) / base_avg * 100\n",
    "            status = STATUS_OK if improvement > 40 else (STATUS_WARN if improvement > 0 else STATUS_FAIL)\n",
    "            print(f\"  {status} Multi-concat: {base_avg:.4f} → {multi_avg:.4f} ({improvement:+.1f}%)\")\n",
    "    \n",
    "    if 'HOM_NO_META' in all_section_lers and 'HOM_META' in all_section_lers:\n",
    "        no_meta_avg = np.mean(all_section_lers['HOM_NO_META'])\n",
    "        meta_avg = np.mean(all_section_lers['HOM_META'])\n",
    "        if no_meta_avg > 0:\n",
    "            improvement = (no_meta_avg - meta_avg) / no_meta_avg * 100\n",
    "            status = STATUS_OK if improvement > 10 else (STATUS_WARN if improvement > 0 else STATUS_FAIL)\n",
    "            print(f\"  {status} Metachecks (hom. product): {no_meta_avg:.4f} → {meta_avg:.4f} ({improvement:+.1f}%)\")\n",
    "        elif meta_avg == 0 and no_meta_avg == 0:\n",
    "            print(f\"  {STATUS_OK} Metachecks (hom. product): both 0.0000 (perfect)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473c7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DUAL CODE TESTS\n",
      "======================================================================\n",
      "\n",
      "Testing DualCode(code) - swaps X and Z sectors\n",
      "\n",
      "[1/10] Dual(FourQubit422_[[4,2,2]])... ✓ n=4, k=2\n",
      "[2/10] Dual(C6)... ✓ n=6, k=2\n",
      "[3/10] Dual(Steane_713)... ✓ n=7, k=1\n",
      "[4/10] Dual(Shor_91)... ✓ n=9, k=1\n",
      "[5/10] Dual(ReedMuller_15_1_3)... ✓ n=15, k=1\n",
      "[6/10] Dual(Hamming_CSS_7)... ✓ n=7, k=1\n",
      "[7/10] Dual(Hamming_CSS_15)... ✓ n=15, k=7\n",
      "[8/10] Dual(Hamming_CSS_31)... ✓ n=31, k=21\n",
      "[9/10] Dual(Code_832)... ✓ n=8, k=3\n",
      "[10/10] Dual(Repetition_3)... ✓ n=3, k=1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DUAL CODE SUMMARY: 10 ✓ | 0 ⚠️ | 0 ✗\n",
      "✓ n=4, k=2\n",
      "[2/10] Dual(C6)... ✓ n=6, k=2\n",
      "[3/10] Dual(Steane_713)... ✓ n=7, k=1\n",
      "[4/10] Dual(Shor_91)... ✓ n=9, k=1\n",
      "[5/10] Dual(ReedMuller_15_1_3)... ✓ n=15, k=1\n",
      "[6/10] Dual(Hamming_CSS_7)... ✓ n=7, k=1\n",
      "[7/10] Dual(Hamming_CSS_15)... ✓ n=15, k=7\n",
      "[8/10] Dual(Hamming_CSS_31)... ✓ n=31, k=21\n",
      "[9/10] Dual(Code_832)... ✓ n=8, k=3\n",
      "[10/10] Dual(Repetition_3)... ✓ n=3, k=1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DUAL CODE SUMMARY: 10 ✓ | 0 ⚠️ | 0 ✗\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 7: Dual Code Tests\"\"\"\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DUAL CODE TESTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTesting DualCode(code) - swaps X and Z sectors\\n\")\n",
    "\n",
    "dual_results = []\n",
    "\n",
    "# Test on a selection of codes\n",
    "dual_test_codes = list(css_codes.items())[:10]\n",
    "\n",
    "for i, (name, code) in enumerate(dual_test_codes):\n",
    "    print(f\"[{i+1}/{len(dual_test_codes)}] Dual({name})...\", end=' ', flush=True)\n",
    "    \n",
    "    result = {\n",
    "        'original': name,\n",
    "        'status': 'UNKNOWN',\n",
    "        'n': None,\n",
    "        'k': None,\n",
    "        'error': None,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        dual = DualCode(code)\n",
    "        result['n'] = dual.n\n",
    "        result['k'] = dual.k\n",
    "        \n",
    "        # Verify n and k preserved\n",
    "        if dual.n == code.n and dual.k == code.k:\n",
    "            result['status'] = 'OK'\n",
    "        else:\n",
    "            result['status'] = 'WARN'\n",
    "            result['error'] = f\"n,k changed: {code.n},{code.k} -> {dual.n},{dual.k}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        result['status'] = 'FAIL'\n",
    "        result['error'] = f\"{type(e).__name__}: {str(e)[:30]}\"\n",
    "    \n",
    "    dual_results.append(result)\n",
    "    \n",
    "    if result['status'] == 'OK':\n",
    "        print(f\"{STATUS_OK} n={result['n']}, k={result['k']}\")\n",
    "    elif result['status'] == 'WARN':\n",
    "        print(f\"{STATUS_WARN} {result['error']}\")\n",
    "    else:\n",
    "        print(f\"{STATUS_FAIL} {result['error']}\")\n",
    "\n",
    "# Summary\n",
    "ok = sum(1 for r in dual_results if r['status'] == 'OK')\n",
    "warn = sum(1 for r in dual_results if r['status'] == 'WARN')\n",
    "fail = sum(1 for r in dual_results if r['status'] == 'FAIL')\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"DUAL CODE SUMMARY: {ok} {STATUS_OK} | {warn} {STATUS_WARN} | {fail} {STATUS_FAIL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baac212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "COMPOSITE CODE SMOKE TEST - COMPREHENSIVE RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "CONCATENATION (ConcatenatedTopologicalCSSCode):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Outer                | Inner                |     n |   k |  Circuit | Status\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RotatedSurface_[[9,1 | FourQubit422_[[4,2,2 |    36 |  10 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | C6                   |    54 |  10 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | Steane_713           |    63 |   1 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | Shor_91              |    81 |   1 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | Hamming_CSS_7        |    63 |   1 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | Code_832             |     - |   - |        ✗ | ✗ ValueError: Hx Hz^T \n",
      "RotatedSurface_[[9,1 | Repetition_3         |    27 |   1 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | Repetition_5         |    45 |   1 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | Repetition_7         |    63 |   1 |        ✓ | ✓ OK\n",
      "RotatedSurface_[[9,1 | TriangularColour_d3  |    63 |   1 |        ✓ | ✓ OK\n",
      "\n",
      "\n",
      "MULTI-LEVEL CONCATENATION:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "(FourQubit422_[[4,2,2]] ∘ C6) ∘ Steane_713         | n=  168 k=  6 | ✓ OK\n",
      "(C6 ∘ Steane_713) ∘ Shor_91                        | n=  378 k=  2 | ✓ OK\n",
      "(Steane_713 ∘ Shor_91) ∘ FourQubit422_[[4,2,2]]    | n=  252 k= 64 | ✓ OK\n",
      "\n",
      "\n",
      "HOMOLOGICAL PRODUCT:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FourQubit422_[[4,2,2 ⊗ FourQubit422_[[4,2,2 | n=   18 k=  4 | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Steane_713           | n=   34 k=  2 | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Shor_91              | n=   44 k=  2 | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Hamming_CSS_7        | n=   34 k=  2 | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Hamming_CSS_15       | n=   68 k= 14 | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Hamming_CSS_31       | n=  134 k= 42 | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Repetition_3         | n=   11 k=  - | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Repetition_5         | n=   21 k=  - | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ Repetition_7         | n=   31 k=  - | ✓ OK\n",
      "FourQubit422_[[4,2,2 ⊗ RotatedSurface_[[9,1 | n=   44 k=  2 | ✓ OK\n",
      "\n",
      "\n",
      "DUAL CODES:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dual(FourQubit422_[[4,2,2]]        ) | n=    4 k=  2 | ✓\n",
      "Dual(C6                            ) | n=    6 k=  2 | ✓\n",
      "Dual(Steane_713                    ) | n=    7 k=  1 | ✓\n",
      "Dual(Shor_91                       ) | n=    9 k=  1 | ✓\n",
      "Dual(ReedMuller_15_1_3             ) | n=   15 k=  1 | ✓\n",
      "Dual(Hamming_CSS_7                 ) | n=    7 k=  1 | ✓\n",
      "Dual(Hamming_CSS_15                ) | n=   15 k=  7 | ✓\n",
      "Dual(Hamming_CSS_31                ) | n=   31 k= 21 | ✓\n",
      "Dual(Code_832                      ) | n=    8 k=  3 | ✓\n",
      "Dual(Repetition_3                  ) | n=    3 k=  1 | ✓\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell 8: Comprehensive Results Table\"\"\"\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"COMPOSITE CODE SMOKE TEST - COMPREHENSIVE RESULTS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Concatenation results\n",
    "print(\"\\nCONCATENATION (ConcatenatedTopologicalCSSCode):\")\n",
    "print(\"-\"*100)\n",
    "print(f\"{'Outer':<20} | {'Inner':<20} | {'n':>5} | {'k':>3} | {'Circuit':>8} | Status\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for r in concat_results:\n",
    "    outer = r['outer'][:20] if r['outer'] else 'N/A'\n",
    "    inner = r['inner'][:20] if r['inner'] else 'N/A'\n",
    "    n = str(r['n']) if r['n'] else '-'\n",
    "    k = str(r['k']) if r['k'] else '-'\n",
    "    circ = STATUS_OK if r.get('circuit_ok') else STATUS_FAIL\n",
    "    \n",
    "    if r['status'] == 'OK':\n",
    "        status = f\"{STATUS_OK} OK\"\n",
    "    elif r['status'] == 'WARN':\n",
    "        status = f\"{STATUS_WARN} {r['error'][:20]}\" if r['error'] else f\"{STATUS_WARN}\"\n",
    "    else:\n",
    "        status = f\"{STATUS_FAIL} {r['error'][:20]}\" if r['error'] else f\"{STATUS_FAIL}\"\n",
    "    \n",
    "    print(f\"{outer:<20} | {inner:<20} | {n:>5} | {k:>3} | {circ:>8} | {status}\")\n",
    "\n",
    "# Multi-level results\n",
    "if multi_results:\n",
    "    print(\"\\n\\nMULTI-LEVEL CONCATENATION:\")\n",
    "    print(\"-\"*100)\n",
    "    for r in multi_results:\n",
    "        desc = r['desc'][:50] if r.get('desc') else 'N/A'\n",
    "        n = str(r['n']) if r['n'] else '-'\n",
    "        k = str(r['k']) if r['k'] else '-'\n",
    "        \n",
    "        if r['status'] == 'OK':\n",
    "            status = f\"{STATUS_OK} OK\"\n",
    "        elif r['status'] == 'WARN':\n",
    "            status = f\"{STATUS_WARN}\"\n",
    "        else:\n",
    "            status = f\"{STATUS_FAIL} {r['error'][:30]}\" if r['error'] else f\"{STATUS_FAIL}\"\n",
    "        \n",
    "        print(f\"{desc:<50} | n={n:>5} k={k:>3} | {status}\")\n",
    "\n",
    "# Homological product results\n",
    "if hom_results:\n",
    "    print(\"\\n\\nHOMOLOGICAL PRODUCT:\")\n",
    "    print(\"-\"*100)\n",
    "    for r in hom_results:\n",
    "        code_a = r['code_a'][:20] if r.get('code_a') else 'N/A'\n",
    "        code_b = r['code_b'][:20] if r.get('code_b') else 'N/A'\n",
    "        n = str(r['n']) if r['n'] else '-'\n",
    "        k = str(r['k']) if r['k'] else '-'\n",
    "        \n",
    "        if r['status'] == 'OK':\n",
    "            status = f\"{STATUS_OK} OK\"\n",
    "        else:\n",
    "            status = f\"{STATUS_FAIL} {r['error'][:30]}\" if r['error'] else f\"{STATUS_FAIL}\"\n",
    "        \n",
    "        print(f\"{code_a:<20} ⊗ {code_b:<20} | n={n:>5} k={k:>3} | {status}\")\n",
    "\n",
    "# Dual code results\n",
    "if dual_results:\n",
    "    print(\"\\n\\nDUAL CODES:\")\n",
    "    print(\"-\"*100)\n",
    "    for r in dual_results:\n",
    "        orig = r['original'][:30] if r.get('original') else 'N/A'\n",
    "        n = str(r['n']) if r['n'] else '-'\n",
    "        k = str(r['k']) if r['k'] else '-'\n",
    "        \n",
    "        if r['status'] == 'OK':\n",
    "            status = f\"{STATUS_OK}\"\n",
    "        elif r['status'] == 'WARN':\n",
    "            status = f\"{STATUS_WARN}\"\n",
    "        else:\n",
    "            status = f\"{STATUS_FAIL}\"\n",
    "        \n",
    "        print(f\"Dual({orig:<30}) | n={n:>5} k={k:>3} | {status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
